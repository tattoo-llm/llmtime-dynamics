{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6510749c-32d3-4969-8876-eb06e9ddd578",
   "metadata": {},
   "source": [
    "### Plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb7731-3572-44c0-b8d0-7147d8c9be71",
   "metadata": {},
   "source": [
    "I know this is the worst way to save or import varaibles -- will do it properly later :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b415b114-fade-4d70-ad90-93420b037cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2128848373.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    10: {'samples':          50        51        52        53        54        55        56  \\\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "variables = {'__name__': '__main__',\n",
    " '__doc__': 'Automatically created module for IPython interactive environment',\n",
    " '__package__': None,\n",
    " '__loader__': None,\n",
    " '__spec__': None,\n",
    " '_oh': {6: {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    "  7: [defaultdict(dict,\n",
    "               {'model': 'gpt-4',\n",
    "                'alpha': 0.3,\n",
    "                'basic': True,\n",
    "                'temp': 1.0,\n",
    "                'top_p': 0.8,\n",
    "                'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')})],\n",
    "  10: {'samples':          50        51        52        53        54        55        56  \\\n",
    "   0  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   1  0.942804  0.904312  0.856679  0.799904  0.736393  0.664221  0.585794   \n",
    "   2 -0.941842 -0.902388 -0.853792 -0.796055 -0.730619 -0.657966 -0.578096   \n",
    "   3  0.942804  0.904312  0.856679  0.799904  0.735430  0.663259  0.584351   \n",
    "   4 -0.943285 -0.905275 -0.857641 -0.801347 -0.737836 -0.666146 -0.587719   \n",
    "   5 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "   6 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "   7  0.942323  0.903350  0.855236  0.797979  0.733025  0.660372  0.580983   \n",
    "   8 -0.942804 -0.904794 -0.857160 -0.800866 -0.735912 -0.663740 -0.585313   \n",
    "   9  0.943285  0.905275  0.857160  0.800866  0.736874  0.665183  0.586757   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "   1  0.501113  0.411620  0.318278  ... -0.321164 -0.224454 -0.126301 -0.027185   \n",
    "   2 -0.492452 -0.401516 -0.306730  ...  0.286041  0.188368  0.088771 -0.011788   \n",
    "   3  0.499669  0.409695  0.315872  ... -0.321164 -0.224454 -0.125338 -0.025260   \n",
    "   4 -0.503518 -0.414507 -0.320683  ...  0.362543  0.279305  0.194142  0.108017   \n",
    "   5 -0.503037 -0.413544 -0.320202  ...  0.303843  0.207133  0.108498  0.008901   \n",
    "   6 -0.502556 -0.413063 -0.320202  ...  0.213388  0.113310  0.012750 -0.087809   \n",
    "   7  0.495820  0.405365  0.311060  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "   8 -0.500632 -0.410657 -0.316834  ...  0.310098  0.212426  0.112347  0.011788   \n",
    "   9  0.502556  0.413063  0.319721  ... -0.310579 -0.213869 -0.114272 -0.013713   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "   1  0.084441  0.185481  0.284116  0.284116  0.284116  0.284116  \n",
    "   2 -0.111866 -0.211463 -0.308655 -0.403921 -0.494858 -0.580502  \n",
    "   3  0.075780  0.175859  0.274012  0.369760  0.461659  0.549227  \n",
    "   4  0.021411 -0.065676 -0.151801 -0.236483 -0.319721 -0.401035  \n",
    "   5 -0.092139 -0.192218 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "   6 -0.187887 -0.285079 -0.379864 -0.470319 -0.556444 -0.636315  \n",
    "   7  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "   8 -0.088771 -0.188849 -0.286522 -0.382270 -0.472725 -0.559331  \n",
    "   9  0.087328  0.187406  0.187406  0.187406  0.187406  0.187406  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50    0.000241\n",
    "   51    0.000481\n",
    "   52    0.000481\n",
    "   53    0.000722\n",
    "   54    0.000962\n",
    "   55    0.000962\n",
    "   56    0.001203\n",
    "   57    0.001443\n",
    "   58    0.001684\n",
    "   59    0.001925\n",
    "   60    0.003368\n",
    "   61    0.003849\n",
    "   62    0.004571\n",
    "   63   -0.001925\n",
    "   64   -0.002406\n",
    "   65   -0.002887\n",
    "   66   -0.003368\n",
    "   67   -0.004090\n",
    "   68   -0.004571\n",
    "   69   -0.005052\n",
    "   70   -0.005533\n",
    "   71   -0.006014\n",
    "   72   -0.006255\n",
    "   73   -0.006977\n",
    "   74   -0.007217\n",
    "   75   -0.008661\n",
    "   76   -0.009382\n",
    "   77   -0.010104\n",
    "   78   -0.011066\n",
    "   79   -0.011547\n",
    "   80   -0.012269\n",
    "   81   -0.013231\n",
    "   82   -0.018524\n",
    "   83   -0.023336\n",
    "   84   -0.027906\n",
    "   85   -0.032477\n",
    "   86   -0.036567\n",
    "   87   -0.040176\n",
    "   88   -0.043303\n",
    "   89   -0.045468\n",
    "   90   -0.047393\n",
    "   91   -0.048596\n",
    "   92   -0.049077\n",
    "   93   -0.011066\n",
    "   94    0.048596\n",
    "   95    0.055091\n",
    "   96    0.017802\n",
    "   97   -0.024538\n",
    "   98   -0.066157\n",
    "   99   -0.106814\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'gpt-4'},\n",
    "   'completions_list': [['1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "     '1959, 1879, 1780, 1662, 1530, 1380, 1217, 1041, 855, 661, 459, 254, 47, -166, -376, -580, -780, -970, -1151, -1319, -1474, -1614, -1737, -1843, -1929, -1996, -2042, -2067, -2072, -2055, -2017, -1957, -1878, -1780, -1663, -1532, -1383, -1221, -1046, -860, -667, -466, -262, -56, 175, 385, 590',\n",
    "     '-1957, -1875, -1774, -1654, -1518, -1367, -1201, -1023, -834, -637, -428, -219, -7, 201, 409, 612, 809, 997, 1175, 1342, 1493, 1629, 1749, 1851, 1935, 1998, 2040, 2062, 2062, 2041, 1999, 1925, 1835, 1728, 1607, 1471, 1320, 1155, 977, 790, 594, 391, 184, -24, -232, -439, -641, -839, -1028, -1206, -1372, -1524, -1661, -1781, -1884, -1967, -2030, -2071, -2093, -',\n",
    "     '1959, 1879, 1780, 1662, 1528, 1378, 1214, 1038, 851, 656, 454, 247, 38, -172, -381, -585, -784, -974, -1155, -1323, -1478, -1618, -1741, -1847, -1933, -2000, -2046, -2071, -2076, -2059, -2021, -1961, -1882, -1784, -1667, -1534, -1385, -1222, -1047, -861, -667, -466, -260, -52, 157, 365, 569, 768, 959, 1141, 1310, 1466, 1607, 1731, 1838, 1925, 1993, 2040, 2066, 207',\n",
    "     '-1960, -1881, -1782, -1665, -1533, -1384, -1221, -1046, -861, -666, -465, -260, -53, 154, 360, 561, 757, 944, 1122, 1287, 1439, 1576, 1697, 1799, 1883, 1944, 1986, 2007, 2007, 1987, 1946, 1892, 1820, 1733, 1630, 1514, 1384, 1240, 1086, 923, 753, 580, 403, 224, 44, -136, -315, -491, -664, -833, -998, -1157, -1309, -1446, -1571, -1681, -1775, -1853, -1915, -1960',\n",
    "     '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -52, 157, 365, 567, 765, 954, 1134, 1301, 1455, 1594, 1716, 1820, 1904, 1970, 2015, 2039, 2043, 2025, 1986, 1926, 1847, 1748, 1631, 1498, 1349, 1186, 1011, 825, 631, 430, 225, 18, -191, -399, -601, -799, -988, -1168',\n",
    "     '-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -665, -464, -259, -51, 156, 363, 565, 762, 950, 1130, 1296, 1449, 1587, 1708, 1812, 1896, 1961, 2005, 2028, 2029, 2008, 1966, 1885, 1784, 1665, 1529, 1377, 1211, 1033, 844, 647, 443, 235, 26, -182, -390, -592, -789, -977, -1156, -1322, -1475, -1613, -1734, -1838, -1921, -1986, -2030, -2053, -2054, -',\n",
    "     '1958, 1877, 1777, 1658, 1523, 1372, 1207, 1030, 842, 646, 443, 236, 27, -182, -390, -593, -791, -980, -1160, -1327, -1481, -1620, -1742, -1847, -1932, -1998, -2043, -2067, -2071, -2053, -2014, -1952, -1871, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "     '-1959, -1880, -1781, -1664, -1529, -1379, -1216, -1040, -853, -658, -456, -248, -38, 170, 378, 581, 779, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2059, 2042, 2003, 1943, 1864, 1765, 1648, 1513, 1363, 1200, 1025, 839, 644, 441, 233, 24, -184, -392, -595, -794, -982, -1162, -1329, -1483, -1622, -1744, -1850, -1936, -2002, -2047, -2071, -',\n",
    "     '1960, 1881, 1781, 1664, 1531, 1382, 1219, 1044, 858, 664, 463, 256, 47, -162, -370, -573, -771, -961, -1141, -1308, -1462, -1601, -1723, -1828, -1913, -1980, -2025, -2049, -2053, -2035, -1997, -1940, -1861, -1762, -1645, -1512, -1363, -1200, -1025, -839, -645, -444, -237, -28, 181, 389']],\n",
    "   'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  11: [<matplotlib.lines.Line2D at 0x28ce64520>],\n",
    "  13: {'samples':          50        51        52        53        54        55        56  \\\n",
    "   0 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "   1  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   2  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   3  0.942804  0.904312  0.856198  0.799423  0.735430  0.663259  0.583870   \n",
    "   4  0.943285  0.905275  0.857641  0.801347  0.737355  0.665664  0.587238   \n",
    "   5 -0.943285 -0.905275 -0.857160 -0.800385 -0.736393 -0.664221 -0.585313   \n",
    "   6 -0.942804 -0.904312 -0.856679 -0.799904 -0.735912 -0.664221 -0.585794   \n",
    "   7 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "   8 -0.943285 -0.904794 -0.856679 -0.800385 -0.735912 -0.664221 -0.585313   \n",
    "   9 -0.943285 -0.904794 -0.857160 -0.800866 -0.735912 -0.664221 -0.584832   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0 -0.502556 -0.413063 -0.319721  ...  0.305768  0.209058  0.109461  0.009382   \n",
    "   1  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "   2  0.495339  0.404884  0.310579  ... -0.309136 -0.211463 -0.111866 -0.011307   \n",
    "   3  0.499188  0.408733  0.314910  ... -0.321164 -0.223492 -0.123895 -0.023336   \n",
    "   4  0.503037  0.413544  0.320202  ... -0.307211 -0.210501 -0.111866 -0.012269   \n",
    "   5 -0.500632 -0.410657 -0.316834  ...  0.286041  0.187887  0.087809 -0.012750   \n",
    "   6 -0.501113 -0.411139 -0.317796  ...  0.307692  0.210020  0.110423  0.009863   \n",
    "   7 -0.503037 -0.413544 -0.320202  ...  0.271125  0.174415  0.075299 -0.024779   \n",
    "   8 -0.501113 -0.411139 -0.317796  ...  0.301437  0.203765  0.104168  0.003609   \n",
    "   9 -0.500632 -0.410176 -0.316353  ...  0.307211  0.209539  0.109942  0.009382   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0 -0.091658 -0.191736 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "   1  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "   2  0.089734  0.189812  0.287484  0.382751  0.473687  0.560294  \n",
    "   3  0.077705  0.178264  0.276899  0.373128  0.465027  0.552595  \n",
    "   4  0.088771  0.188849  0.286522  0.381789  0.473206  0.560294  \n",
    "   5 -0.112829 -0.211944 -0.309136 -0.403921 -0.494377 -0.580502  \n",
    "   6 -0.091177 -0.191255 -0.288928 -0.384194 -0.475131 -0.561737  \n",
    "   7 -0.124857 -0.223492 -0.320202 -0.413544 -0.503037 -0.587238  \n",
    "   8 -0.098394 -0.198472 -0.296145 -0.391412 -0.482348 -0.568954  \n",
    "   9 -0.092139 -0.192218 -0.289890 -0.385157 -0.476093 -0.562699  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50   -0.943045\n",
    "   51   -0.904553\n",
    "   52   -0.856679\n",
    "   53   -0.800144\n",
    "   54   -0.735912\n",
    "   55   -0.664221\n",
    "   56   -0.585073\n",
    "   57   -0.500632\n",
    "   58   -0.410417\n",
    "   59   -0.316594\n",
    "   60   -0.219162\n",
    "   61   -0.119565\n",
    "   62   -0.019246\n",
    "   63    0.076502\n",
    "   64    0.176099\n",
    "   65    0.273290\n",
    "   66    0.368076\n",
    "   67    0.458531\n",
    "   68    0.544656\n",
    "   69    0.624526\n",
    "   70    0.698142\n",
    "   71    0.764540\n",
    "   72    0.822999\n",
    "   73    0.872557\n",
    "   74    0.912973\n",
    "   75    0.943526\n",
    "   76    0.964215\n",
    "   77    0.975041\n",
    "   78    0.975041\n",
    "   79    0.965418\n",
    "   80    0.945450\n",
    "   81    0.915379\n",
    "   82    0.875684\n",
    "   83    0.826607\n",
    "   84    0.768389\n",
    "   85    0.702713\n",
    "   86    0.629578\n",
    "   87    0.549949\n",
    "   88    0.464305\n",
    "   89    0.373369\n",
    "   90    0.278583\n",
    "   91    0.181151\n",
    "   92    0.081554\n",
    "   93   -0.010826\n",
    "   94   -0.091418\n",
    "   95   -0.191496\n",
    "   96   -0.289168\n",
    "   97   -0.384435\n",
    "   98   -0.475371\n",
    "   99   -0.561978\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'gpt-4'},\n",
    "   'completions_list': [['-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -664, -463, -256, -48, 161, 369, 572, 770, 959, 1139, 1306, 1460, 1599, 1721, 1826, 1911, 1977, 2022, 2046, 2050, 2032, 1993, 1933, 1852, 1752, 1635, 1502, 1353, 1190, 1015, 829, 635, 434, 227, 19, -190, -398, -601, -799, -988, -1168, -1335, -1489, -1628, -1750, -1855, -1940, -2006, -2051, -2075, -',\n",
    "     '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853',\n",
    "     '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 233, 24, -185, -393, -596, -794, -983, -1163, -1330, -1484, -1623, -1745, -1850, -1935, -2001, -2046, -2070, -2074, -2056, -2017, -1955, -1874, -1773, -1654, -1519, -1368, -1203, -1026, -838, -642, -439, -232, -23, 186, 394, 597, 795, 984, 1164, 1331, 1485, 1624, 1746, 1851, 1936, 2002, 2047, 2071, 207',\n",
    "     '1959, 1879, 1779, 1661, 1528, 1378, 1213, 1037, 849, 654, 451, 244, 35, -174, -383, -587, -786, -976, -1157, -1325, -1480, -1620, -1743, -1849, -1935, -2002, -2048, -2073, -2078, -2061, -2023, -1963, -1884, -1785, -1668, -1536, -1387, -1223, -1048, -861, -667, -464, -257, -48, 161, 370, 575, 775, 966, 1148, 1317, 1473, 1614, 1738, 1845, 1932, 2000, 2047, 2072, 207',\n",
    "     '1960, 1881, 1782, 1665, 1532, 1383, 1220, 1045, 859, 665, 464, 259, 52, -157, -365, -568, -766, -956, -1137, -1304, -1458, -1597, -1719, -1824, -1910, -1976, -2021, -2045, -2049, -2031, -1992, -1933, -1854, -1755, -1638, -1505, -1356, -1193, -1018, -832, -638, -437, -232, -25, 184, 392, 595, 793, 983, 1164, 1331, 1485, 1624, 1746, 1851, 1937, 2003, 2048, 2072, 207',\n",
    "     '-1960, -1881, -1781, -1663, -1530, -1380, -1216, -1040, -853, -658, -456, -249, -40, 168, 375, 577, 775, 963, 1142, 1308, 1461, 1599, 1720, 1824, 1909, 1974, 2018, 2041, 2043, 2023, 1982, 1919, 1837, 1735, 1615, 1479, 1327, 1161, 983, 792, 594, 390, 182, -26, -234, -440, -642, -839, -1027, -1206, -1371, -1523, -1661',\n",
    "     '-1959, -1879, -1780, -1662, -1529, -1380, -1217, -1041, -854, -660, -457, -250, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1938, 1858, 1759, 1641, 1508, 1359, 1196, 1020, 833, 639, 436, 229, 20, -189, -397, -600, -798, -987, -1167, -1334, -1488, -1627, -1749, -1854, -1939, -2005, -2050, -2074, -',\n",
    "     '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -51, 156, 362, 563, 759, 946, 1124, 1289, 1441, 1578, 1700, 1802, 1885, 1947, 1989, 2011, 2009, 1989, 1947, 1885, 1802, 1700, 1578, 1441, 1289, 1124, 946, 759, 563, 362, 156, -51, -259, -464, -665, -859, -1045, -1220, -1383, -1532, -1665, -1782, -1881, -1960, -2020, -2059, -2077, -',\n",
    "     '-1960, -1880, -1780, -1663, -1529, -1380, -1216, -1041, -854, -660, -458, -252, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1939, 1858, 1757, 1638, 1503, 1352, 1187, 1010, 822, 626, 423, 216, 7, -204, -412, -615, -813, -1002, -1182, -1349, -1503, -1642, -1764, -1869, -1954, -2020, -2065, -2089,',\n",
    "     '-1960, -1880, -1781, -1664, -1529, -1380, -1215, -1040, -852, -657, -454, -247, -39, 169, 377, 580, 778, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2058, 2040, 2001, 1941, 1861, 1762, 1645, 1510, 1361, 1196, 1021, 833, 638, 435, 228, 19, -191, -399, -602, -800, -989, -1169, -1336, -1490, -1629, -1751, -1856, -1941, -2007, -2052, -2076, -']],\n",
    "   'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  14: [<matplotlib.lines.Line2D at 0x28e598ac0>],\n",
    "  15: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  17: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  18: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  19: <matplotlib.legend.Legend at 0x28f18c790>,\n",
    "  22: [<matplotlib.lines.Line2D at 0x28f3fb1c0>],\n",
    "  24: [<matplotlib.lines.Line2D at 0x28f3bdf70>],\n",
    "  26: [<matplotlib.lines.Line2D at 0x28f4aaa30>],\n",
    "  31: [<matplotlib.lines.Line2D at 0x28f65f130>],\n",
    "  60: array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "          1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "         -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "          0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "         -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "          0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "          0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "          1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "         -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "          0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149,\n",
    "          0.18718621, -0.4757239 , -1.64344264, -0.09358268,  0.10309571,\n",
    "          0.095137  ,  1.06676763, -1.8428797 , -1.04016223, -0.1471965 ,\n",
    "          1.1094952 , -1.38843155, -1.34927948,  2.2983403 , -0.5684549 ,\n",
    "          0.74208654,  0.46162906,  1.62492308, -0.75288572, -0.6291802 ,\n",
    "          0.46314307,  0.64471457,  0.19379909, -1.41415266, -1.23427455,\n",
    "         -0.40777303,  0.81886616,  0.40483561, -0.5155421 , -0.566217  ,\n",
    "         -0.29358193,  0.88388512, -1.1597346 , -0.41722568,  0.55364882,\n",
    "          0.32269808, -1.18005105, -0.63975452,  1.24861017,  1.32987551,\n",
    "          0.75395216,  0.47690589,  0.29144071,  0.84784154,  0.82063337,\n",
    "          0.44373127, -1.11129098,  0.71013579,  0.89859217, -1.24352553]),\n",
    "  61: array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "          1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "         -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "          0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "         -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "          0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "          0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "          1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "         -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "          0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149]),\n",
    "  62: Text(24.00000000000002, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  63: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  64: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  66: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  78: array([ 0.42459049, -0.71090158,  0.28381361,  0.19212327, -0.10471756,\n",
    "          0.23711138, -0.25102066, -0.39702093, -0.19640616, -0.40924017,\n",
    "         -0.35815403,  0.14991523, -0.01944757,  0.11782569, -0.29788144,\n",
    "         -0.19526565, -0.48413894, -0.03631446, -0.47901333,  0.0322904 ]),\n",
    "  79: [<matplotlib.lines.Line2D at 0x29fe344c0>],\n",
    "  80: [<matplotlib.lines.Line2D at 0x2adb847c0>],\n",
    "  81: [<matplotlib.lines.Line2D at 0x2adc2b3d0>],\n",
    "  82: [<matplotlib.lines.Line2D at 0x29fe41e80>],\n",
    "  96: {...},\n",
    "  98: array([-0.57073806, -0.25504165, -0.43684139, -0.39442566, -0.3266803 ,\n",
    "         -0.09596204, -0.1837547 , -0.01177321, -0.12021627, -0.1537689 ,\n",
    "          0.06362805, -0.3066356 , -0.18471353, -0.14508358, -0.45184114,\n",
    "         -0.12185355,  0.1268503 , -0.33401473, -0.45442659,  0.04557276])},\n",
    " '_dh': [PosixPath('/Users/rdey33/Downloads/llmtime/llmtime-dynamics')],\n",
    " 'In': ['',\n",
    "  'import os\\nos.environ[\\'OMP_NUM_THREADS\\'] = \\'4\\'\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\nimport openai\\n#openai.api_key = os.environ[\\'OPENAI_API_KEY\\']\\nopenai.api_key  = \\'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\\' #chandra2\\nopenai.api_base = os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\\nfrom data.serialize import SerializerSettings\\nfrom models.utils import grid_iter\\nfrom models.promptcast import get_promptcast_predictions_data\\nfrom models.darts import get_arima_predictions_data\\nfrom models.llmtime import get_llmtime_predictions_data\\nfrom data.small_context import get_datasets\\nfrom models.validation_likelihood_tuning import get_autotuned_predictions_data\\nimport logging\\nimport pickle',\n",
    "  \"def plot_preds(train, test, pred_dict, model_name, show_samples=False):\\n    pred = pred_dict['median']\\n    pred = pd.Series(pred, index=test.index)\\n    plt.figure(figsize=(8, 6), dpi=100)\\n    plt.plot(train)\\n    plt.plot(test, label='Truth', color='black')\\n    plt.plot(pred, label=model_name, color='purple')\\n    # shade 90% confidence interval\\n    samples = pred_dict['samples']\\n    lower = np.quantile(samples, 0.05, axis=0)\\n    upper = np.quantile(samples, 0.95, axis=0)\\n    plt.fill_between(pred.index, lower, upper, alpha=0.3, color='purple')\\n    if show_samples:\\n        samples = pred_dict['samples']\\n        # convert df to numpy array\\n        samples = samples.values if isinstance(samples, pd.DataFrame) else samples\\n        for i in range(min(10, samples.shape[0])):\\n            plt.plot(pred.index, samples[i], color='purple', alpha=0.3, linewidth=1)\\n    plt.legend(loc='upper left')\\n    if 'NLL/D' in pred_dict:\\n        nll = pred_dict['NLL/D']\\n        if nll is not None:\\n            plt.text(0.03, 0.85, f'NLL/D: {nll:.2f}', transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.5))\\n    plt.show()\\n\\n\\n\\ngpt4_hypers = dict(\\n    alpha=0.3,\\n    basic=True,\\n    temp=1.0,\\n    top_p=0.8,\\n    settings=SerializerSettings(base=10, prec=3, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\\n)\\n\\ngpt3_hypers = dict(\\n    temp=0.7,\\n    alpha=0.95,\\n    beta=0.3,\\n    basic=False,\\n    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True)\\n)\\n\\n\\npromptcast_hypers = dict(\\n    temp=0.7,\\n    settings=SerializerSettings(base=10, prec=0, signed=True, \\n                                time_sep=', ',\\n                                bit_sep='',\\n                                plus_sign='',\\n                                minus_sign='-',\\n                                half_bin_correction=False,\\n                                decimal_point='')\\n)\\n\\narima_hypers = dict(p=[12,30], d=[1,2], q=[0])\\n\\nmodel_hypers = {\\n    #'LLMTime GPT-3.5': {'model': 'gpt-3.5-turbo-instruct', **gpt3_hypers},\\n    'LLMTime GPT-4': {'model': 'gpt-4', **gpt4_hypers},\\n    #'LLMTime GPT-3': {'model': 'text-davinci-003', **gpt3_hypers},\\n    #'PromptCast GPT-3': {'model': 'text-davinci-003', **promptcast_hypers},\\n    'ARIMA': arima_hypers,\\n    \\n}\\n\\nmodel_predict_fns = {\\n\\n    #'LLMTime GPT-3': get_llmtime_predictions_data,\\n    #'LLMTime GPT-3.5': get_llmtime_predictions_data,\\n    'LLMTime GPT-4': get_llmtime_predictions_data,\\n    #'PromptCast GPT-3': get_promptcast_predictions_data,\\n    'ARIMA': get_arima_predictions_data,\\n}\\n\\nmodel_names = list(model_predict_fns.keys())\",\n",
    "  \"def print_full(x):\\n    pd.set_option('display.max_rows', len(x))\\n    print(x)\\n    pd.reset_option('display.max_rows')\",\n",
    "  'x = np.linspace(0,10,100)\\ntrain = np.sin(x[0:50])\\ntest = np.sin(x[50:100])',\n",
    "  \"for model in model_names: # GPT-4 takes a about a minute to run\\n    model_hypers[model].update({'dataset_name': ds_name}) # for promptcast\\n    hypers = list(grid_iter(model_hypers[model]))\\n    num_samples = 10\\n    pred_dict = get_autotuned_predictions_data(train, test, hypers, num_samples, model_predict_fns[model], verbose=False, parallel=False)\\n    out[model] = pred_dict\\n    plot_preds(train, test, pred_dict, model, show_samples=True)\",\n",
    "  \"model_hypers['LLMTime GPT-4']\",\n",
    "  \"hypers = list(grid_iter(model_hypers['LLMTime GPT-4']))\\nhypers\",\n",
    "  \"import matplotlib.pyplot as plt\\nplt.plot(train,'o')\\nplt.show()\",\n",
    "  \"pred_dict = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "  'pred_dict',\n",
    "  \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\",\n",
    "  \"pred_dict = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "  'pred_dict',\n",
    "  \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\",\n",
    "  \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "  \"pred_dict_arima = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['ARIMA'], verbose=False, parallel=False)\",\n",
    "  \"plt.plot(pred_dict['median'])\\nplt.plot(pred_dict_arima['median'],'b')\\nplt.plot(np.linspace(50,100,50),test,'r')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "  \"plt.plot(pred_dict['median'],'r')\\nplt.plot(pred_dict_arima['median'],'b')\\nplt.plot(np.linspace(50,100,50),test,'ko')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "  'plt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")',\n",
    "  'plt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "  'x2 = np.linspace(0,10,100)\\ntrain = np.sin(x2[0:50]) + 2*np.sin(x2[0:50]/2) + 3*np.sin(x2[0:50]/3)\\ntest = np.sin(x2[50:100]) + 2*np.sin(x2[50:100]/2) + 3*np.sin(x2[50:100]/3)',\n",
    "  \"plt.plot(np.linspace(50,100,50),test,'k')\",\n",
    "  'x2 = np.linspace(0,10,100)\\ntrain = np.sin(x2[0:50]) + 0.2*np.sin(x2[0:50]*10) + 0.03*np.sin(x2[0:50]*20)\\ntest = np.sin(x2[50:100]) + 0.2*np.sin(x2[50:100]*10) + 0.03*np.sin(x2[50:100]*20)',\n",
    "  \"plt.plot(np.linspace(50,100,50),test,'k')\",\n",
    "  'x2 = np.linspace(0,10,100)\\ntrain2 = np.sin(x2[0:50]) + 0.2*np.sin(x2[0:50]*10) + 0.03*np.sin(x2[0:50]*20)\\ntest2 = np.sin(x2[50:100]) + 0.2*np.sin(x2[50:100]*10) + 0.03*np.sin(x2[50:100]*20)',\n",
    "  \"plt.plot(np.linspace(50,100,50),test2,'k')\",\n",
    "  \"pred_dict_gpt_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "  'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "  'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "  'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'oscillator2.png\\')',\n",
    "  \"x3 = np.linspace(0,10,100)\\ntrain3 = np.sin(x3[0:50]) + 0.2*np.sin(x3[0:50]*10) + 0.1*np.sin(x3[0:50]*20)\\ntest3 = np.sin(x3[50:100]) + 0.2*np.sin(x3[50:100]*10) + 0.1*np.sin(x3[50:100]*20)\\nplt.plot(np.linspace(50,100,50),test3,'k')\",\n",
    "  \"fft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"time = np.linspace(50,100,50)\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"time = np.linspace(50,100,50)\\n\\n\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\n\\n# Calculate the squared amplitude or power\\nfft_power = np.abs(fft_result) ** 2\\n\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"time = np.linspace(50,100,50)\\n\\n\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\n\\n# Calculate the squared amplitude or power\\nfft_power = np.abs(fft_result) ** 2\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask])\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask])\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\n#plt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\n#plt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.show()',\n",
    "  'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.show()',\n",
    "  'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "  'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "  'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n# Normalize the power spectrum\\nfft_power = fft_power / np.max(fft_power)\\nfft_power_arima = fft_power_arima / np.max(fft_power_arima)\\nfft_power_gpt = fft_power_gpt / np.max(fft_power_gpt)\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "  'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n# Normalize the power spectrum\\nfft_power = fft_power / np.max(fft_power)\\nfft_power_arima = fft_power_arima / np.max(fft_power_arima)\\nfft_power_gpt = fft_power_gpt / np.max(fft_power_gpt)\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq >= 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j] + time_series[i-1]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j] + time_series[i-j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.05\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA], verbose=False, parallel=False)\\n\\n                                                    plt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA], verbose=False, parallel=False)\\n\\n                                                \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  'time_series',\n",
    "  'time_series[0:50]',\n",
    "  'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\n                                                \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(time_series[50:100],\\'k\\')                                         \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  \"pred_dict_gpt_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "  'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_gpt_ar[\\'median\\'],\\'r\\')\\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\n\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  'import statsmodels.api as sm',\n",
    "  'import statsmodels.api as sm\\nar_model = sm.tsa.AR(time_series[50:100])\\nar_results = ar_model.fit(maxlag=150)  # You can adjust the maximum number of lags as needed\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg((time_series[50:100], lags=150)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg((time_series[50:100], lags=50)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg(time_series[50:100], lags=50)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  'import statsmodels.api as sm\\n\\nres = sm.tsa.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  'import statsmodels.api as sm\\n\\nres = sm.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term',\n",
    "  'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=49).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients',\n",
    "  'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients',\n",
    "  \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'ko')\\nplt.plot(ar_coefficients_gpt,'ro')\\nplt.plot(ar_coefficients_arima,'ro')\",\n",
    "  \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'ko')\\nplt.plot(ar_coefficients_gpt,'ro')\\nplt.plot(ar_coefficients_arima,'bo')\",\n",
    "  \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "  \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=10).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "  \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=30).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=30).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=30).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "  \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\\nplt.savefig('ar-coeff.png')\",\n",
    "  'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_gpt_ar[\\'median\\'],\\'r\\')\\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\n\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\n\\nplt.savefig(\\'autoregressive.png\\')',\n",
    "  'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,\\'k-\\')\\nplt.plot(ar_coefficients_gpt,\\'r-\\')\\nplt.plot(ar_coefficients_arima,\\'b-\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\n\\nplt.savefig(\\'ar-coeff.png\\')',\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\n\\nplt.savefig('autoregressive.png')\",\n",
    "  \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\n\\nplt.savefig('autoregressive.png')\",\n",
    "  'def compute_rmse(actual_values, predicted_values):\\n    \"\"\"\\n    Compute Root Mean Square Error (RMSE) between two time series.\\n\\n    Args:\\n        actual_values (array-like): Actual values of the time series.\\n        predicted_values (array-like): Predicted values of the time series.\\n\\n    Returns:\\n        float: RMSE value.\\n    \"\"\"\\n    # Ensure both arrays have the same length\\n    if len(actual_values) != len(predicted_values):\\n        raise ValueError(\"Lengths of actual_values and predicted_values must be the same.\")\\n\\n    # Convert input arrays to numpy arrays\\n    actual_values = np.array(actual_values)\\n    predicted_values = np.array(predicted_values)\\n\\n    # Compute the squared error between actual and predicted values\\n    squared_error = (actual_values - predicted_values) ** 2\\n\\n    # Compute the mean of squared errors\\n    mean_squared_error = np.mean(squared_error)\\n\\n    # Compute the square root of mean squared error (RMSE)\\n    rmse = np.sqrt(mean_squared_error)\\n\\n    return rmse',\n",
    "  \"rmse_gpt = compute_rmse(time_series[50:100],pred_dict_gpt_ar['median'])\",\n",
    "  \"rmse_gpt = compute_rmse(time_series[50:100],pred_dict_gpt_ar['median'])\\nrmse_arima = compute_rmse(time_series[50:100],pred_dict_arima_ar['median'])\\nprint(rmse_gpt,rmse_arima)\",\n",
    "  \"rmse_gpt_sin = compute_rmse(test2,pred_dict_gpt_sum['median'])\\nrmse_arima_sin = compute_rmse(test2],pred_dict_arima_sum['median'])\\nprint(rmse_gpt_sin,rmse_arima_sin)\",\n",
    "  \"rmse_gpt_sin = compute_rmse(test2,pred_dict_gpt_sum['median'])\\nrmse_arima_sin = compute_rmse(test2,pred_dict_arima_sum['median'])\\nprint(rmse_gpt_sin,rmse_arima_sin)\",\n",
    "  'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,\\'k-\\')\\nplt.plot(ar_coefficients_gpt,\\'r-\\')\\nplt.plot(ar_coefficients_arima,\\'b-\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\n\\nplt.savefig(\\'ar-coeff.png\\')',\n",
    "  'variables_dict = globals()',\n",
    "  'variables_dict',\n",
    "  \"variables_dict['ar_coefficients]\",\n",
    "  \"variables_dict['ar_coefficients']\",\n",
    "  '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "  '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "  '# Specify the filename for the pickle file\\nimport pickle\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "  'import pickle\\n\\n# Assuming you have your variables already defined in memory in Jupyter Notebook\\n\\n# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Get all global variables\\nvariables_dict = globals()\\n\\n# Filter out objects that cannot be pickled (e.g., modules, functions)\\nfiltered_variables_dict = {key: value for key, value in variables_dict.items() if not callable(value)}\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the filtered variables dictionary into the pickle file\\n    pickle.dump(filtered_variables_dict, f)\\n\\nprint(\"Filtered variables stored in pickle file:\", pickle_filename)',\n",
    "  'variables_dict'],\n",
    " 'Out': {6: {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    "  7: [defaultdict(dict,\n",
    "               {'model': 'gpt-4',\n",
    "                'alpha': 0.3,\n",
    "                'basic': True,\n",
    "                'temp': 1.0,\n",
    "                'top_p': 0.8,\n",
    "                'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')})],\n",
    "  10: {'samples':          50        51        52        53        54        55        56  \\\n",
    "   0  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   1  0.942804  0.904312  0.856679  0.799904  0.736393  0.664221  0.585794   \n",
    "   2 -0.941842 -0.902388 -0.853792 -0.796055 -0.730619 -0.657966 -0.578096   \n",
    "   3  0.942804  0.904312  0.856679  0.799904  0.735430  0.663259  0.584351   \n",
    "   4 -0.943285 -0.905275 -0.857641 -0.801347 -0.737836 -0.666146 -0.587719   \n",
    "   5 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "   6 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "   7  0.942323  0.903350  0.855236  0.797979  0.733025  0.660372  0.580983   \n",
    "   8 -0.942804 -0.904794 -0.857160 -0.800866 -0.735912 -0.663740 -0.585313   \n",
    "   9  0.943285  0.905275  0.857160  0.800866  0.736874  0.665183  0.586757   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "   1  0.501113  0.411620  0.318278  ... -0.321164 -0.224454 -0.126301 -0.027185   \n",
    "   2 -0.492452 -0.401516 -0.306730  ...  0.286041  0.188368  0.088771 -0.011788   \n",
    "   3  0.499669  0.409695  0.315872  ... -0.321164 -0.224454 -0.125338 -0.025260   \n",
    "   4 -0.503518 -0.414507 -0.320683  ...  0.362543  0.279305  0.194142  0.108017   \n",
    "   5 -0.503037 -0.413544 -0.320202  ...  0.303843  0.207133  0.108498  0.008901   \n",
    "   6 -0.502556 -0.413063 -0.320202  ...  0.213388  0.113310  0.012750 -0.087809   \n",
    "   7  0.495820  0.405365  0.311060  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "   8 -0.500632 -0.410657 -0.316834  ...  0.310098  0.212426  0.112347  0.011788   \n",
    "   9  0.502556  0.413063  0.319721  ... -0.310579 -0.213869 -0.114272 -0.013713   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "   1  0.084441  0.185481  0.284116  0.284116  0.284116  0.284116  \n",
    "   2 -0.111866 -0.211463 -0.308655 -0.403921 -0.494858 -0.580502  \n",
    "   3  0.075780  0.175859  0.274012  0.369760  0.461659  0.549227  \n",
    "   4  0.021411 -0.065676 -0.151801 -0.236483 -0.319721 -0.401035  \n",
    "   5 -0.092139 -0.192218 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "   6 -0.187887 -0.285079 -0.379864 -0.470319 -0.556444 -0.636315  \n",
    "   7  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "   8 -0.088771 -0.188849 -0.286522 -0.382270 -0.472725 -0.559331  \n",
    "   9  0.087328  0.187406  0.187406  0.187406  0.187406  0.187406  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50    0.000241\n",
    "   51    0.000481\n",
    "   52    0.000481\n",
    "   53    0.000722\n",
    "   54    0.000962\n",
    "   55    0.000962\n",
    "   56    0.001203\n",
    "   57    0.001443\n",
    "   58    0.001684\n",
    "   59    0.001925\n",
    "   60    0.003368\n",
    "   61    0.003849\n",
    "   62    0.004571\n",
    "   63   -0.001925\n",
    "   64   -0.002406\n",
    "   65   -0.002887\n",
    "   66   -0.003368\n",
    "   67   -0.004090\n",
    "   68   -0.004571\n",
    "   69   -0.005052\n",
    "   70   -0.005533\n",
    "   71   -0.006014\n",
    "   72   -0.006255\n",
    "   73   -0.006977\n",
    "   74   -0.007217\n",
    "   75   -0.008661\n",
    "   76   -0.009382\n",
    "   77   -0.010104\n",
    "   78   -0.011066\n",
    "   79   -0.011547\n",
    "   80   -0.012269\n",
    "   81   -0.013231\n",
    "   82   -0.018524\n",
    "   83   -0.023336\n",
    "   84   -0.027906\n",
    "   85   -0.032477\n",
    "   86   -0.036567\n",
    "   87   -0.040176\n",
    "   88   -0.043303\n",
    "   89   -0.045468\n",
    "   90   -0.047393\n",
    "   91   -0.048596\n",
    "   92   -0.049077\n",
    "   93   -0.011066\n",
    "   94    0.048596\n",
    "   95    0.055091\n",
    "   96    0.017802\n",
    "   97   -0.024538\n",
    "   98   -0.066157\n",
    "   99   -0.106814\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'gpt-4'},\n",
    "   'completions_list': [['1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "     '1959, 1879, 1780, 1662, 1530, 1380, 1217, 1041, 855, 661, 459, 254, 47, -166, -376, -580, -780, -970, -1151, -1319, -1474, -1614, -1737, -1843, -1929, -1996, -2042, -2067, -2072, -2055, -2017, -1957, -1878, -1780, -1663, -1532, -1383, -1221, -1046, -860, -667, -466, -262, -56, 175, 385, 590',\n",
    "     '-1957, -1875, -1774, -1654, -1518, -1367, -1201, -1023, -834, -637, -428, -219, -7, 201, 409, 612, 809, 997, 1175, 1342, 1493, 1629, 1749, 1851, 1935, 1998, 2040, 2062, 2062, 2041, 1999, 1925, 1835, 1728, 1607, 1471, 1320, 1155, 977, 790, 594, 391, 184, -24, -232, -439, -641, -839, -1028, -1206, -1372, -1524, -1661, -1781, -1884, -1967, -2030, -2071, -2093, -',\n",
    "     '1959, 1879, 1780, 1662, 1528, 1378, 1214, 1038, 851, 656, 454, 247, 38, -172, -381, -585, -784, -974, -1155, -1323, -1478, -1618, -1741, -1847, -1933, -2000, -2046, -2071, -2076, -2059, -2021, -1961, -1882, -1784, -1667, -1534, -1385, -1222, -1047, -861, -667, -466, -260, -52, 157, 365, 569, 768, 959, 1141, 1310, 1466, 1607, 1731, 1838, 1925, 1993, 2040, 2066, 207',\n",
    "     '-1960, -1881, -1782, -1665, -1533, -1384, -1221, -1046, -861, -666, -465, -260, -53, 154, 360, 561, 757, 944, 1122, 1287, 1439, 1576, 1697, 1799, 1883, 1944, 1986, 2007, 2007, 1987, 1946, 1892, 1820, 1733, 1630, 1514, 1384, 1240, 1086, 923, 753, 580, 403, 224, 44, -136, -315, -491, -664, -833, -998, -1157, -1309, -1446, -1571, -1681, -1775, -1853, -1915, -1960',\n",
    "     '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -52, 157, 365, 567, 765, 954, 1134, 1301, 1455, 1594, 1716, 1820, 1904, 1970, 2015, 2039, 2043, 2025, 1986, 1926, 1847, 1748, 1631, 1498, 1349, 1186, 1011, 825, 631, 430, 225, 18, -191, -399, -601, -799, -988, -1168',\n",
    "     '-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -665, -464, -259, -51, 156, 363, 565, 762, 950, 1130, 1296, 1449, 1587, 1708, 1812, 1896, 1961, 2005, 2028, 2029, 2008, 1966, 1885, 1784, 1665, 1529, 1377, 1211, 1033, 844, 647, 443, 235, 26, -182, -390, -592, -789, -977, -1156, -1322, -1475, -1613, -1734, -1838, -1921, -1986, -2030, -2053, -2054, -',\n",
    "     '1958, 1877, 1777, 1658, 1523, 1372, 1207, 1030, 842, 646, 443, 236, 27, -182, -390, -593, -791, -980, -1160, -1327, -1481, -1620, -1742, -1847, -1932, -1998, -2043, -2067, -2071, -2053, -2014, -1952, -1871, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "     '-1959, -1880, -1781, -1664, -1529, -1379, -1216, -1040, -853, -658, -456, -248, -38, 170, 378, 581, 779, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2059, 2042, 2003, 1943, 1864, 1765, 1648, 1513, 1363, 1200, 1025, 839, 644, 441, 233, 24, -184, -392, -595, -794, -982, -1162, -1329, -1483, -1622, -1744, -1850, -1936, -2002, -2047, -2071, -',\n",
    "     '1960, 1881, 1781, 1664, 1531, 1382, 1219, 1044, 858, 664, 463, 256, 47, -162, -370, -573, -771, -961, -1141, -1308, -1462, -1601, -1723, -1828, -1913, -1980, -2025, -2049, -2053, -2035, -1997, -1940, -1861, -1762, -1645, -1512, -1363, -1200, -1025, -839, -645, -444, -237, -28, 181, 389']],\n",
    "   'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  11: [<matplotlib.lines.Line2D at 0x28ce64520>],\n",
    "  13: {'samples':          50        51        52        53        54        55        56  \\\n",
    "   0 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "   1  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   2  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   3  0.942804  0.904312  0.856198  0.799423  0.735430  0.663259  0.583870   \n",
    "   4  0.943285  0.905275  0.857641  0.801347  0.737355  0.665664  0.587238   \n",
    "   5 -0.943285 -0.905275 -0.857160 -0.800385 -0.736393 -0.664221 -0.585313   \n",
    "   6 -0.942804 -0.904312 -0.856679 -0.799904 -0.735912 -0.664221 -0.585794   \n",
    "   7 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "   8 -0.943285 -0.904794 -0.856679 -0.800385 -0.735912 -0.664221 -0.585313   \n",
    "   9 -0.943285 -0.904794 -0.857160 -0.800866 -0.735912 -0.664221 -0.584832   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0 -0.502556 -0.413063 -0.319721  ...  0.305768  0.209058  0.109461  0.009382   \n",
    "   1  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "   2  0.495339  0.404884  0.310579  ... -0.309136 -0.211463 -0.111866 -0.011307   \n",
    "   3  0.499188  0.408733  0.314910  ... -0.321164 -0.223492 -0.123895 -0.023336   \n",
    "   4  0.503037  0.413544  0.320202  ... -0.307211 -0.210501 -0.111866 -0.012269   \n",
    "   5 -0.500632 -0.410657 -0.316834  ...  0.286041  0.187887  0.087809 -0.012750   \n",
    "   6 -0.501113 -0.411139 -0.317796  ...  0.307692  0.210020  0.110423  0.009863   \n",
    "   7 -0.503037 -0.413544 -0.320202  ...  0.271125  0.174415  0.075299 -0.024779   \n",
    "   8 -0.501113 -0.411139 -0.317796  ...  0.301437  0.203765  0.104168  0.003609   \n",
    "   9 -0.500632 -0.410176 -0.316353  ...  0.307211  0.209539  0.109942  0.009382   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0 -0.091658 -0.191736 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "   1  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "   2  0.089734  0.189812  0.287484  0.382751  0.473687  0.560294  \n",
    "   3  0.077705  0.178264  0.276899  0.373128  0.465027  0.552595  \n",
    "   4  0.088771  0.188849  0.286522  0.381789  0.473206  0.560294  \n",
    "   5 -0.112829 -0.211944 -0.309136 -0.403921 -0.494377 -0.580502  \n",
    "   6 -0.091177 -0.191255 -0.288928 -0.384194 -0.475131 -0.561737  \n",
    "   7 -0.124857 -0.223492 -0.320202 -0.413544 -0.503037 -0.587238  \n",
    "   8 -0.098394 -0.198472 -0.296145 -0.391412 -0.482348 -0.568954  \n",
    "   9 -0.092139 -0.192218 -0.289890 -0.385157 -0.476093 -0.562699  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50   -0.943045\n",
    "   51   -0.904553\n",
    "   52   -0.856679\n",
    "   53   -0.800144\n",
    "   54   -0.735912\n",
    "   55   -0.664221\n",
    "   56   -0.585073\n",
    "   57   -0.500632\n",
    "   58   -0.410417\n",
    "   59   -0.316594\n",
    "   60   -0.219162\n",
    "   61   -0.119565\n",
    "   62   -0.019246\n",
    "   63    0.076502\n",
    "   64    0.176099\n",
    "   65    0.273290\n",
    "   66    0.368076\n",
    "   67    0.458531\n",
    "   68    0.544656\n",
    "   69    0.624526\n",
    "   70    0.698142\n",
    "   71    0.764540\n",
    "   72    0.822999\n",
    "   73    0.872557\n",
    "   74    0.912973\n",
    "   75    0.943526\n",
    "   76    0.964215\n",
    "   77    0.975041\n",
    "   78    0.975041\n",
    "   79    0.965418\n",
    "   80    0.945450\n",
    "   81    0.915379\n",
    "   82    0.875684\n",
    "   83    0.826607\n",
    "   84    0.768389\n",
    "   85    0.702713\n",
    "   86    0.629578\n",
    "   87    0.549949\n",
    "   88    0.464305\n",
    "   89    0.373369\n",
    "   90    0.278583\n",
    "   91    0.181151\n",
    "   92    0.081554\n",
    "   93   -0.010826\n",
    "   94   -0.091418\n",
    "   95   -0.191496\n",
    "   96   -0.289168\n",
    "   97   -0.384435\n",
    "   98   -0.475371\n",
    "   99   -0.561978\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'gpt-4'},\n",
    "   'completions_list': [['-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -664, -463, -256, -48, 161, 369, 572, 770, 959, 1139, 1306, 1460, 1599, 1721, 1826, 1911, 1977, 2022, 2046, 2050, 2032, 1993, 1933, 1852, 1752, 1635, 1502, 1353, 1190, 1015, 829, 635, 434, 227, 19, -190, -398, -601, -799, -988, -1168, -1335, -1489, -1628, -1750, -1855, -1940, -2006, -2051, -2075, -',\n",
    "     '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853',\n",
    "     '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 233, 24, -185, -393, -596, -794, -983, -1163, -1330, -1484, -1623, -1745, -1850, -1935, -2001, -2046, -2070, -2074, -2056, -2017, -1955, -1874, -1773, -1654, -1519, -1368, -1203, -1026, -838, -642, -439, -232, -23, 186, 394, 597, 795, 984, 1164, 1331, 1485, 1624, 1746, 1851, 1936, 2002, 2047, 2071, 207',\n",
    "     '1959, 1879, 1779, 1661, 1528, 1378, 1213, 1037, 849, 654, 451, 244, 35, -174, -383, -587, -786, -976, -1157, -1325, -1480, -1620, -1743, -1849, -1935, -2002, -2048, -2073, -2078, -2061, -2023, -1963, -1884, -1785, -1668, -1536, -1387, -1223, -1048, -861, -667, -464, -257, -48, 161, 370, 575, 775, 966, 1148, 1317, 1473, 1614, 1738, 1845, 1932, 2000, 2047, 2072, 207',\n",
    "     '1960, 1881, 1782, 1665, 1532, 1383, 1220, 1045, 859, 665, 464, 259, 52, -157, -365, -568, -766, -956, -1137, -1304, -1458, -1597, -1719, -1824, -1910, -1976, -2021, -2045, -2049, -2031, -1992, -1933, -1854, -1755, -1638, -1505, -1356, -1193, -1018, -832, -638, -437, -232, -25, 184, 392, 595, 793, 983, 1164, 1331, 1485, 1624, 1746, 1851, 1937, 2003, 2048, 2072, 207',\n",
    "     '-1960, -1881, -1781, -1663, -1530, -1380, -1216, -1040, -853, -658, -456, -249, -40, 168, 375, 577, 775, 963, 1142, 1308, 1461, 1599, 1720, 1824, 1909, 1974, 2018, 2041, 2043, 2023, 1982, 1919, 1837, 1735, 1615, 1479, 1327, 1161, 983, 792, 594, 390, 182, -26, -234, -440, -642, -839, -1027, -1206, -1371, -1523, -1661',\n",
    "     '-1959, -1879, -1780, -1662, -1529, -1380, -1217, -1041, -854, -660, -457, -250, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1938, 1858, 1759, 1641, 1508, 1359, 1196, 1020, 833, 639, 436, 229, 20, -189, -397, -600, -798, -987, -1167, -1334, -1488, -1627, -1749, -1854, -1939, -2005, -2050, -2074, -',\n",
    "     '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -51, 156, 362, 563, 759, 946, 1124, 1289, 1441, 1578, 1700, 1802, 1885, 1947, 1989, 2011, 2009, 1989, 1947, 1885, 1802, 1700, 1578, 1441, 1289, 1124, 946, 759, 563, 362, 156, -51, -259, -464, -665, -859, -1045, -1220, -1383, -1532, -1665, -1782, -1881, -1960, -2020, -2059, -2077, -',\n",
    "     '-1960, -1880, -1780, -1663, -1529, -1380, -1216, -1041, -854, -660, -458, -252, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1939, 1858, 1757, 1638, 1503, 1352, 1187, 1010, 822, 626, 423, 216, 7, -204, -412, -615, -813, -1002, -1182, -1349, -1503, -1642, -1764, -1869, -1954, -2020, -2065, -2089,',\n",
    "     '-1960, -1880, -1781, -1664, -1529, -1380, -1215, -1040, -852, -657, -454, -247, -39, 169, 377, 580, 778, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2058, 2040, 2001, 1941, 1861, 1762, 1645, 1510, 1361, 1196, 1021, 833, 638, 435, 228, 19, -191, -399, -602, -800, -989, -1169, -1336, -1490, -1629, -1751, -1856, -1941, -2007, -2052, -2076, -']],\n",
    "   'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  14: [<matplotlib.lines.Line2D at 0x28e598ac0>],\n",
    "  15: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  17: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  18: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  19: <matplotlib.legend.Legend at 0x28f18c790>,\n",
    "  22: [<matplotlib.lines.Line2D at 0x28f3fb1c0>],\n",
    "  24: [<matplotlib.lines.Line2D at 0x28f3bdf70>],\n",
    "  26: [<matplotlib.lines.Line2D at 0x28f4aaa30>],\n",
    "  31: [<matplotlib.lines.Line2D at 0x28f65f130>],\n",
    "  60: array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "          1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "         -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "          0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "         -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "          0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "          0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "          1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "         -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "          0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149,\n",
    "          0.18718621, -0.4757239 , -1.64344264, -0.09358268,  0.10309571,\n",
    "          0.095137  ,  1.06676763, -1.8428797 , -1.04016223, -0.1471965 ,\n",
    "          1.1094952 , -1.38843155, -1.34927948,  2.2983403 , -0.5684549 ,\n",
    "          0.74208654,  0.46162906,  1.62492308, -0.75288572, -0.6291802 ,\n",
    "          0.46314307,  0.64471457,  0.19379909, -1.41415266, -1.23427455,\n",
    "         -0.40777303,  0.81886616,  0.40483561, -0.5155421 , -0.566217  ,\n",
    "         -0.29358193,  0.88388512, -1.1597346 , -0.41722568,  0.55364882,\n",
    "          0.32269808, -1.18005105, -0.63975452,  1.24861017,  1.32987551,\n",
    "          0.75395216,  0.47690589,  0.29144071,  0.84784154,  0.82063337,\n",
    "          0.44373127, -1.11129098,  0.71013579,  0.89859217, -1.24352553]),\n",
    "  61: array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "          1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "         -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "          0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "         -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "          0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "          0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "          1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "         -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "          0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149]),\n",
    "  62: Text(24.00000000000002, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  63: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  64: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  66: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  78: array([ 0.42459049, -0.71090158,  0.28381361,  0.19212327, -0.10471756,\n",
    "          0.23711138, -0.25102066, -0.39702093, -0.19640616, -0.40924017,\n",
    "         -0.35815403,  0.14991523, -0.01944757,  0.11782569, -0.29788144,\n",
    "         -0.19526565, -0.48413894, -0.03631446, -0.47901333,  0.0322904 ]),\n",
    "  79: [<matplotlib.lines.Line2D at 0x29fe344c0>],\n",
    "  80: [<matplotlib.lines.Line2D at 0x2adb847c0>],\n",
    "  81: [<matplotlib.lines.Line2D at 0x2adc2b3d0>],\n",
    "  82: [<matplotlib.lines.Line2D at 0x29fe41e80>],\n",
    "  96: {...},\n",
    "  98: array([-0.57073806, -0.25504165, -0.43684139, -0.39442566, -0.3266803 ,\n",
    "         -0.09596204, -0.1837547 , -0.01177321, -0.12021627, -0.1537689 ,\n",
    "          0.06362805, -0.3066356 , -0.18471353, -0.14508358, -0.45184114,\n",
    "         -0.12185355,  0.1268503 , -0.33401473, -0.45442659,  0.04557276])},\n",
    " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x105a74f10>>,\n",
    " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x105a84c70>,\n",
    " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x105a84c70>,\n",
    " 'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
    " '_': array([-0.57073806, -0.25504165, -0.43684139, -0.39442566, -0.3266803 ,\n",
    "        -0.09596204, -0.1837547 , -0.01177321, -0.12021627, -0.1537689 ,\n",
    "         0.06362805, -0.3066356 , -0.18471353, -0.14508358, -0.45184114,\n",
    "        -0.12185355,  0.1268503 , -0.33401473, -0.45442659,  0.04557276]),\n",
    " '__': {...},\n",
    " '___': [<matplotlib.lines.Line2D at 0x29fe41e80>],\n",
    " '__session__': '/Users/rdey33/Downloads/llmtime/llmtime-dynamics/physics_demo.ipynb',\n",
    " '_i': 'import pickle\\n\\n# Assuming you have your variables already defined in memory in Jupyter Notebook\\n\\n# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Get all global variables\\nvariables_dict = globals()\\n\\n# Filter out objects that cannot be pickled (e.g., modules, functions)\\nfiltered_variables_dict = {key: value for key, value in variables_dict.items() if not callable(value)}\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the filtered variables dictionary into the pickle file\\n    pickle.dump(filtered_variables_dict, f)\\n\\nprint(\"Filtered variables stored in pickle file:\", pickle_filename)',\n",
    " '_ii': '# Specify the filename for the pickle file\\nimport pickle\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    " '_iii': '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    " '_i1': 'import os\\nos.environ[\\'OMP_NUM_THREADS\\'] = \\'4\\'\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\nimport openai\\n#openai.api_key = os.environ[\\'OPENAI_API_KEY\\']\\nopenai.api_key  = \\'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\\' #chandra2\\nopenai.api_base = os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\\nfrom data.serialize import SerializerSettings\\nfrom models.utils import grid_iter\\nfrom models.promptcast import get_promptcast_predictions_data\\nfrom models.darts import get_arima_predictions_data\\nfrom models.llmtime import get_llmtime_predictions_data\\nfrom data.small_context import get_datasets\\nfrom models.validation_likelihood_tuning import get_autotuned_predictions_data\\nimport logging\\nimport pickle',\n",
    " 'os': <module 'os' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/os.py'>,\n",
    " 'np': <module 'numpy' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/numpy/__init__.py'>,\n",
    " 'pd': <module 'pandas' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/pandas/__init__.py'>,\n",
    " 'plt': <module 'matplotlib.pyplot' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/matplotlib/pyplot.py'>,\n",
    " 'openai': <module 'openai' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/openai/__init__.py'>,\n",
    " 'SerializerSettings': data.serialize.SerializerSettings,\n",
    " 'grid_iter': models.utils.grid_iter,\n",
    " 'get_promptcast_predictions_data': <function models.promptcast.get_promptcast_predictions_data(train, test, model, settings, num_samples=10, temp=0.8, dataset_name='dataset', **kwargs)>,\n",
    " 'get_arima_predictions_data': <function models.darts.get_arima_predictions_data(train, test, p=12, d=1, q=0, num_samples=100, **kwargs)>,\n",
    " 'get_llmtime_predictions_data': <function models.llmtime.get_llmtime_predictions_data(train, test, model, settings, num_samples=10, temp=0.7, alpha=0.95, beta=0.3, basic=False, parallel=True, **kwargs)>,\n",
    " 'get_datasets': <function data.small_context.get_datasets(n=-1, testfrac=0.2)>,\n",
    " 'get_autotuned_predictions_data': <function models.validation_likelihood_tuning.get_autotuned_predictions_data(train, test, hypers, num_samples, get_predictions_fn, verbose=False, parallel=True, n_train=None, n_val=None)>,\n",
    " 'logging': <module 'logging' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/logging/__init__.py'>,\n",
    " 'pickle': <module 'pickle' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/pickle.py'>,\n",
    " '_i2': \"def plot_preds(train, test, pred_dict, model_name, show_samples=False):\\n    pred = pred_dict['median']\\n    pred = pd.Series(pred, index=test.index)\\n    plt.figure(figsize=(8, 6), dpi=100)\\n    plt.plot(train)\\n    plt.plot(test, label='Truth', color='black')\\n    plt.plot(pred, label=model_name, color='purple')\\n    # shade 90% confidence interval\\n    samples = pred_dict['samples']\\n    lower = np.quantile(samples, 0.05, axis=0)\\n    upper = np.quantile(samples, 0.95, axis=0)\\n    plt.fill_between(pred.index, lower, upper, alpha=0.3, color='purple')\\n    if show_samples:\\n        samples = pred_dict['samples']\\n        # convert df to numpy array\\n        samples = samples.values if isinstance(samples, pd.DataFrame) else samples\\n        for i in range(min(10, samples.shape[0])):\\n            plt.plot(pred.index, samples[i], color='purple', alpha=0.3, linewidth=1)\\n    plt.legend(loc='upper left')\\n    if 'NLL/D' in pred_dict:\\n        nll = pred_dict['NLL/D']\\n        if nll is not None:\\n            plt.text(0.03, 0.85, f'NLL/D: {nll:.2f}', transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.5))\\n    plt.show()\\n\\n\\n\\ngpt4_hypers = dict(\\n    alpha=0.3,\\n    basic=True,\\n    temp=1.0,\\n    top_p=0.8,\\n    settings=SerializerSettings(base=10, prec=3, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\\n)\\n\\ngpt3_hypers = dict(\\n    temp=0.7,\\n    alpha=0.95,\\n    beta=0.3,\\n    basic=False,\\n    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True)\\n)\\n\\n\\npromptcast_hypers = dict(\\n    temp=0.7,\\n    settings=SerializerSettings(base=10, prec=0, signed=True, \\n                                time_sep=', ',\\n                                bit_sep='',\\n                                plus_sign='',\\n                                minus_sign='-',\\n                                half_bin_correction=False,\\n                                decimal_point='')\\n)\\n\\narima_hypers = dict(p=[12,30], d=[1,2], q=[0])\\n\\nmodel_hypers = {\\n    #'LLMTime GPT-3.5': {'model': 'gpt-3.5-turbo-instruct', **gpt3_hypers},\\n    'LLMTime GPT-4': {'model': 'gpt-4', **gpt4_hypers},\\n    #'LLMTime GPT-3': {'model': 'text-davinci-003', **gpt3_hypers},\\n    #'PromptCast GPT-3': {'model': 'text-davinci-003', **promptcast_hypers},\\n    'ARIMA': arima_hypers,\\n    \\n}\\n\\nmodel_predict_fns = {\\n\\n    #'LLMTime GPT-3': get_llmtime_predictions_data,\\n    #'LLMTime GPT-3.5': get_llmtime_predictions_data,\\n    'LLMTime GPT-4': get_llmtime_predictions_data,\\n    #'PromptCast GPT-3': get_promptcast_predictions_data,\\n    'ARIMA': get_arima_predictions_data,\\n}\\n\\nmodel_names = list(model_predict_fns.keys())\",\n",
    " 'plot_preds': <function __main__.plot_preds(train, test, pred_dict, model_name, show_samples=False)>,\n",
    " 'gpt4_hypers': {'alpha': 0.3,\n",
    "  'basic': True,\n",
    "  'temp': 1.0,\n",
    "  'top_p': 0.8,\n",
    "  'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    " 'gpt3_hypers': {'temp': 0.7,\n",
    "  'alpha': 0.95,\n",
    "  'beta': 0.3,\n",
    "  'basic': False,\n",
    "  'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=' ,', bit_sep=' ', plus_sign='', minus_sign=' -', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    " 'promptcast_hypers': {'temp': 0.7,\n",
    "  'settings': SerializerSettings(base=10, prec=0, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=False, decimal_point='', missing_str=' Nan')},\n",
    " 'arima_hypers': {'p': [12, 30], 'd': [1, 2], 'q': [0]},\n",
    " 'model_hypers': {'LLMTime GPT-4': {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    "  'ARIMA': {'p': [12, 30], 'd': [1, 2], 'q': [0]}},\n",
    " 'model_predict_fns': {'LLMTime GPT-4': <function models.llmtime.get_llmtime_predictions_data(train, test, model, settings, num_samples=10, temp=0.7, alpha=0.95, beta=0.3, basic=False, parallel=True, **kwargs)>,\n",
    "  'ARIMA': <function models.darts.get_arima_predictions_data(train, test, p=12, d=1, q=0, num_samples=100, **kwargs)>},\n",
    " 'model_names': ['LLMTime GPT-4', 'ARIMA'],\n",
    " '_i3': \"def print_full(x):\\n    pd.set_option('display.max_rows', len(x))\\n    print(x)\\n    pd.reset_option('display.max_rows')\",\n",
    " 'print_full': <function __main__.print_full(x)>,\n",
    " '_i4': 'x = np.linspace(0,10,100)\\ntrain = np.sin(x[0:50])\\ntest = np.sin(x[50:100])',\n",
    " 'x': array([ 0.        ,  0.1010101 ,  0.2020202 ,  0.3030303 ,  0.4040404 ,\n",
    "         0.50505051,  0.60606061,  0.70707071,  0.80808081,  0.90909091,\n",
    "         1.01010101,  1.11111111,  1.21212121,  1.31313131,  1.41414141,\n",
    "         1.51515152,  1.61616162,  1.71717172,  1.81818182,  1.91919192,\n",
    "         2.02020202,  2.12121212,  2.22222222,  2.32323232,  2.42424242,\n",
    "         2.52525253,  2.62626263,  2.72727273,  2.82828283,  2.92929293,\n",
    "         3.03030303,  3.13131313,  3.23232323,  3.33333333,  3.43434343,\n",
    "         3.53535354,  3.63636364,  3.73737374,  3.83838384,  3.93939394,\n",
    "         4.04040404,  4.14141414,  4.24242424,  4.34343434,  4.44444444,\n",
    "         4.54545455,  4.64646465,  4.74747475,  4.84848485,  4.94949495,\n",
    "         5.05050505,  5.15151515,  5.25252525,  5.35353535,  5.45454545,\n",
    "         5.55555556,  5.65656566,  5.75757576,  5.85858586,  5.95959596,\n",
    "         6.06060606,  6.16161616,  6.26262626,  6.36363636,  6.46464646,\n",
    "         6.56565657,  6.66666667,  6.76767677,  6.86868687,  6.96969697,\n",
    "         7.07070707,  7.17171717,  7.27272727,  7.37373737,  7.47474747,\n",
    "         7.57575758,  7.67676768,  7.77777778,  7.87878788,  7.97979798,\n",
    "         8.08080808,  8.18181818,  8.28282828,  8.38383838,  8.48484848,\n",
    "         8.58585859,  8.68686869,  8.78787879,  8.88888889,  8.98989899,\n",
    "         9.09090909,  9.19191919,  9.29292929,  9.39393939,  9.49494949,\n",
    "         9.5959596 ,  9.6969697 ,  9.7979798 ,  9.8989899 , 10.        ]),\n",
    " 'train': array([ 0.        ,  0.2972367 ,  0.35731232,  0.31400343,  0.26585066,\n",
    "         0.27639963,  0.51256688,  0.8213306 ,  0.904692  ,  0.83590927,\n",
    "         0.75100161,  0.69065491,  0.8269244 ,  1.10119197,  1.18749806,\n",
    "         1.07717744,  0.93495622,  0.79682455,  0.81654052,  1.02603832,\n",
    "         1.10864503,  0.96282708,  0.76279164,  0.55916882,  0.47259406,\n",
    "         0.60907063,  0.69685163,  0.54379641,  0.3070198 ,  0.06723   ,\n",
    "        -0.09212802, -0.01636787,  0.09607604, -0.02163259, -0.2585526 ,\n",
    "        -0.49658592, -0.68292178, -0.64326164, -0.48587393, -0.52472469,\n",
    "        -0.72099784, -0.92253453, -1.09233244, -1.06357349, -0.851197  ,\n",
    "        -0.78119449, -0.90437415, -1.04875937, -1.17414227, -1.14131212]),\n",
    " 'test': array([-0.88209427, -0.6973774 , -0.73270271, -0.81938345, -0.89577425,\n",
    "        -0.86009574, -0.58199325, -0.30401812, -0.25741528, -0.304764  ,\n",
    "        -0.35037054, -0.32835171, -0.0733774 ,  0.25444065,  0.36049572,\n",
    "         0.32328515,  0.27583927,  0.25965338,  0.44691271,  0.77132079,\n",
    "         0.90728793,  0.85243785,  0.76933234,  0.69306657,  0.7788732 ,\n",
    "         1.05163056,  1.19205516,  1.10521015,  0.96486774,  0.81934952,\n",
    "         0.79155354,  0.98211495,  1.11423813,  1.0018416 ,  0.80394875,\n",
    "         0.59821144,  0.47047521,  0.57244203,  0.69909477,  0.58828182,\n",
    "         0.35534332,  0.11544319, -0.07670492, -0.04722262,  0.08857259,\n",
    "         0.01931833, -0.20967662, -0.44819378, -0.65833188, -0.67149316]),\n",
    " '_i5': \"for model in model_names: # GPT-4 takes a about a minute to run\\n    model_hypers[model].update({'dataset_name': ds_name}) # for promptcast\\n    hypers = list(grid_iter(model_hypers[model]))\\n    num_samples = 10\\n    pred_dict = get_autotuned_predictions_data(train, test, hypers, num_samples, model_predict_fns[model], verbose=False, parallel=False)\\n    out[model] = pred_dict\\n    plot_preds(train, test, pred_dict, model, show_samples=True)\",\n",
    " 'model': 'LLMTime GPT-4',\n",
    " '_i6': \"model_hypers['LLMTime GPT-4']\",\n",
    " '_6': {'model': 'gpt-4',\n",
    "  'alpha': 0.3,\n",
    "  'basic': True,\n",
    "  'temp': 1.0,\n",
    "  'top_p': 0.8,\n",
    "  'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    " '_i7': \"hypers = list(grid_iter(model_hypers['LLMTime GPT-4']))\\nhypers\",\n",
    " 'hypers': [defaultdict(dict,\n",
    "              {'model': 'gpt-4',\n",
    "               'alpha': 0.3,\n",
    "               'basic': True,\n",
    "               'temp': 1.0,\n",
    "               'top_p': 0.8,\n",
    "               'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')})],\n",
    " '_7': [defaultdict(dict,\n",
    "              {'model': 'gpt-4',\n",
    "               'alpha': 0.3,\n",
    "               'basic': True,\n",
    "               'temp': 1.0,\n",
    "               'top_p': 0.8,\n",
    "               'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')})],\n",
    " '_i8': \"import matplotlib.pyplot as plt\\nplt.plot(train,'o')\\nplt.show()\",\n",
    " '_i9': \"pred_dict = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    " 'pred_dict': {'samples':          50        51        52        53        54        55        56  \\\n",
    "  0 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "  1  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "  2  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "  3  0.942804  0.904312  0.856198  0.799423  0.735430  0.663259  0.583870   \n",
    "  4  0.943285  0.905275  0.857641  0.801347  0.737355  0.665664  0.587238   \n",
    "  5 -0.943285 -0.905275 -0.857160 -0.800385 -0.736393 -0.664221 -0.585313   \n",
    "  6 -0.942804 -0.904312 -0.856679 -0.799904 -0.735912 -0.664221 -0.585794   \n",
    "  7 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "  8 -0.943285 -0.904794 -0.856679 -0.800385 -0.735912 -0.664221 -0.585313   \n",
    "  9 -0.943285 -0.904794 -0.857160 -0.800866 -0.735912 -0.664221 -0.584832   \n",
    "  \n",
    "           57        58        59  ...        90        91        92        93  \\\n",
    "  0 -0.502556 -0.413063 -0.319721  ...  0.305768  0.209058  0.109461  0.009382   \n",
    "  1  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "  2  0.495339  0.404884  0.310579  ... -0.309136 -0.211463 -0.111866 -0.011307   \n",
    "  3  0.499188  0.408733  0.314910  ... -0.321164 -0.223492 -0.123895 -0.023336   \n",
    "  4  0.503037  0.413544  0.320202  ... -0.307211 -0.210501 -0.111866 -0.012269   \n",
    "  5 -0.500632 -0.410657 -0.316834  ...  0.286041  0.187887  0.087809 -0.012750   \n",
    "  6 -0.501113 -0.411139 -0.317796  ...  0.307692  0.210020  0.110423  0.009863   \n",
    "  7 -0.503037 -0.413544 -0.320202  ...  0.271125  0.174415  0.075299 -0.024779   \n",
    "  8 -0.501113 -0.411139 -0.317796  ...  0.301437  0.203765  0.104168  0.003609   \n",
    "  9 -0.500632 -0.410176 -0.316353  ...  0.307211  0.209539  0.109942  0.009382   \n",
    "  \n",
    "           94        95        96        97        98        99  \n",
    "  0 -0.091658 -0.191736 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "  1  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "  2  0.089734  0.189812  0.287484  0.382751  0.473687  0.560294  \n",
    "  3  0.077705  0.178264  0.276899  0.373128  0.465027  0.552595  \n",
    "  4  0.088771  0.188849  0.286522  0.381789  0.473206  0.560294  \n",
    "  5 -0.112829 -0.211944 -0.309136 -0.403921 -0.494377 -0.580502  \n",
    "  6 -0.091177 -0.191255 -0.288928 -0.384194 -0.475131 -0.561737  \n",
    "  7 -0.124857 -0.223492 -0.320202 -0.413544 -0.503037 -0.587238  \n",
    "  8 -0.098394 -0.198472 -0.296145 -0.391412 -0.482348 -0.568954  \n",
    "  9 -0.092139 -0.192218 -0.289890 -0.385157 -0.476093 -0.562699  \n",
    "  \n",
    "  [10 rows x 50 columns],\n",
    "  'median': 50   -0.943045\n",
    "  51   -0.904553\n",
    "  52   -0.856679\n",
    "  53   -0.800144\n",
    "  54   -0.735912\n",
    "  55   -0.664221\n",
    "  56   -0.585073\n",
    "  57   -0.500632\n",
    "  58   -0.410417\n",
    "  59   -0.316594\n",
    "  60   -0.219162\n",
    "  61   -0.119565\n",
    "  62   -0.019246\n",
    "  63    0.076502\n",
    "  64    0.176099\n",
    "  65    0.273290\n",
    "  66    0.368076\n",
    "  67    0.458531\n",
    "  68    0.544656\n",
    "  69    0.624526\n",
    "  70    0.698142\n",
    "  71    0.764540\n",
    "  72    0.822999\n",
    "  73    0.872557\n",
    "  74    0.912973\n",
    "  75    0.943526\n",
    "  76    0.964215\n",
    "  77    0.975041\n",
    "  78    0.975041\n",
    "  79    0.965418\n",
    "  80    0.945450\n",
    "  81    0.915379\n",
    "  82    0.875684\n",
    "  83    0.826607\n",
    "  84    0.768389\n",
    "  85    0.702713\n",
    "  86    0.629578\n",
    "  87    0.549949\n",
    "  88    0.464305\n",
    "  89    0.373369\n",
    "  90    0.278583\n",
    "  91    0.181151\n",
    "  92    0.081554\n",
    "  93   -0.010826\n",
    "  94   -0.091418\n",
    "  95   -0.191496\n",
    "  96   -0.289168\n",
    "  97   -0.384435\n",
    "  98   -0.475371\n",
    "  99   -0.561978\n",
    "  dtype: float64,\n",
    "  'info': {'Method': 'gpt-4'},\n",
    "  'completions_list': [['-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -664, -463, -256, -48, 161, 369, 572, 770, 959, 1139, 1306, 1460, 1599, 1721, 1826, 1911, 1977, 2022, 2046, 2050, 2032, 1993, 1933, 1852, 1752, 1635, 1502, 1353, 1190, 1015, 829, 635, 434, 227, 19, -190, -398, -601, -799, -988, -1168, -1335, -1489, -1628, -1750, -1855, -1940, -2006, -2051, -2075, -',\n",
    "    '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853',\n",
    "    '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 233, 24, -185, -393, -596, -794, -983, -1163, -1330, -1484, -1623, -1745, -1850, -1935, -2001, -2046, -2070, -2074, -2056, -2017, -1955, -1874, -1773, -1654, -1519, -1368, -1203, -1026, -838, -642, -439, -232, -23, 186, 394, 597, 795, 984, 1164, 1331, 1485, 1624, 1746, 1851, 1936, 2002, 2047, 2071, 207',\n",
    "    '1959, 1879, 1779, 1661, 1528, 1378, 1213, 1037, 849, 654, 451, 244, 35, -174, -383, -587, -786, -976, -1157, -1325, -1480, -1620, -1743, -1849, -1935, -2002, -2048, -2073, -2078, -2061, -2023, -1963, -1884, -1785, -1668, -1536, -1387, -1223, -1048, -861, -667, -464, -257, -48, 161, 370, 575, 775, 966, 1148, 1317, 1473, 1614, 1738, 1845, 1932, 2000, 2047, 2072, 207',\n",
    "    '1960, 1881, 1782, 1665, 1532, 1383, 1220, 1045, 859, 665, 464, 259, 52, -157, -365, -568, -766, -956, -1137, -1304, -1458, -1597, -1719, -1824, -1910, -1976, -2021, -2045, -2049, -2031, -1992, -1933, -1854, -1755, -1638, -1505, -1356, -1193, -1018, -832, -638, -437, -232, -25, 184, 392, 595, 793, 983, 1164, 1331, 1485, 1624, 1746, 1851, 1937, 2003, 2048, 2072, 207',\n",
    "    '-1960, -1881, -1781, -1663, -1530, -1380, -1216, -1040, -853, -658, -456, -249, -40, 168, 375, 577, 775, 963, 1142, 1308, 1461, 1599, 1720, 1824, 1909, 1974, 2018, 2041, 2043, 2023, 1982, 1919, 1837, 1735, 1615, 1479, 1327, 1161, 983, 792, 594, 390, 182, -26, -234, -440, -642, -839, -1027, -1206, -1371, -1523, -1661',\n",
    "    '-1959, -1879, -1780, -1662, -1529, -1380, -1217, -1041, -854, -660, -457, -250, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1938, 1858, 1759, 1641, 1508, 1359, 1196, 1020, 833, 639, 436, 229, 20, -189, -397, -600, -798, -987, -1167, -1334, -1488, -1627, -1749, -1854, -1939, -2005, -2050, -2074, -',\n",
    "    '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -51, 156, 362, 563, 759, 946, 1124, 1289, 1441, 1578, 1700, 1802, 1885, 1947, 1989, 2011, 2009, 1989, 1947, 1885, 1802, 1700, 1578, 1441, 1289, 1124, 946, 759, 563, 362, 156, -51, -259, -464, -665, -859, -1045, -1220, -1383, -1532, -1665, -1782, -1881, -1960, -2020, -2059, -2077, -',\n",
    "    '-1960, -1880, -1780, -1663, -1529, -1380, -1216, -1041, -854, -660, -458, -252, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1939, 1858, 1757, 1638, 1503, 1352, 1187, 1010, 822, 626, 423, 216, 7, -204, -412, -615, -813, -1002, -1182, -1349, -1503, -1642, -1764, -1869, -1954, -2020, -2065, -2089,',\n",
    "    '-1960, -1880, -1781, -1664, -1529, -1380, -1215, -1040, -852, -657, -454, -247, -39, 169, 377, 580, 778, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2058, 2040, 2001, 1941, 1861, 1762, 1645, 1510, 1361, 1196, 1021, 833, 638, 435, 228, 19, -191, -399, -602, -800, -989, -1169, -1336, -1490, -1629, -1751, -1856, -1941, -2007, -2052, -2076, -']],\n",
    "  'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "  'best_hyper': {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': {'base': 10,\n",
    "    'prec': 3,\n",
    "    'signed': True,\n",
    "    'fixed_length': False,\n",
    "    'max_val': 10000000.0,\n",
    "    'time_sep': ', ',\n",
    "    'bit_sep': '',\n",
    "    'plus_sign': '',\n",
    "    'minus_sign': '-',\n",
    "    'half_bin_correction': True,\n",
    "    'decimal_point': '',\n",
    "    'missing_str': ' Nan'}}},\n",
    " '_i10': 'pred_dict',\n",
    " '_10': {'samples':          50        51        52        53        54        55        56  \\\n",
    "  0  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "  1  0.942804  0.904312  0.856679  0.799904  0.736393  0.664221  0.585794   \n",
    "  2 -0.941842 -0.902388 -0.853792 -0.796055 -0.730619 -0.657966 -0.578096   \n",
    "  3  0.942804  0.904312  0.856679  0.799904  0.735430  0.663259  0.584351   \n",
    "  4 -0.943285 -0.905275 -0.857641 -0.801347 -0.737836 -0.666146 -0.587719   \n",
    "  5 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "  6 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "  7  0.942323  0.903350  0.855236  0.797979  0.733025  0.660372  0.580983   \n",
    "  8 -0.942804 -0.904794 -0.857160 -0.800866 -0.735912 -0.663740 -0.585313   \n",
    "  9  0.943285  0.905275  0.857160  0.800866  0.736874  0.665183  0.586757   \n",
    "  \n",
    "           57        58        59  ...        90        91        92        93  \\\n",
    "  0  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "  1  0.501113  0.411620  0.318278  ... -0.321164 -0.224454 -0.126301 -0.027185   \n",
    "  2 -0.492452 -0.401516 -0.306730  ...  0.286041  0.188368  0.088771 -0.011788   \n",
    "  3  0.499669  0.409695  0.315872  ... -0.321164 -0.224454 -0.125338 -0.025260   \n",
    "  4 -0.503518 -0.414507 -0.320683  ...  0.362543  0.279305  0.194142  0.108017   \n",
    "  5 -0.503037 -0.413544 -0.320202  ...  0.303843  0.207133  0.108498  0.008901   \n",
    "  6 -0.502556 -0.413063 -0.320202  ...  0.213388  0.113310  0.012750 -0.087809   \n",
    "  7  0.495820  0.405365  0.311060  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "  8 -0.500632 -0.410657 -0.316834  ...  0.310098  0.212426  0.112347  0.011788   \n",
    "  9  0.502556  0.413063  0.319721  ... -0.310579 -0.213869 -0.114272 -0.013713   \n",
    "  \n",
    "           94        95        96        97        98        99  \n",
    "  0  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "  1  0.084441  0.185481  0.284116  0.284116  0.284116  0.284116  \n",
    "  2 -0.111866 -0.211463 -0.308655 -0.403921 -0.494858 -0.580502  \n",
    "  3  0.075780  0.175859  0.274012  0.369760  0.461659  0.549227  \n",
    "  4  0.021411 -0.065676 -0.151801 -0.236483 -0.319721 -0.401035  \n",
    "  5 -0.092139 -0.192218 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "  6 -0.187887 -0.285079 -0.379864 -0.470319 -0.556444 -0.636315  \n",
    "  7  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "  8 -0.088771 -0.188849 -0.286522 -0.382270 -0.472725 -0.559331  \n",
    "  9  0.087328  0.187406  0.187406  0.187406  0.187406  0.187406  \n",
    "  \n",
    "  [10 rows x 50 columns],\n",
    "  'median': 50    0.000241\n",
    "  51    0.000481\n",
    "  52    0.000481\n",
    "  53    0.000722\n",
    "  54    0.000962\n",
    "  55    0.000962\n",
    "  56    0.001203\n",
    "  57    0.001443\n",
    "  58    0.001684\n",
    "  59    0.001925\n",
    "  60    0.003368\n",
    "  61    0.003849\n",
    "  62    0.004571\n",
    "  63   -0.001925\n",
    "  64   -0.002406\n",
    "  65   -0.002887\n",
    "  66   -0.003368\n",
    "  67   -0.004090\n",
    "  68   -0.004571\n",
    "  69   -0.005052\n",
    "  70   -0.005533\n",
    "  71   -0.006014\n",
    "  72   -0.006255\n",
    "  73   -0.006977\n",
    "  74   -0.007217\n",
    "  75   -0.008661\n",
    "  76   -0.009382\n",
    "  77   -0.010104\n",
    "  78   -0.011066\n",
    "  79   -0.011547\n",
    "  80   -0.012269\n",
    "  81   -0.013231\n",
    "  82   -0.018524\n",
    "  83   -0.023336\n",
    "  84   -0.027906\n",
    "  85   -0.032477\n",
    "  86   -0.036567\n",
    "  87   -0.040176\n",
    "  88   -0.043303\n",
    "  89   -0.045468\n",
    "  90   -0.047393\n",
    "  91   -0.048596\n",
    "  92   -0.049077\n",
    "  93   -0.011066\n",
    "  94    0.048596\n",
    "  95    0.055091\n",
    "  96    0.017802\n",
    "  97   -0.024538\n",
    "  98   -0.066157\n",
    "  99   -0.106814\n",
    "  dtype: float64,\n",
    "  'info': {'Method': 'gpt-4'},\n",
    "  'completions_list': [['1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "    '1959, 1879, 1780, 1662, 1530, 1380, 1217, 1041, 855, 661, 459, 254, 47, -166, -376, -580, -780, -970, -1151, -1319, -1474, -1614, -1737, -1843, -1929, -1996, -2042, -2067, -2072, -2055, -2017, -1957, -1878, -1780, -1663, -1532, -1383, -1221, -1046, -860, -667, -466, -262, -56, 175, 385, 590',\n",
    "    '-1957, -1875, -1774, -1654, -1518, -1367, -1201, -1023, -834, -637, -428, -219, -7, 201, 409, 612, 809, 997, 1175, 1342, 1493, 1629, 1749, 1851, 1935, 1998, 2040, 2062, 2062, 2041, 1999, 1925, 1835, 1728, 1607, 1471, 1320, 1155, 977, 790, 594, 391, 184, -24, -232, -439, -641, -839, -1028, -1206, -1372, -1524, -1661, -1781, -1884, -1967, -2030, -2071, -2093, -',\n",
    "    '1959, 1879, 1780, 1662, 1528, 1378, 1214, 1038, 851, 656, 454, 247, 38, -172, -381, -585, -784, -974, -1155, -1323, -1478, -1618, -1741, -1847, -1933, -2000, -2046, -2071, -2076, -2059, -2021, -1961, -1882, -1784, -1667, -1534, -1385, -1222, -1047, -861, -667, -466, -260, -52, 157, 365, 569, 768, 959, 1141, 1310, 1466, 1607, 1731, 1838, 1925, 1993, 2040, 2066, 207',\n",
    "    '-1960, -1881, -1782, -1665, -1533, -1384, -1221, -1046, -861, -666, -465, -260, -53, 154, 360, 561, 757, 944, 1122, 1287, 1439, 1576, 1697, 1799, 1883, 1944, 1986, 2007, 2007, 1987, 1946, 1892, 1820, 1733, 1630, 1514, 1384, 1240, 1086, 923, 753, 580, 403, 224, 44, -136, -315, -491, -664, -833, -998, -1157, -1309, -1446, -1571, -1681, -1775, -1853, -1915, -1960',\n",
    "    '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -52, 157, 365, 567, 765, 954, 1134, 1301, 1455, 1594, 1716, 1820, 1904, 1970, 2015, 2039, 2043, 2025, 1986, 1926, 1847, 1748, 1631, 1498, 1349, 1186, 1011, 825, 631, 430, 225, 18, -191, -399, -601, -799, -988, -1168',\n",
    "    '-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -665, -464, -259, -51, 156, 363, 565, 762, 950, 1130, 1296, 1449, 1587, 1708, 1812, 1896, 1961, 2005, 2028, 2029, 2008, 1966, 1885, 1784, 1665, 1529, 1377, 1211, 1033, 844, 647, 443, 235, 26, -182, -390, -592, -789, -977, -1156, -1322, -1475, -1613, -1734, -1838, -1921, -1986, -2030, -2053, -2054, -',\n",
    "    '1958, 1877, 1777, 1658, 1523, 1372, 1207, 1030, 842, 646, 443, 236, 27, -182, -390, -593, -791, -980, -1160, -1327, -1481, -1620, -1742, -1847, -1932, -1998, -2043, -2067, -2071, -2053, -2014, -1952, -1871, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "    '-1959, -1880, -1781, -1664, -1529, -1379, -1216, -1040, -853, -658, -456, -248, -38, 170, 378, 581, 779, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2059, 2042, 2003, 1943, 1864, 1765, 1648, 1513, 1363, 1200, 1025, 839, 644, 441, 233, 24, -184, -392, -595, -794, -982, -1162, -1329, -1483, -1622, -1744, -1850, -1936, -2002, -2047, -2071, -',\n",
    "    '1960, 1881, 1781, 1664, 1531, 1382, 1219, 1044, 858, 664, 463, 256, 47, -162, -370, -573, -771, -961, -1141, -1308, -1462, -1601, -1723, -1828, -1913, -1980, -2025, -2049, -2053, -2035, -1997, -1940, -1861, -1762, -1645, -1512, -1363, -1200, -1025, -839, -645, -444, -237, -28, 181, 389']],\n",
    "  'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "  'best_hyper': {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': {'base': 10,\n",
    "    'prec': 3,\n",
    "    'signed': True,\n",
    "    'fixed_length': False,\n",
    "    'max_val': 10000000.0,\n",
    "    'time_sep': ', ',\n",
    "    'bit_sep': '',\n",
    "    'plus_sign': '',\n",
    "    'minus_sign': '-',\n",
    "    'half_bin_correction': True,\n",
    "    'decimal_point': '',\n",
    "    'missing_str': ' Nan'}}},\n",
    " '_i11': \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\",\n",
    " '_11': [<matplotlib.lines.Line2D at 0x28ce64520>],\n",
    " '_i12': \"pred_dict = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    " '_i13': 'pred_dict',\n",
    " '_13': {'samples':          50        51        52        53        54        55        56  \\\n",
    "  0 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "  1  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "  2  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "  3  0.942804  0.904312  0.856198  0.799423  0.735430  0.663259  0.583870   \n",
    "  4  0.943285  0.905275  0.857641  0.801347  0.737355  0.665664  0.587238   \n",
    "  5 -0.943285 -0.905275 -0.857160 -0.800385 -0.736393 -0.664221 -0.585313   \n",
    "  6 -0.942804 -0.904312 -0.856679 -0.799904 -0.735912 -0.664221 -0.585794   \n",
    "  7 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "  8 -0.943285 -0.904794 -0.856679 -0.800385 -0.735912 -0.664221 -0.585313   \n",
    "  9 -0.943285 -0.904794 -0.857160 -0.800866 -0.735912 -0.664221 -0.584832   \n",
    "  \n",
    "           57        58        59  ...        90        91        92        93  \\\n",
    "  0 -0.502556 -0.413063 -0.319721  ...  0.305768  0.209058  0.109461  0.009382   \n",
    "  1  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "  2  0.495339  0.404884  0.310579  ... -0.309136 -0.211463 -0.111866 -0.011307   \n",
    "  3  0.499188  0.408733  0.314910  ... -0.321164 -0.223492 -0.123895 -0.023336   \n",
    "  4  0.503037  0.413544  0.320202  ... -0.307211 -0.210501 -0.111866 -0.012269   \n",
    "  5 -0.500632 -0.410657 -0.316834  ...  0.286041  0.187887  0.087809 -0.012750   \n",
    "  6 -0.501113 -0.411139 -0.317796  ...  0.307692  0.210020  0.110423  0.009863   \n",
    "  7 -0.503037 -0.413544 -0.320202  ...  0.271125  0.174415  0.075299 -0.024779   \n",
    "  8 -0.501113 -0.411139 -0.317796  ...  0.301437  0.203765  0.104168  0.003609   \n",
    "  9 -0.500632 -0.410176 -0.316353  ...  0.307211  0.209539  0.109942  0.009382   \n",
    "  \n",
    "           94        95        96        97        98        99  \n",
    "  0 -0.091658 -0.191736 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "  1  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "  2  0.089734  0.189812  0.287484  0.382751  0.473687  0.560294  \n",
    "  3  0.077705  0.178264  0.276899  0.373128  0.465027  0.552595  \n",
    "  4  0.088771  0.188849  0.286522  0.381789  0.473206  0.560294  \n",
    "  5 -0.112829 -0.211944 -0.309136 -0.403921 -0.494377 -0.580502  \n",
    "  6 -0.091177 -0.191255 -0.288928 -0.384194 -0.475131 -0.561737  \n",
    "  7 -0.124857 -0.223492 -0.320202 -0.413544 -0.503037 -0.587238  \n",
    "  8 -0.098394 -0.198472 -0.296145 -0.391412 -0.482348 -0.568954  \n",
    "  9 -0.092139 -0.192218 -0.289890 -0.385157 -0.476093 -0.562699  \n",
    "  \n",
    "  [10 rows x 50 columns],\n",
    "  'median': 50   -0.943045\n",
    "  51   -0.904553\n",
    "  52   -0.856679\n",
    "  53   -0.800144\n",
    "  54   -0.735912\n",
    "  55   -0.664221\n",
    "  56   -0.585073\n",
    "  57   -0.500632\n",
    "  58   -0.410417\n",
    "  59   -0.316594\n",
    "  60   -0.219162\n",
    "  61   -0.119565\n",
    "  62   -0.019246\n",
    "  63    0.076502\n",
    "  64    0.176099\n",
    "  65    0.273290\n",
    "  66    0.368076\n",
    "  67    0.458531\n",
    "  68    0.544656\n",
    "  69    0.624526\n",
    "  70    0.698142\n",
    "  71    0.764540\n",
    "  72    0.822999\n",
    "  73    0.872557\n",
    "  74    0.912973\n",
    "  75    0.943526\n",
    "  76    0.964215\n",
    "  77    0.975041\n",
    "  78    0.975041\n",
    "  79    0.965418\n",
    "  80    0.945450\n",
    "  81    0.915379\n",
    "  82    0.875684\n",
    "  83    0.826607\n",
    "  84    0.768389\n",
    "  85    0.702713\n",
    "  86    0.629578\n",
    "  87    0.549949\n",
    "  88    0.464305\n",
    "  89    0.373369\n",
    "  90    0.278583\n",
    "  91    0.181151\n",
    "  92    0.081554\n",
    "  93   -0.010826\n",
    "  94   -0.091418\n",
    "  95   -0.191496\n",
    "  96   -0.289168\n",
    "  97   -0.384435\n",
    "  98   -0.475371\n",
    "  99   -0.561978\n",
    "  dtype: float64,\n",
    "  'info': {'Method': 'gpt-4'},\n",
    "  'completions_list': [['-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -664, -463, -256, -48, 161, 369, 572, 770, 959, 1139, 1306, 1460, 1599, 1721, 1826, 1911, 1977, 2022, 2046, 2050, 2032, 1993, 1933, 1852, 1752, 1635, 1502, 1353, 1190, 1015, 829, 635, 434, 227, 19, -190, -398, -601, -799, -988, -1168, -1335, -1489, -1628, -1750, -1855, -1940, -2006, -2051, -2075, -',\n",
    "    '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853',\n",
    "    '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 233, 24, -185, -393, -596, -794, -983, -1163, -1330, -1484, -1623, -1745, -1850, -1935, -2001, -2046, -2070, -2074, -2056, -2017, -1955, -1874, -1773, -1654, -1519, -1368, -1203, -1026, -838, -642, -439, -232, -23, 186, 394, 597, 795, 984, 1164, 1331, 1485, 1624, 1746, 1851, 1936, 2002, 2047, 2071, 207',\n",
    "    '1959, 1879, 1779, 1661, 1528, 1378, 1213, 1037, 849, 654, 451, 244, 35, -174, -383, -587, -786, -976, -1157, -1325, -1480, -1620, -1743, -1849, -1935, -2002, -2048, -2073, -2078, -2061, -2023, -1963, -1884, -1785, -1668, -1536, -1387, -1223, -1048, -861, -667, -464, -257, -48, 161, 370, 575, 775, 966, 1148, 1317, 1473, 1614, 1738, 1845, 1932, 2000, 2047, 2072, 207',\n",
    "    '1960, 1881, 1782, 1665, 1532, 1383, 1220, 1045, 859, 665, 464, 259, 52, -157, -365, -568, -766, -956, -1137, -1304, -1458, -1597, -1719, -1824, -1910, -1976, -2021, -2045, -2049, -2031, -1992, -1933, -1854, -1755, -1638, -1505, -1356, -1193, -1018, -832, -638, -437, -232, -25, 184, 392, 595, 793, 983, 1164, 1331, 1485, 1624, 1746, 1851, 1937, 2003, 2048, 2072, 207',\n",
    "    '-1960, -1881, -1781, -1663, -1530, -1380, -1216, -1040, -853, -658, -456, -249, -40, 168, 375, 577, 775, 963, 1142, 1308, 1461, 1599, 1720, 1824, 1909, 1974, 2018, 2041, 2043, 2023, 1982, 1919, 1837, 1735, 1615, 1479, 1327, 1161, 983, 792, 594, 390, 182, -26, -234, -440, -642, -839, -1027, -1206, -1371, -1523, -1661',\n",
    "    '-1959, -1879, -1780, -1662, -1529, -1380, -1217, -1041, -854, -660, -457, -250, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1938, 1858, 1759, 1641, 1508, 1359, 1196, 1020, 833, 639, 436, 229, 20, -189, -397, -600, -798, -987, -1167, -1334, -1488, -1627, -1749, -1854, -1939, -2005, -2050, -2074, -',\n",
    "    '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -51, 156, 362, 563, 759, 946, 1124, 1289, 1441, 1578, 1700, 1802, 1885, 1947, 1989, 2011, 2009, 1989, 1947, 1885, 1802, 1700, 1578, 1441, 1289, 1124, 946, 759, 563, 362, 156, -51, -259, -464, -665, -859, -1045, -1220, -1383, -1532, -1665, -1782, -1881, -1960, -2020, -2059, -2077, -',\n",
    "    '-1960, -1880, -1780, -1663, -1529, -1380, -1216, -1041, -854, -660, -458, -252, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1939, 1858, 1757, 1638, 1503, 1352, 1187, 1010, 822, 626, 423, 216, 7, -204, -412, -615, -813, -1002, -1182, -1349, -1503, -1642, -1764, -1869, -1954, -2020, -2065, -2089,',\n",
    "    '-1960, -1880, -1781, -1664, -1529, -1380, -1215, -1040, -852, -657, -454, -247, -39, 169, 377, 580, 778, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2058, 2040, 2001, 1941, 1861, 1762, 1645, 1510, 1361, 1196, 1021, 833, 638, 435, 228, 19, -191, -399, -602, -800, -989, -1169, -1336, -1490, -1629, -1751, -1856, -1941, -2007, -2052, -2076, -']],\n",
    "  'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "  'best_hyper': {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': {'base': 10,\n",
    "    'prec': 3,\n",
    "    'signed': True,\n",
    "    'fixed_length': False,\n",
    "    'max_val': 10000000.0,\n",
    "    'time_sep': ', ',\n",
    "    'bit_sep': '',\n",
    "    'plus_sign': '',\n",
    "    'minus_sign': '-',\n",
    "    'half_bin_correction': True,\n",
    "    'decimal_point': '',\n",
    "    'missing_str': ' Nan'}}},\n",
    " '_i14': \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\",\n",
    " '_14': [<matplotlib.lines.Line2D at 0x28e598ac0>],\n",
    " '_i15': \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    " '_15': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    " '_i16': \"pred_dict_arima = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['ARIMA'], verbose=False, parallel=False)\",\n",
    " 'pred_dict_arima': {'NLL/D': -4.969729363485449,\n",
    "  'samples':         50        51        52        53        54        55        56  \\\n",
    "  0 -0.94365 -0.905443 -0.852557 -0.800318 -0.734074 -0.662144 -0.585516   \n",
    "  1 -0.94365 -0.905118 -0.864710 -0.797575 -0.740557 -0.670163 -0.591889   \n",
    "  2 -0.94365 -0.904909 -0.855473 -0.800623 -0.741641 -0.658677 -0.587553   \n",
    "  3 -0.94365 -0.902747 -0.852602 -0.806026 -0.730404 -0.660079 -0.580143   \n",
    "  4 -0.94365 -0.905678 -0.853939 -0.802684 -0.738891 -0.658912 -0.590644   \n",
    "  5 -0.94365 -0.902273 -0.860992 -0.800059 -0.735753 -0.671671 -0.583049   \n",
    "  6 -0.94365 -0.903072 -0.861410 -0.796147 -0.740228 -0.669109 -0.583842   \n",
    "  7 -0.94365 -0.904404 -0.860577 -0.798270 -0.742046 -0.664599 -0.588831   \n",
    "  8 -0.94365 -0.901084 -0.857657 -0.802336 -0.735326 -0.661621 -0.586273   \n",
    "  9 -0.94365 -0.905363 -0.857093 -0.804975 -0.736419 -0.669259 -0.589145   \n",
    "  \n",
    "           57        58        59  ...        90        91        92        93  \\\n",
    "  0 -0.494148 -0.405684 -0.316743  ...  0.314964  0.223465  0.118506  0.023308   \n",
    "  1 -0.504005 -0.419174 -0.329284  ...  0.328523  0.237772  0.138675  0.039767   \n",
    "  2 -0.501735 -0.404988 -0.320936  ...  0.320913  0.219232  0.121903  0.024940   \n",
    "  3 -0.499412 -0.404190 -0.307360  ...  0.348126  0.243689  0.153016  0.056852   \n",
    "  4 -0.494303 -0.413767 -0.316401  ...  0.378078  0.278006  0.177887  0.081747   \n",
    "  5 -0.503164 -0.415042 -0.322271  ...  0.354223  0.276022  0.158557  0.061611   \n",
    "  6 -0.503433 -0.414259 -0.321314  ...  0.342413  0.248807  0.160784  0.063264   \n",
    "  7 -0.498080 -0.417262 -0.318544  ...  0.402404  0.291452  0.208110  0.101532   \n",
    "  8 -0.498329 -0.413145 -0.313249  ...  0.375809  0.284512  0.174369  0.086975   \n",
    "  9 -0.504753 -0.415561 -0.325437  ...  0.320836  0.235207  0.133222  0.040175   \n",
    "  \n",
    "           94        95        96        97        98        99  \n",
    "  0 -0.082856 -0.191330 -0.287530 -0.375918 -0.487488 -0.565742  \n",
    "  1 -0.055386 -0.163871 -0.264247 -0.357118 -0.439809 -0.536424  \n",
    "  2 -0.079951 -0.183952 -0.275269 -0.375722 -0.465214 -0.557245  \n",
    "  3 -0.050828 -0.147686 -0.245323 -0.336029 -0.427241 -0.517167  \n",
    "  4 -0.011558 -0.121913 -0.214677 -0.314062 -0.398466 -0.491806  \n",
    "  5 -0.036022 -0.141459 -0.243957 -0.338766 -0.441351 -0.519933  \n",
    "  6 -0.033722 -0.122408 -0.216506 -0.308145 -0.391628 -0.476830  \n",
    "  7  0.005380 -0.096285 -0.198618 -0.291039 -0.387284 -0.469629  \n",
    "  8 -0.021613 -0.119366 -0.224972 -0.307706 -0.413565 -0.501481  \n",
    "  9 -0.065688 -0.155704 -0.258237 -0.344688 -0.433817 -0.525883  \n",
    "  \n",
    "  [10 rows x 50 columns],\n",
    "  'median': 50   -0.943650\n",
    "  51   -0.904656\n",
    "  52   -0.857375\n",
    "  53   -0.800471\n",
    "  54   -0.737655\n",
    "  55   -0.663371\n",
    "  56   -0.586913\n",
    "  57   -0.500573\n",
    "  58   -0.414013\n",
    "  59   -0.319740\n",
    "  60   -0.219111\n",
    "  61   -0.120967\n",
    "  62   -0.018869\n",
    "  63    0.084380\n",
    "  64    0.180881\n",
    "  65    0.281847\n",
    "  66    0.381607\n",
    "  67    0.472454\n",
    "  68    0.558048\n",
    "  69    0.640257\n",
    "  70    0.718235\n",
    "  71    0.784317\n",
    "  72    0.846605\n",
    "  73    0.897299\n",
    "  74    0.941481\n",
    "  75    0.973108\n",
    "  76    0.997849\n",
    "  77    1.007439\n",
    "  78    1.013450\n",
    "  79    1.000197\n",
    "  80    0.983191\n",
    "  81    0.958019\n",
    "  82    0.918515\n",
    "  83    0.871231\n",
    "  84    0.810083\n",
    "  85    0.752420\n",
    "  86    0.683215\n",
    "  87    0.602929\n",
    "  88    0.520326\n",
    "  89    0.437604\n",
    "  90    0.345270\n",
    "  91    0.246248\n",
    "  92    0.155787\n",
    "  93    0.059231\n",
    "  94   -0.043425\n",
    "  95   -0.144572\n",
    "  96   -0.244640\n",
    "  97   -0.337398\n",
    "  98   -0.430529\n",
    "  99   -0.518550\n",
    "  dtype: float64,\n",
    "  'info': {'Method': 'ARIMA', 'p': 12, 'd': 1},\n",
    "  'best_hyper': {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': {'base': 10,\n",
    "    'prec': 3,\n",
    "    'signed': True,\n",
    "    'fixed_length': False,\n",
    "    'max_val': 10000000.0,\n",
    "    'time_sep': ', ',\n",
    "    'bit_sep': '',\n",
    "    'plus_sign': '',\n",
    "    'minus_sign': '-',\n",
    "    'half_bin_correction': True,\n",
    "    'decimal_point': '',\n",
    "    'missing_str': ' Nan'}}},\n",
    " '_i17': \"plt.plot(pred_dict['median'])\\nplt.plot(pred_dict_arima['median'],'b')\\nplt.plot(np.linspace(50,100,50),test,'r')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    " '_17': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    " '_i18': \"plt.plot(pred_dict['median'],'r')\\nplt.plot(pred_dict_arima['median'],'b')\\nplt.plot(np.linspace(50,100,50),test,'ko')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    " '_18': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    " '_i19': '\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")',\n",
    " '_19': <matplotlib.legend.Legend at 0x28f18c790>,\n",
    " '_i20': '\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    " '_i21': 'x2 = np.linspace(0,10,100)\\ntrain = np.sin(x2[0:50]) + 2*np.sin(x2[0:50]/2) + 3*np.sin(x2[0:50]/3)\\ntest = np.sin(x2[50:100]) + 2*np.sin(x2[50:100]/2) + 3*np.sin(x2[50:100]/3)',\n",
    " 'x2': array([ 0.        ,  0.1010101 ,  0.2020202 ,  0.3030303 ,  0.4040404 ,\n",
    "         0.50505051,  0.60606061,  0.70707071,  0.80808081,  0.90909091,\n",
    "         1.01010101,  1.11111111,  1.21212121,  1.31313131,  1.41414141,\n",
    "         1.51515152,  1.61616162,  1.71717172,  1.81818182,  1.91919192,\n",
    "         2.02020202,  2.12121212,  2.22222222,  2.32323232,  2.42424242,\n",
    "         2.52525253,  2.62626263,  2.72727273,  2.82828283,  2.92929293,\n",
    "         3.03030303,  3.13131313,  3.23232323,  3.33333333,  3.43434343,\n",
    "         3.53535354,  3.63636364,  3.73737374,  3.83838384,  3.93939394,\n",
    "         4.04040404,  4.14141414,  4.24242424,  4.34343434,  4.44444444,\n",
    "         4.54545455,  4.64646465,  4.74747475,  4.84848485,  4.94949495,\n",
    "         5.05050505,  5.15151515,  5.25252525,  5.35353535,  5.45454545,\n",
    "         5.55555556,  5.65656566,  5.75757576,  5.85858586,  5.95959596,\n",
    "         6.06060606,  6.16161616,  6.26262626,  6.36363636,  6.46464646,\n",
    "         6.56565657,  6.66666667,  6.76767677,  6.86868687,  6.96969697,\n",
    "         7.07070707,  7.17171717,  7.27272727,  7.37373737,  7.47474747,\n",
    "         7.57575758,  7.67676768,  7.77777778,  7.87878788,  7.97979798,\n",
    "         8.08080808,  8.18181818,  8.28282828,  8.38383838,  8.48484848,\n",
    "         8.58585859,  8.68686869,  8.78787879,  8.88888889,  8.98989899,\n",
    "         9.09090909,  9.19191919,  9.29292929,  9.39393939,  9.49494949,\n",
    "         9.5959596 ,  9.6969697 ,  9.7979798 ,  9.8989899 , 10.        ]),\n",
    " '_i22': \"plt.plot(np.linspace(50,100,50),test,'k')\",\n",
    " '_22': [<matplotlib.lines.Line2D at 0x28f3fb1c0>],\n",
    " '_i23': 'x2 = np.linspace(0,10,100)\\ntrain = np.sin(x2[0:50]) + 0.2*np.sin(x2[0:50]*10) + 0.03*np.sin(x2[0:50]*20)\\ntest = np.sin(x2[50:100]) + 0.2*np.sin(x2[50:100]*10) + 0.03*np.sin(x2[50:100]*20)',\n",
    " '_i24': \"plt.plot(np.linspace(50,100,50),test,'k')\",\n",
    " '_24': [<matplotlib.lines.Line2D at 0x28f3bdf70>],\n",
    " '_i25': 'x2 = np.linspace(0,10,100)\\ntrain2 = np.sin(x2[0:50]) + 0.2*np.sin(x2[0:50]*10) + 0.03*np.sin(x2[0:50]*20)\\ntest2 = np.sin(x2[50:100]) + 0.2*np.sin(x2[50:100]*10) + 0.03*np.sin(x2[50:100]*20)',\n",
    " 'train2': array([ 0.        ,  0.2972367 ,  0.35731232,  0.31400343,  0.26585066,\n",
    "         0.27639963,  0.51256688,  0.8213306 ,  0.904692  ,  0.83590927,\n",
    "         0.75100161,  0.69065491,  0.8269244 ,  1.10119197,  1.18749806,\n",
    "         1.07717744,  0.93495622,  0.79682455,  0.81654052,  1.02603832,\n",
    "         1.10864503,  0.96282708,  0.76279164,  0.55916882,  0.47259406,\n",
    "         0.60907063,  0.69685163,  0.54379641,  0.3070198 ,  0.06723   ,\n",
    "        -0.09212802, -0.01636787,  0.09607604, -0.02163259, -0.2585526 ,\n",
    "        -0.49658592, -0.68292178, -0.64326164, -0.48587393, -0.52472469,\n",
    "        -0.72099784, -0.92253453, -1.09233244, -1.06357349, -0.851197  ,\n",
    "        -0.78119449, -0.90437415, -1.04875937, -1.17414227, -1.14131212]),\n",
    " 'test2': array([-0.88209427, -0.6973774 , -0.73270271, -0.81938345, -0.89577425,\n",
    "        -0.86009574, -0.58199325, -0.30401812, -0.25741528, -0.304764  ,\n",
    "        -0.35037054, -0.32835171, -0.0733774 ,  0.25444065,  0.36049572,\n",
    "         0.32328515,  0.27583927,  0.25965338,  0.44691271,  0.77132079,\n",
    "         0.90728793,  0.85243785,  0.76933234,  0.69306657,  0.7788732 ,\n",
    "         1.05163056,  1.19205516,  1.10521015,  0.96486774,  0.81934952,\n",
    "         0.79155354,  0.98211495,  1.11423813,  1.0018416 ,  0.80394875,\n",
    "         0.59821144,  0.47047521,  0.57244203,  0.69909477,  0.58828182,\n",
    "         0.35534332,  0.11544319, -0.07670492, -0.04722262,  0.08857259,\n",
    "         0.01931833, -0.20967662, -0.44819378, -0.65833188, -0.67149316]),\n",
    " '_i26': \"plt.plot(np.linspace(50,100,50),test2,'k')\",\n",
    " '_26': [<matplotlib.lines.Line2D at 0x28f4aaa30>],\n",
    " '_i27': \"pred_dict_gpt_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    " 'pred_dict_gpt_sum': {'samples':          50        51        52        53        54        55        56  \\\n",
    "  0 -0.904598 -0.780762 -0.841940 -0.966270 -1.120202 -1.125629 -0.936667   \n",
    "  1 -0.926800 -0.849834 -0.964790 -1.102934 -1.222823 -1.182367 -0.956896   \n",
    "  2 -0.942094 -0.873022 -1.012153 -1.163125 -1.290415 -1.248972 -1.043729   \n",
    "  3 -0.926307 -0.841447 -0.847860 -0.962323 -1.065438 -1.144870 -1.098987   \n",
    "  4 -0.943081 -0.860195 -0.991925 -1.148324 -1.254893 -1.199635 -0.981564   \n",
    "  5 -0.895224 -0.766454 -0.821218 -0.955416 -1.093560 -1.204569 -1.156711   \n",
    "  6 -0.924826 -0.743759 -0.711690 -0.835033 -0.979097 -1.104414 -1.071851   \n",
    "  7 -0.921866 -0.735865 -0.763494 -0.917426 -1.094053 -1.250452 -1.215423   \n",
    "  8 -0.926800 -0.815298 -0.885850 -1.040276 -1.188287 -1.299789 -1.209996   \n",
    "  9 -0.930747 -0.770894 -0.799016 -0.962323 -1.123655 -1.235651 -1.204075   \n",
    "  \n",
    "           57        58        59  ...        90        91        92        93  \\\n",
    "  0 -0.849834 -0.959856 -1.100960  ... -1.230717 -1.076785 -0.878449 -0.757080   \n",
    "  1 -0.876969 -0.987978 -1.121189  ... -1.235158 -1.235158 -1.235158 -1.235158   \n",
    "  2 -0.955909 -1.094547 -1.236144  ... -1.399451 -1.399451 -1.399451 -1.399451   \n",
    "  3 -0.909532 -0.759053 -0.687514  ... -0.022448 -0.022448 -0.022448 -0.022448   \n",
    "  4 -0.834539 -0.930254 -1.095040  ... -0.321925 -0.321925 -0.321925 -0.321925   \n",
    "  5 -0.935187 -0.782735 -0.785202  ... -0.079186 -0.189208 -0.305151 -0.420107   \n",
    "  6 -0.855261 -0.674193 -0.642124  ... -0.965283 -0.965283 -0.965283 -0.965283   \n",
    "  7 -0.998339 -0.899171 -1.037315  ... -1.274627 -1.448294 -1.371822 -1.123162   \n",
    "  8 -0.992912 -0.837006 -0.868089  ... -0.834539 -0.698369 -0.459083 -0.289363   \n",
    "  9 -0.996859 -0.875489 -0.999819  ... -1.207035 -1.207035 -1.207035 -1.207035   \n",
    "  \n",
    "           94        95        96        97        98        99  \n",
    "  0 -0.935681 -1.135990 -1.211969 -1.053103 -0.847367 -0.737838  \n",
    "  1 -1.235158 -1.235158 -1.235158 -1.235158 -1.235158 -1.235158  \n",
    "  2 -1.399451 -1.399451 -1.399451 -1.399451 -1.399451 -1.399451  \n",
    "  3 -0.022448 -0.022448 -0.022448 -0.022448 -0.022448 -0.022448  \n",
    "  4 -0.321925 -0.321925 -0.321925 -0.321925 -0.321925 -0.321925  \n",
    "  5 -0.530622 -0.484738 -0.274562 -0.064385  0.056985 -0.056985  \n",
    "  6 -0.965283 -0.965283 -0.965283 -0.965283 -0.965283 -0.965283  \n",
    "  7 -0.958376 -1.118722 -1.283015 -1.458162 -1.379222 -1.127109  \n",
    "  8 -0.313538 -0.499046 -0.614002 -0.656925 -0.514341 -0.273575  \n",
    "  9 -1.207035 -1.207035 -1.207035 -1.207035 -1.207035 -1.207035  \n",
    "  \n",
    "  [10 rows x 50 columns],\n",
    "  'median': 50   -0.926553\n",
    "  51   -0.798030\n",
    "  52   -0.844900\n",
    "  53   -0.964296\n",
    "  54   -1.121929\n",
    "  55   -1.202102\n",
    "  56   -1.085419\n",
    "  57   -0.922360\n",
    "  58   -0.887330\n",
    "  59   -1.018567\n",
    "  60   -1.168552\n",
    "  61   -1.188287\n",
    "  62   -1.067904\n",
    "  63   -1.006233\n",
    "  64   -0.942835\n",
    "  65   -0.933954\n",
    "  66   -1.023748\n",
    "  67   -1.104167\n",
    "  68   -1.003766\n",
    "  69   -0.935681\n",
    "  70   -0.995625\n",
    "  71   -1.025721\n",
    "  72   -1.086159\n",
    "  73   -1.086159\n",
    "  74   -0.976631\n",
    "  75   -0.936174\n",
    "  76   -0.993652\n",
    "  77   -1.046689\n",
    "  78   -1.086159\n",
    "  79   -1.075798\n",
    "  80   -0.967750\n",
    "  81   -0.904351\n",
    "  82   -0.957142\n",
    "  83   -1.045949\n",
    "  84   -1.086159\n",
    "  85   -1.045703\n",
    "  86   -0.942094\n",
    "  87   -0.877956\n",
    "  88   -0.956402\n",
    "  89   -1.037809\n",
    "  90   -1.086159\n",
    "  91   -1.021034\n",
    "  92   -0.921866\n",
    "  93   -0.861181\n",
    "  94   -0.947028\n",
    "  95   -1.042002\n",
    "  96   -1.086159\n",
    "  97   -1.009193\n",
    "  98   -0.906325\n",
    "  99   -0.851561\n",
    "  dtype: float64,\n",
    "  'info': {'Method': 'gpt-4'},\n",
    "  'completions_list': [['-1833, -1582, -1706, -1958, -2270, -2281, -1898, -1722, -1945, -2231, -2529, -2424, -2024, -1828, -2068, -2436, -2698, -2515, -2088, -1836, -2104, -2474, -2680, -2476, -2034, -1790, -2076, -2452, -2677, -2404, -1966, -1709, -2006, -2393, -2569, -2282, -1862, -1602, -1942, -2328, -2494, -2182, -1780, -1534, -1896, -2302, -2456, -2134, -1717, -1495, -1875, -2288, -2407 ',\n",
    "    '-1878, -1722, -1955, -2235, -2478, -2396, -1939, -1777, -2002, -2272, -2513, -2425, -1959, -1796, -2024, -2296, -2538, -2450, -1980, -1817, -2047, -2320, -2564, -2476, -2002, -1838, -2071, -2346, -2591, -2503',\n",
    "    '-1909, -1769, -2051, -2357, -2615, -2531, -2115, -1937, -2218, -2505, -2760, -2651, -2231, -2047, -2330, -2607, -2855, -2736, -2315, -2127, -2402, -2671, -2914, -2792, -2366, -2175, -2452, -2721, -2961, -2836',\n",
    "    '-1877, -1705, -1718, -1950, -2159, -2320, -2227, -1843, -1538, -1393, -1531, -1726, -1890, -1771, -1372, -1060, -868, -1003, -1180, -1356, -1172, -742, -306, -45',\n",
    "    '-1911, -1743, -2010, -2327, -2543, -2431, -1989, -1691, -1885, -2219, -2493, -2375, -1949, -1432, -1164, -935, -710, -257, -59, 166, 133, -186, -785, -1171, -1069, -515, -247, -194, -312, -857, -1225, -1153, -617, -346, -409, -696, -1112, -1342, -1212, -798, -652',\n",
    "    '-1814, -1553, -1664, -1936, -2216, -2441, -2344, -1895, -1586, -1591, -1830, -2087, -2308, -2193, -1735, -1263, -1062, -1290, -1535, -1778, -1988, -1888, -1441, -984, -726, -951, -1188, -1429, -1662, -1563, -1120, -673, -425, -651, -891, -1135, -1363, -1267, -835, -401, -160, -383, -618, -851, -1075, -982, -556, -130, 115, -115, -348, -577, -804, -714, -294, 130, 377, 147, -96, -323, -548, -463',\n",
    "    '-1874, -1507, -1442, -1692, -1984, -2238, -2172, -1733, -1366, -1301, -1551, -1843, -2097, -2031, -1592, -1225, -1160, -1410, -1702, -1956',\n",
    "    '-1868, -1491, -1547, -1859, -2217, -2534, -2463, -2023, -1822, -2102, -2401, -2696, -2605, -2151, -1885, -2167, -2476, -2789, -2675, -2208, -1916, -2201, -2517, -2845, -2715, -2233, -1918, -2218, -2543, -2886, -2741, -2251, -1923, -2230, -2564, -2912, -2762, -2265, -1934, -2250, -2583, -2935, -2780, -2276, -1942, -2267, -2600, -2955, -2795, -2284, -1950, -2278, -2615, -2972, -',\n",
    "    '-1878, -1652, -1795, -2108, -2408, -2634, -2452, -2012, -1696, -1759, -2101, -2392, -2600, -2394, -1944, -1618, -1673, -2025, -2301, -2478, -2249, -1782, -1451, -1500, -1852, -2117, -2270, -2024, -1550, -1214, -1263, -1623, -1874, -2009, -1746, -1265, -926, -975, -1343, -1580, -1691, -1415, -930, -586, -635, -1011, -1244, -1331, -1042, -554, -206, -255, -639, -870, -953, -660, -170, 180',\n",
    "    '-1886, -1562, -1619, -1950, -2277, -2504, -2440, -2020, -1774, -2026, -2335, -2645, -2579, -2157, -1936, -2219, -2607, -2971, -2891, -2446']],\n",
    "  'input_strs': ('0, 602, 724, 636, 538, 560, 1038, 1664, 1833, 1694, 1522, 1399, 1676, 2231, 2406, 2183, 1895, 1615, 1655, 2079, 2247, 1951, 1546, 1133, 957, 1234, 1412, 1102, 622, 136, -186, -33, 194, -43, -524, -1006, -1384, -1303, -984, -1063, -1461, -1869, -2214, -2155, -1725, -1583, -1833, -2125, -2379, -2313, ',),\n",
    "  'best_hyper': {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': {'base': 10,\n",
    "    'prec': 3,\n",
    "    'signed': True,\n",
    "    'fixed_length': False,\n",
    "    'max_val': 10000000.0,\n",
    "    'time_sep': ', ',\n",
    "    'bit_sep': '',\n",
    "    'plus_sign': '',\n",
    "    'minus_sign': '-',\n",
    "    'half_bin_correction': True,\n",
    "    'decimal_point': '',\n",
    "    'missing_str': ' Nan'}}},\n",
    " '_i28': 'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    " 'pred_dict_arima_sum': {'NLL/D': -4.1888975611189565,\n",
    "  'samples':          50        51        52        53        54        55        56  \\\n",
    "  0 -0.882607 -0.704058 -0.738500 -0.833129 -0.907222 -0.874076 -0.610003   \n",
    "  1 -0.882607 -0.696324 -0.733016 -0.816796 -0.884020 -0.861572 -0.555588   \n",
    "  2 -0.882607 -0.695825 -0.734471 -0.820938 -0.900189 -0.870921 -0.581207   \n",
    "  3 -0.882607 -0.704905 -0.728674 -0.834020 -0.895926 -0.863431 -0.585385   \n",
    "  4 -0.882607 -0.699143 -0.720814 -0.827033 -0.873154 -0.853279 -0.556753   \n",
    "  5 -0.882607 -0.694893 -0.739368 -0.814894 -0.902822 -0.864668 -0.576967   \n",
    "  6 -0.882607 -0.709379 -0.718335 -0.848384 -0.889453 -0.878848 -0.608141   \n",
    "  7 -0.882607 -0.698440 -0.735343 -0.817520 -0.903700 -0.854247 -0.585465   \n",
    "  8 -0.882607 -0.702617 -0.732953 -0.829258 -0.907910 -0.863368 -0.603446   \n",
    "  9 -0.882607 -0.704916 -0.730982 -0.818871 -0.902704 -0.847071 -0.582599   \n",
    "  \n",
    "           57        58        59  ...        90        91        92        93  \\\n",
    "  0 -0.326174 -0.309662 -0.350169  ...  1.190632  1.006682  0.858615  0.954495   \n",
    "  1 -0.296714 -0.225472 -0.265066  ...  1.866805  1.659945  1.521586  1.579240   \n",
    "  2 -0.314046 -0.251882 -0.308393  ...  1.691563  1.475050  1.322847  1.377170   \n",
    "  3 -0.303474 -0.253858 -0.298953  ...  1.512233  1.295683  1.160856  1.222863   \n",
    "  4 -0.281398 -0.207561 -0.258617  ...  2.120482  1.928566  1.783217  1.824684   \n",
    "  5 -0.318252 -0.248874 -0.307859  ...  1.667444  1.458180  1.321353  1.371914   \n",
    "  6 -0.319160 -0.283300 -0.335002  ...  1.091053  0.906172  0.706964  0.774893   \n",
    "  7 -0.301791 -0.251999 -0.294007  ...  1.915786  1.747191  1.611410  1.702512   \n",
    "  8 -0.308972 -0.273849 -0.316830  ...  1.368005  1.152561  1.033258  1.077206   \n",
    "  9 -0.306658 -0.235918 -0.303405  ...  0.990253  0.787730  0.601073  0.684061   \n",
    "  \n",
    "           94        95        96        97        98        99  \n",
    "  0  1.112691  1.103780  0.887679  0.691527  0.490860  0.514675  \n",
    "  1  1.739250  1.710230  1.462288  1.260123  1.024068  1.011417  \n",
    "  2  1.540410  1.472163  1.267758  1.014856  0.798240  0.768250  \n",
    "  3  1.365499  1.351708  1.123374  0.871389  0.710564  0.649955  \n",
    "  4  2.004155  1.958960  1.716237  1.509127  1.282651  1.260510  \n",
    "  5  1.524643  1.491214  1.256226  1.033564  0.805312  0.813809  \n",
    "  6  0.903928  0.869526  0.629159  0.384127  0.174851  0.126023  \n",
    "  7  1.895099  1.839247  1.683449  1.436648  1.263552  1.252441  \n",
    "  8  1.254469  1.213167  1.017366  0.768234  0.599821  0.577370  \n",
    "  9  0.826680  0.775376  0.574227  0.357377  0.135462  0.169936  \n",
    "  \n",
    "  [10 rows x 50 columns],\n",
    "  'median': 50   -0.882607\n",
    "  51   -0.700880\n",
    "  52   -0.732984\n",
    "  53   -0.823986\n",
    "  54   -0.901447\n",
    "  55   -0.863399\n",
    "  56   -0.583992\n",
    "  57   -0.307815\n",
    "  58   -0.251940\n",
    "  59   -0.305632\n",
    "  60   -0.336607\n",
    "  61   -0.308903\n",
    "  62   -0.042321\n",
    "  63    0.286063\n",
    "  64    0.414689\n",
    "  65    0.392608\n",
    "  66    0.356034\n",
    "  67    0.376533\n",
    "  68    0.586068\n",
    "  69    0.932218\n",
    "  70    1.103616\n",
    "  71    1.092661\n",
    "  72    1.026094\n",
    "  73    1.012123\n",
    "  74    1.141689\n",
    "  75    1.447814\n",
    "  76    1.653312\n",
    "  77    1.616693\n",
    "  78    1.512663\n",
    "  79    1.443847\n",
    "  80    1.461684\n",
    "  81    1.713792\n",
    "  82    1.904596\n",
    "  83    1.858689\n",
    "  84    1.704362\n",
    "  85    1.571048\n",
    "  86    1.493825\n",
    "  87    1.658488\n",
    "  88    1.830467\n",
    "  89    1.775599\n",
    "  90    1.589838\n",
    "  91    1.376931\n",
    "  92    1.241105\n",
    "  93    1.297388\n",
    "  94    1.445071\n",
    "  95    1.411935\n",
    "  96    1.189800\n",
    "  97    0.943123\n",
    "  98    0.754402\n",
    "  99    0.709103\n",
    "  dtype: float64,\n",
    "  'info': {'Method': 'ARIMA', 'p': 12, 'd': 1},\n",
    "  'best_hyper': {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': {'base': 10,\n",
    "    'prec': 3,\n",
    "    'signed': True,\n",
    "    'fixed_length': False,\n",
    "    'max_val': 10000000.0,\n",
    "    'time_sep': ', ',\n",
    "    'bit_sep': '',\n",
    "    'plus_sign': '',\n",
    "    'minus_sign': '-',\n",
    "    'half_bin_correction': True,\n",
    "    'decimal_point': '',\n",
    "    'missing_str': ' Nan'}}},\n",
    " '_i29': 'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    " '_i30': 'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'oscillator2.png\\')',\n",
    " '_i31': \"x3 = np.linspace(0,10,100)\\ntrain3 = np.sin(x3[0:50]) + 0.2*np.sin(x3[0:50]*10) + 0.1*np.sin(x3[0:50]*20)\\ntest3 = np.sin(x3[50:100]) + 0.2*np.sin(x3[50:100]*10) + 0.1*np.sin(x3[50:100]*20)\\nplt.plot(np.linspace(50,100,50),test3,'k')\",\n",
    " 'x3': array([ 0.        ,  0.1010101 ,  0.2020202 ,  0.3030303 ,  0.4040404 ,\n",
    "         0.50505051,  0.60606061,  0.70707071,  0.80808081,  0.90909091,\n",
    "         1.01010101,  1.11111111,  1.21212121,  1.31313131,  1.41414141,\n",
    "         1.51515152,  1.61616162,  1.71717172,  1.81818182,  1.91919192,\n",
    "         2.02020202,  2.12121212,  2.22222222,  2.32323232,  2.42424242,\n",
    "         2.52525253,  2.62626263,  2.72727273,  2.82828283,  2.92929293,\n",
    "         3.03030303,  3.13131313,  3.23232323,  3.33333333,  3.43434343,\n",
    "         3.53535354,  3.63636364,  3.73737374,  3.83838384,  3.93939394,\n",
    "         4.04040404,  4.14141414,  4.24242424,  4.34343434,  4.44444444,\n",
    "         4.54545455,  4.64646465,  4.74747475,  4.84848485,  4.94949495,\n",
    "         5.05050505,  5.15151515,  5.25252525,  5.35353535,  5.45454545,\n",
    "         5.55555556,  5.65656566,  5.75757576,  5.85858586,  5.95959596,\n",
    "         6.06060606,  6.16161616,  6.26262626,  6.36363636,  6.46464646,\n",
    "         6.56565657,  6.66666667,  6.76767677,  6.86868687,  6.96969697,\n",
    "         7.07070707,  7.17171717,  7.27272727,  7.37373737,  7.47474747,\n",
    "         7.57575758,  7.67676768,  7.77777778,  7.87878788,  7.97979798,\n",
    "         8.08080808,  8.18181818,  8.28282828,  8.38383838,  8.48484848,\n",
    "         8.58585859,  8.68686869,  8.78787879,  8.88888889,  8.98989899,\n",
    "         9.09090909,  9.19191919,  9.29292929,  9.39393939,  9.49494949,\n",
    "         9.5959596 ,  9.6969697 ,  9.7979798 ,  9.8989899 , 10.        ]),\n",
    " 'train3': array([ 0.        ,  0.36028608,  0.3025312 ,  0.29855121,  0.33405761,\n",
    "         0.23258951,  0.48242482,  0.89132997,  0.87401437,  0.79256449,\n",
    "         0.81933982,  0.67462332,  0.77251542,  1.16449739,  1.18690346,\n",
    "         1.01438865,  0.99010553,  0.81169628,  0.74846975,  1.0703106 ,\n",
    "         1.13824936,  0.89283276,  0.79400262,  0.60204515,  0.40412953,\n",
    "         0.62568044,  0.75088456,  0.48023952,  0.30820896,  0.12975367,\n",
    "        -0.14764154, -0.03065804,  0.16400572, -0.06636385, -0.28761705,\n",
    "        -0.42660171, -0.71466386, -0.68566641, -0.41728801, -0.54191152,\n",
    "        -0.7746508 , -0.85873075, -1.09411607, -1.12582753, -0.79532328,\n",
    "        -0.76748692, -0.97215784, -1.00357236, -1.1456198 , -1.21128119]),\n",
    " 'test3': array([-8.49823380e-01, -6.55447245e-01, -8.01405061e-01, -8.01620842e-01,\n",
    "        -8.42505127e-01, -9.24141791e-01, -5.79615279e-01, -2.42038190e-01,\n",
    "        -3.13645173e-01, -3.17887991e-01, -2.82737735e-01, -3.73991209e-01,\n",
    "        -1.01355845e-01,  3.24389516e-01,  3.27698347e-01,  2.81832628e-01,\n",
    "         3.44653107e-01,  2.41316269e-01,  3.94031270e-01,  8.35604503e-01,\n",
    "         9.04315779e-01,  7.90736520e-01,  8.25914347e-01,  7.05606028e-01,\n",
    "         7.11396160e-01,  1.09771926e+00,  1.21948756e+00,  1.03528653e+00,\n",
    "         9.98189228e-01,  8.60321416e-01,  7.22633186e-01,  1.00102523e+00,\n",
    "         1.16672808e+00,  9.37324861e-01,  8.07514850e-01,  6.59629726e-01,\n",
    "         4.13545175e-01,  5.60488009e-01,  7.66411189e-01,  5.41747263e-01,\n",
    "         3.28458958e-01,  1.85336523e-01, -1.10548118e-01, -8.77109321e-02,\n",
    "         1.57594484e-01, -1.63770953e-04, -2.61771287e-01, -3.83448676e-01,\n",
    "        -6.62491682e-01, -7.32623969e-01]),\n",
    " '_31': [<matplotlib.lines.Line2D at 0x28f65f130>],\n",
    " '_i32': \"fft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    " 'fft_result': array([ 10.8219627 +0.00000000e+00j, -20.27626833+7.12908344e+00j,\n",
    "         -2.30219353+1.48420426e+00j,  -1.03140446+8.71880203e-01j,\n",
    "         -0.64019691+6.07061886e-01j,  -0.46352351+4.46139691e-01j,\n",
    "         -0.36156284+3.20495717e-01j,  -0.27528062+1.66187559e-01j,\n",
    "          1.45020645-4.38591808e+00j,  -0.34826886+4.24607974e-01j,\n",
    "         -0.29373581+2.92813849e-01j,  -0.26643897+2.28720651e-01j,\n",
    "         -0.24600045+1.81751604e-01j,  -0.22609238+1.39399371e-01j,\n",
    "         -0.19933879+9.14537400e-02j,  -0.13824127+5.67066362e-03j,\n",
    "          1.38071213-1.74568629e+00j,  -0.38105484+2.53978917e-01j,\n",
    "         -0.30873856+1.57474219e-01j,  -0.28492771+1.16699273e-01j,\n",
    "         -0.2729384 +8.95625172e-02j,  -0.26584681+6.79996226e-02j,\n",
    "         -0.26139223+4.92731197e-02j,  -0.25862686+3.21315914e-02j,\n",
    "         -0.25710397+1.58677940e-02j,  -0.25661664-8.32667268e-17j,\n",
    "         -0.25710397-1.58677940e-02j,  -0.25862686-3.21315914e-02j,\n",
    "         -0.26139223-4.92731197e-02j,  -0.26584681-6.79996226e-02j,\n",
    "         -0.2729384 -8.95625172e-02j,  -0.28492771-1.16699273e-01j,\n",
    "         -0.30873856-1.57474219e-01j,  -0.38105484-2.53978917e-01j,\n",
    "          1.38071213+1.74568629e+00j,  -0.13824127-5.67066362e-03j,\n",
    "         -0.19933879-9.14537400e-02j,  -0.22609238-1.39399371e-01j,\n",
    "         -0.24600045-1.81751604e-01j,  -0.26643897-2.28720651e-01j,\n",
    "         -0.29373581-2.92813849e-01j,  -0.34826886-4.24607974e-01j,\n",
    "          1.45020645+4.38591808e+00j,  -0.27528062-1.66187559e-01j,\n",
    "         -0.36156284-3.20495717e-01j,  -0.46352351-4.46139691e-01j,\n",
    "         -0.64019691-6.07061886e-01j,  -1.03140446-8.71880203e-01j,\n",
    "         -2.30219353-1.48420426e+00j, -20.27626833-7.12908344e+00j]),\n",
    " '_i33': \"time = np.linspace(50,100,50)\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    " 'time': array([ 50.        ,  51.02040816,  52.04081633,  53.06122449,\n",
    "         54.08163265,  55.10204082,  56.12244898,  57.14285714,\n",
    "         58.16326531,  59.18367347,  60.20408163,  61.2244898 ,\n",
    "         62.24489796,  63.26530612,  64.28571429,  65.30612245,\n",
    "         66.32653061,  67.34693878,  68.36734694,  69.3877551 ,\n",
    "         70.40816327,  71.42857143,  72.44897959,  73.46938776,\n",
    "         74.48979592,  75.51020408,  76.53061224,  77.55102041,\n",
    "         78.57142857,  79.59183673,  80.6122449 ,  81.63265306,\n",
    "         82.65306122,  83.67346939,  84.69387755,  85.71428571,\n",
    "         86.73469388,  87.75510204,  88.7755102 ,  89.79591837,\n",
    "         90.81632653,  91.83673469,  92.85714286,  93.87755102,\n",
    "         94.89795918,  95.91836735,  96.93877551,  97.95918367,\n",
    "         98.97959184, 100.        ]),\n",
    " 'fft_freq': array([ 0.    ,  0.0196,  0.0392,  0.0588,  0.0784,  0.098 ,  0.1176,\n",
    "         0.1372,  0.1568,  0.1764,  0.196 ,  0.2156,  0.2352,  0.2548,\n",
    "         0.2744,  0.294 ,  0.3136,  0.3332,  0.3528,  0.3724,  0.392 ,\n",
    "         0.4116,  0.4312,  0.4508,  0.4704, -0.49  , -0.4704, -0.4508,\n",
    "        -0.4312, -0.4116, -0.392 , -0.3724, -0.3528, -0.3332, -0.3136,\n",
    "        -0.294 , -0.2744, -0.2548, -0.2352, -0.2156, -0.196 , -0.1764,\n",
    "        -0.1568, -0.1372, -0.1176, -0.098 , -0.0784, -0.0588, -0.0392,\n",
    "        -0.0196]),\n",
    " '_i34': \"time = np.linspace(50,100,50)\\n\\n\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\n\\n# Calculate the squared amplitude or power\\nfft_power = np.abs(fft_result) ** 2\\n\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    " 'fft_power': array([2.53522354e-01, 1.00000000e+00, 1.62418940e-02, 3.94840727e-03,\n",
    "        1.68497612e-03, 8.95971153e-04, 5.05346341e-04, 2.23828387e-04,\n",
    "        4.61940365e-02, 6.52846744e-04, 3.72378715e-04, 2.66917688e-04,\n",
    "        2.02510416e-04, 1.52721750e-04, 1.04123063e-04, 4.14390458e-05,\n",
    "        1.07236218e-02, 4.53961860e-04, 2.60022500e-04, 2.05222077e-04,\n",
    "        1.78626810e-04, 1.63001035e-04, 1.53162898e-04, 1.47029254e-04,\n",
    "        1.43639164e-04, 1.42552163e-04, 1.43639164e-04, 1.47029254e-04,\n",
    "        1.53162898e-04, 1.63001035e-04, 1.78626810e-04, 2.05222077e-04,\n",
    "        2.60022500e-04, 4.53961860e-04, 1.07236218e-02, 4.14390458e-05,\n",
    "        1.04123063e-04, 1.52721750e-04, 2.02510416e-04, 2.66917688e-04,\n",
    "        3.72378715e-04, 6.52846744e-04, 4.61940365e-02, 2.23828387e-04,\n",
    "        5.05346341e-04, 8.95971153e-04, 1.68497612e-03, 3.94840727e-03,\n",
    "        1.62418940e-02, 1.00000000e+00]),\n",
    " '_i35': \"time = np.linspace(50,100,50)\\n\\n\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\n\\n# Calculate the squared amplitude or power\\nfft_power = np.abs(fft_result) ** 2\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask])\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    " 'positive_freq_mask': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "         True,  True,  True,  True,  True,  True,  True, False, False,\n",
    "        False, False, False, False, False, False, False, False, False,\n",
    "        False, False, False, False, False, False, False, False, False,\n",
    "        False, False, False, False, False]),\n",
    " '_i36': \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask])\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    " 'fft_result_gpt': array([-50.00920568+0.00000000e+00j,   0.589463  +5.93228486e-01j,\n",
    "          0.51089603+3.60358089e-01j,   0.74317915-6.12768938e-02j,\n",
    "          0.39625272-2.54515002e-01j,   0.36121965+1.67951329e-02j,\n",
    "          0.90081381+2.12022592e-02j,   1.08373324-7.48234000e-01j,\n",
    "          1.2735006 -6.60825159e-01j,  -1.54335335+2.87877545e-01j,\n",
    "         -0.61340117+9.11527582e-02j,  -0.39187576+5.22388906e-02j,\n",
    "         -0.23529283+2.31183474e-01j,   0.0500729 +1.31456474e-02j,\n",
    "         -0.06164139-1.50332069e-01j,  -0.25933826-6.09592934e-02j,\n",
    "          0.05390331+1.98572743e-01j,  -0.16578035-2.18933112e-01j,\n",
    "         -0.15259775+5.58813138e-04j,  -0.08520232-4.28690121e-02j,\n",
    "         -0.14343198+1.09437959e-02j,  -0.08148329+1.23909705e-02j,\n",
    "         -0.0826767 -5.24774037e-02j,  -0.11673006+6.11117934e-02j,\n",
    "         -0.12581202+9.00179035e-02j,  -0.12729006-6.93889390e-17j,\n",
    "         -0.12581202-9.00179035e-02j,  -0.11673006-6.11117934e-02j,\n",
    "         -0.0826767 +5.24774037e-02j,  -0.08148329-1.23909705e-02j,\n",
    "         -0.14343198-1.09437959e-02j,  -0.08520232+4.28690121e-02j,\n",
    "         -0.15259775-5.58813138e-04j,  -0.16578035+2.18933112e-01j,\n",
    "          0.05390331-1.98572743e-01j,  -0.25933826+6.09592934e-02j,\n",
    "         -0.06164139+1.50332069e-01j,   0.0500729 -1.31456474e-02j,\n",
    "         -0.23529283-2.31183474e-01j,  -0.39187576-5.22388906e-02j,\n",
    "         -0.61340117-9.11527582e-02j,  -1.54335335-2.87877545e-01j,\n",
    "          1.2735006 +6.60825159e-01j,   1.08373324+7.48234000e-01j,\n",
    "          0.90081381-2.12022592e-02j,   0.36121965-1.67951329e-02j,\n",
    "          0.39625272+2.54515002e-01j,   0.74317915+6.12768938e-02j,\n",
    "          0.51089603-3.60358089e-01j,   0.589463  -5.93228486e-01j]),\n",
    " 'fft_freq_gpt': array([ 0.    ,  0.0196,  0.0392,  0.0588,  0.0784,  0.098 ,  0.1176,\n",
    "         0.1372,  0.1568,  0.1764,  0.196 ,  0.2156,  0.2352,  0.2548,\n",
    "         0.2744,  0.294 ,  0.3136,  0.3332,  0.3528,  0.3724,  0.392 ,\n",
    "         0.4116,  0.4312,  0.4508,  0.4704, -0.49  , -0.4704, -0.4508,\n",
    "        -0.4312, -0.4116, -0.392 , -0.3724, -0.3528, -0.3332, -0.3136,\n",
    "        -0.294 , -0.2744, -0.2548, -0.2352, -0.2156, -0.196 , -0.1764,\n",
    "        -0.1568, -0.1372, -0.1176, -0.098 , -0.0784, -0.0588, -0.0392,\n",
    "        -0.0196]),\n",
    " 'fft_power_gpt': array([1.00000000e+00, 2.79651682e-04, 1.56291527e-04, 2.22346161e-04,\n",
    "        8.86849834e-05, 5.22854291e-05, 3.24646471e-04, 6.93477361e-04,\n",
    "        8.23094355e-04, 9.85562278e-04, 1.53771299e-04, 6.24951894e-05,\n",
    "        4.35073829e-05, 1.07164661e-06, 1.05558694e-05, 2.83784970e-05,\n",
    "        1.69284464e-05, 3.01548282e-05, 9.31112548e-06, 3.63753551e-06,\n",
    "        8.27395277e-06, 2.71622501e-06, 3.83431392e-06, 6.94166733e-06,\n",
    "        9.56923118e-06, 6.47871789e-06, 9.56923118e-06, 6.94166733e-06,\n",
    "        3.83431392e-06, 2.71622501e-06, 8.27395277e-06, 3.63753551e-06,\n",
    "        9.31112548e-06, 3.01548282e-05, 1.69284464e-05, 2.83784970e-05,\n",
    "        1.05558694e-05, 1.07164661e-06, 4.35073829e-05, 6.24951894e-05,\n",
    "        1.53771299e-04, 9.85562278e-04, 8.23094355e-04, 6.93477361e-04,\n",
    "        3.24646471e-04, 5.22854291e-05, 8.86849834e-05, 2.22346161e-04,\n",
    "        1.56291527e-04, 2.79651682e-04]),\n",
    " '_i37': \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    " 'fft_result_arima': array([ 38.28345735+0.00000000e+00j, -17.13102345+2.30458456e+01j,\n",
    "         -3.22881935+7.48440378e+00j,  -1.88216632+4.63015600e+00j,\n",
    "         -1.40074258+3.34764508e+00j,  -1.20098257+2.60019872e+00j,\n",
    "         -1.07940185+2.07000617e+00j,  -1.00699927+1.64152834e+00j,\n",
    "          0.76181812-3.11072781e+00j,  -1.05367456+1.52613430e+00j,\n",
    "         -1.00873762+1.24664595e+00j,  -0.98053649+1.07411423e+00j,\n",
    "         -0.95977425+9.39363756e-01j,  -0.93868439+8.24903579e-01j,\n",
    "         -0.91433468+7.21760858e-01j,  -0.89491136+6.09140001e-01j,\n",
    "         -0.56943361+1.17174871e-02j,  -0.92664194+5.14134971e-01j,\n",
    "         -1.00250395+3.65587106e-01j,  -0.86975716+3.17386696e-01j,\n",
    "         -0.89316771+2.73091887e-01j,  -0.87275778+2.27546217e-01j,\n",
    "         -0.94612801+1.46570203e-01j,  -0.90780854+9.81513659e-02j,\n",
    "         -0.83541776+9.00451552e-02j,  -0.92862508-5.55111512e-17j,\n",
    "         -0.83541776-9.00451552e-02j,  -0.90780854-9.81513659e-02j,\n",
    "         -0.94612801-1.46570203e-01j,  -0.87275778-2.27546217e-01j,\n",
    "         -0.89316771-2.73091887e-01j,  -0.86975716-3.17386696e-01j,\n",
    "         -1.00250395-3.65587106e-01j,  -0.92664194-5.14134971e-01j,\n",
    "         -0.56943361-1.17174871e-02j,  -0.89491136-6.09140001e-01j,\n",
    "         -0.91433468-7.21760858e-01j,  -0.93868439-8.24903579e-01j,\n",
    "         -0.95977425-9.39363756e-01j,  -0.98053649-1.07411423e+00j,\n",
    "         -1.00873762-1.24664595e+00j,  -1.05367456-1.52613430e+00j,\n",
    "          0.76181812+3.11072781e+00j,  -1.00699927-1.64152834e+00j,\n",
    "         -1.07940185-2.07000617e+00j,  -1.20098257-2.60019872e+00j,\n",
    "         -1.40074258-3.34764508e+00j,  -1.88216632-4.63015600e+00j,\n",
    "         -3.22881935-7.48440378e+00j, -17.13102345-2.30458456e+01j]),\n",
    " 'fft_freq_arima': array([ 0.    ,  0.0196,  0.0392,  0.0588,  0.0784,  0.098 ,  0.1176,\n",
    "         0.1372,  0.1568,  0.1764,  0.196 ,  0.2156,  0.2352,  0.2548,\n",
    "         0.2744,  0.294 ,  0.3136,  0.3332,  0.3528,  0.3724,  0.392 ,\n",
    "         0.4116,  0.4312,  0.4508,  0.4704, -0.49  , -0.4704, -0.4508,\n",
    "        -0.4312, -0.4116, -0.392 , -0.3724, -0.3528, -0.3332, -0.3136,\n",
    "        -0.294 , -0.2744, -0.2548, -0.2352, -0.2156, -0.196 , -0.1764,\n",
    "        -0.1568, -0.1372, -0.1176, -0.098 , -0.0784, -0.0588, -0.0392,\n",
    "        -0.0196]),\n",
    " 'fft_power_arima': array([1.00000000e+00, 5.62615969e-01, 4.53333290e-02, 1.70445557e-02,\n",
    "        8.98512538e-03, 5.59720468e-03, 3.71857804e-03, 2.53043418e-03,\n",
    "        6.99838473e-03, 2.34665786e-03, 1.75466511e-03, 1.44319038e-03,\n",
    "        1.23058300e-03, 1.06548149e-03, 9.25849648e-04, 7.99603855e-04,\n",
    "        2.21333805e-04, 7.66227038e-04, 7.76917406e-04, 5.84878759e-04,\n",
    "        5.95192405e-04, 5.55042706e-04, 6.25427529e-04, 5.68870698e-04,\n",
    "        4.81727503e-04, 5.88380828e-04, 4.81727503e-04, 5.68870698e-04,\n",
    "        6.25427529e-04, 5.55042706e-04, 5.95192405e-04, 5.84878759e-04,\n",
    "        7.76917406e-04, 7.66227038e-04, 2.21333805e-04, 7.99603855e-04,\n",
    "        9.25849648e-04, 1.06548149e-03, 1.23058300e-03, 1.44319038e-03,\n",
    "        1.75466511e-03, 2.34665786e-03, 6.99838473e-03, 2.53043418e-03,\n",
    "        3.71857804e-03, 5.59720468e-03, 8.98512538e-03, 1.70445557e-02,\n",
    "        4.53333290e-02, 5.62615969e-01]),\n",
    " '_i38': \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\n#plt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i39': \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\n#plt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i40': \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i41': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.show()',\n",
    " '_i42': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.show()',\n",
    " '_i43': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    " '_i44': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    " '_i45': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n# Normalize the power spectrum\\nfft_power = fft_power / np.max(fft_power)\\nfft_power_arima = fft_power_arima / np.max(fft_power_arima)\\nfft_power_gpt = fft_power_gpt / np.max(fft_power_gpt)\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    " '_i46': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n# Normalize the power spectrum\\nfft_power = fft_power / np.max(fft_power)\\nfft_power_arima = fft_power_arima / np.max(fft_power_arima)\\nfft_power_gpt = fft_power_gpt / np.max(fft_power_gpt)\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq >= 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    " '_i47': \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " 'generate_autoregressive_series': <function __main__.generate_autoregressive_series(n_lags, decay_rate, length=100)>,\n",
    " 'length': 100,\n",
    " 'n_lags_list': [5, 50, 150],\n",
    " 'decay_rate': -0.5,\n",
    " 'n_lags': 150,\n",
    " 'time_series': array([-0.50424686,  1.37573152,  0.71285812, -1.09337974, -1.61653362,\n",
    "         0.6853512 , -0.37312368,  1.50427309,  0.01644906, -0.88922894,\n",
    "        -1.4263528 ,  0.02577807,  1.08788203,  0.35412927,  0.54455245,\n",
    "        -0.16009542, -1.51774384,  0.17103497, -0.92733637,  0.1105833 ,\n",
    "         0.09526325, -1.26938151, -0.03957398, -0.55873272, -2.06094502,\n",
    "        -0.34427465,  1.99185855, -1.66208958, -1.16222327, -1.39339621,\n",
    "        -0.78397035,  0.03864163, -1.70194318,  0.81069076, -0.65759863,\n",
    "        -0.24789366,  0.25810964, -0.59758127,  0.77476457,  1.84428907,\n",
    "         0.84024977,  0.97700921, -2.05927286,  0.59541377,  0.34905839,\n",
    "         0.19227295, -0.94715642,  0.7571659 ,  1.11126631,  0.46477044,\n",
    "        -0.58787603,  1.05282843, -0.33484999,  0.50861347, -1.48731505,\n",
    "        -1.60372562,  1.512159  , -0.03842358,  0.22389007, -2.02014872,\n",
    "         0.47912526, -2.03009049, -1.51662378,  0.11440123, -1.03269636,\n",
    "         1.51413582,  1.15830166,  0.6518505 ,  0.77329162, -1.04791465,\n",
    "        -0.40866289, -0.12428645,  0.46803623,  2.49381497,  0.73216499,\n",
    "        -1.9635111 ,  1.40261568, -0.92063253,  0.27023893,  0.50720666,\n",
    "        -0.1707714 , -0.23133199,  0.08628002, -0.40585947,  0.23499154,\n",
    "        -0.77199238, -0.43813932,  0.9637006 , -0.54213742, -0.15904474,\n",
    "         1.51876031, -1.70911356, -1.37445416,  1.68234864, -0.68293768,\n",
    "         1.06389174, -0.04166097,  0.47342484,  0.60457459,  0.49932921]),\n",
    " '_i48': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i49': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i50': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i51': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j] + time_series[i-1]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i52': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j] + time_series[i-j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i53': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i54': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i55': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i56': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.05\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i57': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    " '_i58': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA], verbose=False, parallel=False)\\n\\n                                                    plt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    " '_i59': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA], verbose=False, parallel=False)\\n\\n                                                \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    " '_i60': 'time_series',\n",
    " '_60': array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "         1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "        -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "         0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "        -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "         0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "         0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "         1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "        -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "         0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149,\n",
    "         0.18718621, -0.4757239 , -1.64344264, -0.09358268,  0.10309571,\n",
    "         0.095137  ,  1.06676763, -1.8428797 , -1.04016223, -0.1471965 ,\n",
    "         1.1094952 , -1.38843155, -1.34927948,  2.2983403 , -0.5684549 ,\n",
    "         0.74208654,  0.46162906,  1.62492308, -0.75288572, -0.6291802 ,\n",
    "         0.46314307,  0.64471457,  0.19379909, -1.41415266, -1.23427455,\n",
    "        -0.40777303,  0.81886616,  0.40483561, -0.5155421 , -0.566217  ,\n",
    "        -0.29358193,  0.88388512, -1.1597346 , -0.41722568,  0.55364882,\n",
    "         0.32269808, -1.18005105, -0.63975452,  1.24861017,  1.32987551,\n",
    "         0.75395216,  0.47690589,  0.29144071,  0.84784154,  0.82063337,\n",
    "         0.44373127, -1.11129098,  0.71013579,  0.89859217, -1.24352553]),\n",
    " '_i61': 'time_series[0:50]',\n",
    " '_61': array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "         1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "        -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "         0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "        -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "         0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "         0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "         1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "        -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "         0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149]),\n",
    " '_i62': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\n                                                \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    " 'pred_dict_arima_ar': {'NLL/D': 1.4577798391636538,\n",
    "  'samples':          50        51        52        53        54        55        56  \\\n",
    "  0 -1.200867 -1.391889 -0.911250  0.533166  0.737256  0.473448 -0.846662   \n",
    "  1 -1.200867 -0.791836  1.102824  0.402191 -1.773848  0.127751 -1.380472   \n",
    "  2 -1.200867 -1.783871  0.630737 -0.709073  1.096480 -0.331953 -0.164358   \n",
    "  3 -1.200867 -0.939878 -1.766572 -0.537224 -0.388827 -0.115778 -3.050917   \n",
    "  4 -1.200867 -0.475558 -1.776969 -1.986510  0.911533 -0.591239  0.765721   \n",
    "  5 -1.200867 -0.596036 -1.738756 -2.077760 -2.456168 -2.850542 -1.300000   \n",
    "  6 -1.200867  0.559573 -1.092790 -2.303272 -1.011142 -2.326803 -1.279527   \n",
    "  7 -1.200867 -1.220552 -0.960588  0.430052 -0.252699  0.985055  1.241898   \n",
    "  8 -1.200867  1.113144 -0.449773  0.532391  0.582174  1.018656 -0.282407   \n",
    "  9 -1.200867 -1.012151 -2.230767 -0.716813 -1.463290  0.220661 -1.304831   \n",
    "  \n",
    "           57        58        59  ...        90        91        92        93  \\\n",
    "  0 -2.272220  0.087689  0.182865  ...  2.071837  0.299285  0.770130  1.375316   \n",
    "  1 -2.427253 -2.169239 -3.140884  ... -1.486399 -2.785768 -0.265543  0.197259   \n",
    "  2 -0.017975 -2.248502 -1.704624  ... -1.414144 -3.484013 -1.020121 -3.925099   \n",
    "  3 -1.754046 -2.045794 -1.979907  ...  0.864189 -1.084686 -0.876160 -2.435782   \n",
    "  4 -0.985317 -0.854084 -0.249350  ...  1.543715  2.033192  1.147694  1.002903   \n",
    "  5  1.271776  0.204725 -1.497253  ... -1.378420 -2.203122 -2.090758 -1.108570   \n",
    "  6 -0.574731 -1.249339 -0.739728  ... -1.099999 -1.844211 -2.210167 -1.241498   \n",
    "  7 -0.046784 -0.736246 -0.644699  ...  3.168624 -0.822660  1.118764  0.206304   \n",
    "  8 -2.517085  1.442114 -0.632236  ... -0.464924 -0.316805 -0.718189 -1.420316   \n",
    "  9 -1.367846  0.308918  0.769452  ... -0.464899  0.482216 -0.712791 -0.046376   \n",
    "  \n",
    "           94        95        96        97        98        99  \n",
    "  0  1.279699  0.908657  2.954422  2.249194  2.254294  4.229108  \n",
    "  1 -2.868701 -2.109338 -2.145032 -1.367724 -2.474864 -1.875166  \n",
    "  2 -3.547440 -2.084575 -1.815467 -1.434624 -3.481211 -1.220513  \n",
    "  3 -1.584221 -0.789786 -1.423286 -1.799061 -1.306903 -2.507339  \n",
    "  4  0.565011  0.634303  0.007515  1.848120  2.237898  1.854732  \n",
    "  5 -0.137483 -0.189595 -3.283708 -3.099076 -1.620352 -2.334777  \n",
    "  6 -0.994181 -2.616664 -0.580241 -0.972792 -2.746073 -1.238839  \n",
    "  7  0.604256  0.595462  0.172098 -0.212020  0.466873 -1.862443  \n",
    "  8 -1.947941  1.864671 -0.316812  1.022591 -1.181753 -0.208844  \n",
    "  9  0.728844 -0.755448  0.575771  0.781290  0.380046 -1.526102  \n",
    "  \n",
    "  [10 rows x 50 columns],\n",
    "  'median': 50   -1.200867\n",
    "  51   -0.865857\n",
    "  52   -1.026689\n",
    "  53   -0.623148\n",
    "  54   -0.320763\n",
    "  55    0.005987\n",
    "  56   -1.063094\n",
    "  57   -1.176582\n",
    "  58   -0.795165\n",
    "  59   -0.692213\n",
    "  60   -0.260432\n",
    "  61   -0.677853\n",
    "  62   -0.673369\n",
    "  63   -0.836995\n",
    "  64   -0.345208\n",
    "  65   -0.321778\n",
    "  66   -0.319927\n",
    "  67   -0.440152\n",
    "  68   -0.247596\n",
    "  69   -0.361094\n",
    "  70   -0.375960\n",
    "  71   -0.329688\n",
    "  72   -0.423445\n",
    "  73   -0.829610\n",
    "  74   -1.581793\n",
    "  75   -0.001577\n",
    "  76   -0.607717\n",
    "  77   -0.233671\n",
    "  78   -0.546659\n",
    "  79   -0.247173\n",
    "  80   -0.309863\n",
    "  81   -0.298311\n",
    "  82    0.108235\n",
    "  83   -0.269182\n",
    "  84   -1.353898\n",
    "  85    0.366705\n",
    "  86   -0.536231\n",
    "  87   -0.424015\n",
    "  88   -0.447724\n",
    "  89   -0.556991\n",
    "  90   -0.464912\n",
    "  91   -0.953673\n",
    "  92   -0.715490\n",
    "  93   -0.577473\n",
    "  94   -0.565832\n",
    "  95   -0.472522\n",
    "  96   -0.448526\n",
    "  97   -0.592406\n",
    "  98   -1.244328\n",
    "  99   -1.382471\n",
    "  dtype: float64,\n",
    "  'info': {'Method': 'ARIMA', 'p': 12, 'd': 1},\n",
    "  'best_hyper': {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': {'base': 10,\n",
    "    'prec': 3,\n",
    "    'signed': True,\n",
    "    'fixed_length': False,\n",
    "    'max_val': 10000000.0,\n",
    "    'time_sep': ', ',\n",
    "    'bit_sep': '',\n",
    "    'plus_sign': '',\n",
    "    'minus_sign': '-',\n",
    "    'half_bin_correction': True,\n",
    "    'decimal_point': '',\n",
    "    'missing_str': ' Nan'}}},\n",
    " '_62': Text(24.00000000000002, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    " '_i63': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(time_series[50:100],\\'k\\')                                         \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    " '_63': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    " '_i64': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    " '_64': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    " '_i65': \"pred_dict_gpt_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    " 'pred_dict_gpt_ar': {'samples':          50        51        52        53        54        55        56  \\\n",
    "  0  0.663043  1.962294  0.431143 -0.062532  0.655955  0.200761 -0.551650   \n",
    "  1  1.943560  2.046852  0.115191 -0.061013  0.654436 -0.169368 -0.718740   \n",
    "  2  0.188609  2.425083  0.749626 -0.533928 -1.690393 -0.511143  1.536974   \n",
    "  3  0.907602  0.746588  0.713170 -0.292407 -0.042279  0.629625  0.158229   \n",
    "  4  1.376467  0.271648 -1.695963 -1.220010 -0.260508  0.831146 -1.153174   \n",
    "  5  2.022041  1.342542  0.641271  1.191149  0.340003 -0.072659 -1.114186   \n",
    "  6  2.280271  1.655456  0.971906  0.675195 -0.058988 -0.180508 -1.736976   \n",
    "  7  1.447353  1.505582  0.275192  0.432155  1.074692  0.202280 -1.490392   \n",
    "  8  0.373927  1.385074  1.455961  0.548106 -0.139495  0.857475  0.458991   \n",
    "  9  1.478746  1.764824  0.126330  1.304061  0.360256 -0.302534  0.707601   \n",
    "  \n",
    "           57        58        59  ...        90        91        92        93  \\\n",
    "  0 -1.872167  0.988615 -0.454434  ... -1.935965 -1.935965 -1.935965 -1.935965   \n",
    "  1 -1.880774  0.803804 -0.668107  ...  2.019510  2.019510  2.019510  2.019510   \n",
    "  2 -0.468105  2.037231 -0.139495  ...  1.729887  0.065570 -0.625575 -1.177478   \n",
    "  3 -1.061021 -0.858994  1.488873  ... -0.262027 -0.517219 -1.301023  0.241268   \n",
    "  4 -1.040261  0.104558  1.420518  ... -0.730892 -1.789128 -1.404821  1.480265   \n",
    "  5 -1.702545  1.311150  0.235192  ...  0.935450  1.452923  0.405826  0.274686   \n",
    "  6 -2.274702  2.139004  2.477741  ... -0.855450 -1.924319  0.699499 -0.449371   \n",
    "  7 -1.883306 -0.218989  0.500510  ...  1.491911  1.491911  1.491911  1.491911   \n",
    "  8  0.058988  0.283293 -0.605321  ... -0.527346  0.105570 -0.559245 -0.617473   \n",
    "  9  0.753171 -0.144558 -1.277225  ... -0.839247  1.331403 -0.468105 -1.225579   \n",
    "  \n",
    "           94        95        96        97        98        99  \n",
    "  0 -1.935965 -1.935965 -1.935965 -1.935965 -1.935965 -1.935965  \n",
    "  1  2.019510  2.019510  2.019510  2.019510  2.019510  2.019510  \n",
    "  2  1.374948  2.266094 -2.434197 -1.297985  0.209875  0.972413  \n",
    "  3 -1.443303 -1.443303 -1.443303 -1.443303 -1.443303 -1.443303  \n",
    "  4  0.850893  0.548106 -0.124811  2.174954  0.986084 -0.468611  \n",
    "  5  0.003797  0.637220 -0.896463  0.491903  0.673676 -1.332922  \n",
    "  6 -0.136457 -1.351150 -2.524830 -2.524830 -2.524830 -2.524830  \n",
    "  7  1.491911  1.491911  1.491911  1.491911  1.491911  1.491911  \n",
    "  8 -1.282289  0.051393 -0.333927 -0.004304 -0.892412 -1.706090  \n",
    "  9 -2.102548  0.599752  0.768361  0.768361  0.768361  0.768361  \n",
    "  \n",
    "  [10 rows x 50 columns],\n",
    "  'median': 50    1.411910\n",
    "  51    1.580519\n",
    "  52    0.536207\n",
    "  53    0.185571\n",
    "  54    0.148862\n",
    "  55    0.064051\n",
    "  56   -0.635195\n",
    "  57   -1.381783\n",
    "  58    0.543549\n",
    "  59    0.047848\n",
    "  60    0.608359\n",
    "  61    0.502029\n",
    "  62    1.316972\n",
    "  63    0.332914\n",
    "  64   -0.171647\n",
    "  65   -0.336712\n",
    "  66    0.200761\n",
    "  67    0.491143\n",
    "  68   -1.158743\n",
    "  69   -0.041013\n",
    "  70    0.171394\n",
    "  71   -0.589625\n",
    "  72   -0.828361\n",
    "  73    0.664309\n",
    "  74    1.063300\n",
    "  75    0.194938\n",
    "  76    0.316965\n",
    "  77    0.198229\n",
    "  78    0.802032\n",
    "  79   -0.539245\n",
    "  80   -0.118735\n",
    "  81    0.426586\n",
    "  82   -0.150887\n",
    "  83   -0.565321\n",
    "  84    0.657980\n",
    "  85    0.302787\n",
    "  86    0.100254\n",
    "  87    0.111393\n",
    "  88    0.661524\n",
    "  89   -0.462535\n",
    "  90   -0.394687\n",
    "  91    0.085570\n",
    "  92   -0.513675\n",
    "  93   -0.104051\n",
    "  94   -0.066330\n",
    "  95    0.573929\n",
    "  96   -0.615195\n",
    "  97    0.243799\n",
    "  98    0.441776\n",
    "  99   -0.900767\n",
    "  dtype: float64,\n",
    "  'info': {'Method': 'gpt-4'},\n",
    "  'completions_list': [['1309, 3875, 851, -123, 1295, 396, -1089, -3697, 1952, -897, 4185, 842, 2194, 2544, 1076, -796, -117, 1378, -1394, 516, 1188, -2305, -1904, 1908, 2701, 284, 3364, 1288, 1901, -1467, 225, -1620, -1428, -3139, 263, -1080, -210, -2023, -3823',\n",
    "    '3838, 4042, 227, -120, 1292, -334, -1419, -3714, 1587, -1319, 4290, 1140, 2476, 2906, 1285, -533, 138, 1618, -1054, 864, 1169, -2431, -1674, 2261, 3041, 485, 3856, 1486, 2227, -1212, 376, -1293, -1437, -3109, 241, -726, 102, -2127, -4172, 3988',\n",
    "    '372, 4789, 1480, -1054, -3338, -1009, 3035, -924, 4023, -275, 974, -2754, 1874, -124, -1342, 4226, -76, 2229, -4178, 1442, 103, -3280, -2195, 1462, 3822, -3197, -327, -2016, 4021, -2972, -2172, 3720, 737, 2519, -2214, -320, -1685, 2217, -3203, -2175, 3416, 129, -1235, -2325, 2715, 4475, -4807, -2563, 414, 1920, -4298, 434, -2083, -2240, -4691, 3177, 24, -1835, -',\n",
    "    '1792, 1474, 1408, -577, -83, 1243, 312, -2095, -1696, 2940, 2580, -911, 2942, -219, 795, -895, 148, -2190, -2672, -724, 573, -1800, 2230, 964, 2385, 1975, -288, -193, 837, -1450, -694, 1689, -1333, -2840, 2532, 2605, 362, 1559, 1531, -1470, -517, -1021, -2569, 476, -2850',\n",
    "    '2718, 536, -3349, -2409, -514, 1641, -2277, -2054, 206, 2805, -1138, 1744, 2745, -986, -2945, 124, 4598, 1258, 912, -4095, -1801, -528, -2838, -1523, -209, -820, -3242, -990, 628, 3752, -1444, 853, -2502, -950, 2686, -854, -1562, 2362, 2110, -356, -1443, -3533, -2774, 2923, 1680, 1082, -246, 4295, 1947, -925, -669, 3599, -1487, -3473, 3865, 2022, -2065, -1601, -1365, ',\n",
    "    '3993, 2651, 1266, 2352, 671, -143, -2200, -3362, 2589, 464, -1986, -826, 4060, 3165, 1724, 2623, -1057, 1056, -1904, -1408, -3663, 1575, -1597, 2, -2063, -4271, 2926, 4572, 2316, 572, 2068, -440, 2319, -1282, 908, -496, -3426, -1119, 3292, 1651, 1847, 2869, 801, 542, 7, 1258, -1770, 971, 1330, -2632, -2104, 1919, 2765, 764, 3460, 1521, 2122, -1506, ',\n",
    "    '4503, 3269, 1919, 1333, -116, -356, -3430, -4492, 4224, 4893, 1428, 695, 1742, 580, -1139, -3979, 1671, -1023, 4766, 1407, 3052, 3165, 1607, -138, 347, 1995, -1341, 762, 1122, -2841, -1935, 2450, 3073, 277, 4066, 1516, 2530, -1468, 475, -1843, -1689, -3800, 1381, -887, -269, -2668, -4986',\n",
    "    '2858, 2973, 543, 853, 2122, 399, -2943, -3719, -432, 988, 3426, 2653, 1256, -1407, -1589, -4125, 1155, 883, -2992, -2476, -2214, -3449, -943, 4850, 1588, 2391, 2946\\n',\n",
    "    '738, 2735, 2875, 1082, -275, 1693, 906, 116, 559, -1195, -3395, 3137, 3378, 734, 461, 942, 644, -629, -3135, 1159, -1124, 3282, 807, 1859, 2195, 922, -507, 20, 1183, -917, 591, 831, -2001, -1404, 1690, 2303, 293, 2942, 1081, 1663, -1041, 208, -1104, -1219, -2532, 101, -659, -8, -1762, -3369',\n",
    "    '2920, 3485, 249, 2575, 711, -597, 1397, 1487, -285, -2522, -1973, 3839, 2725, 1866, -2583, -1758, 2873, 110, -3142, -678, 666, 3175, -1736, 1161, 2004, -1415, 1540, -1661, 1266, -355, -2009, -1254, 1718, 3490, -1376, 2789, 1224, -2674, 3752, -4247, -1657, 2629, -924, -2420, -4152, 1184, 1517']],\n",
    "  'input_strs': ('-3458, 1160, -2467, -2547, -931, 2069, 1225, 150, 717, -1520, -4315, 3986, 4290, 934, 587, 1199, 820, -800, -3985, 1475, -1431, 4178, 1028, 2364, 2794, 1173, -645, 26, 1506, -1166, 752, 1057, -2543, -1786, 2149, 2929, 373, 3744, 1374, 2115, -1324, 264, -1405, -1549, -3221, 129, -838, -10, -2239, -4284, ',),\n",
    "  'best_hyper': {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': {'base': 10,\n",
    "    'prec': 3,\n",
    "    'signed': True,\n",
    "    'fixed_length': False,\n",
    "    'max_val': 10000000.0,\n",
    "    'time_sep': ', ',\n",
    "    'bit_sep': '',\n",
    "    'plus_sign': '',\n",
    "    'minus_sign': '-',\n",
    "    'half_bin_correction': True,\n",
    "    'decimal_point': '',\n",
    "    'missing_str': ' Nan'}}},\n",
    " '_i66': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_gpt_ar[\\'median\\'],\\'r\\')\\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\n\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    " '_66': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    " '_i67': 'import statsmodels.api as sm',\n",
    " 'sm': <module 'statsmodels.api' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/statsmodels/api.py'>,\n",
    " '_i68': 'import statsmodels.api as sm\\nar_model = sm.tsa.AR(time_series[50:100])\\nar_results = ar_model.fit(maxlag=150)  # You can adjust the maximum number of lags as needed\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    " '_i69': 'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg((time_series[50:100], lags=150)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    " '_i70': 'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg((time_series[50:100], lags=50)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    " '_i71': 'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg(time_series[50:100], lags=50)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    " '_i72': 'import statsmodels.api as sm\\n\\nres = sm.tsa.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    " '_i73': 'import statsmodels.api as sm\\n\\nres = sm.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    " '_i74': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    " 'statsmodels': <module 'statsmodels' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/statsmodels/__init__.py'>,\n",
    " '_i75': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    " 'res': <statsmodels.tsa.ar_model.AutoRegResultsWrapper at 0x293434910>,\n",
    " '_i76': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term',\n",
    " 'ar_coefficients': array([-0.57073806, -0.25504165, -0.43684139, -0.39442566, -0.3266803 ,\n",
    "        -0.09596204, -0.1837547 , -0.01177321, -0.12021627, -0.1537689 ,\n",
    "         0.06362805, -0.3066356 , -0.18471353, -0.14508358, -0.45184114,\n",
    "        -0.12185355,  0.1268503 , -0.33401473, -0.45442659,  0.04557276]),\n",
    " '_i77': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=49).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients',\n",
    " '_i78': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients',\n",
    " '_78': array([ 0.42459049, -0.71090158,  0.28381361,  0.19212327, -0.10471756,\n",
    "         0.23711138, -0.25102066, -0.39702093, -0.19640616, -0.40924017,\n",
    "        -0.35815403,  0.14991523, -0.01944757,  0.11782569, -0.29788144,\n",
    "        -0.19526565, -0.48413894, -0.03631446, -0.47901333,  0.0322904 ]),\n",
    " '_i79': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'ko')\\nplt.plot(ar_coefficients_gpt,'ro')\\nplt.plot(ar_coefficients_arima,'ro')\",\n",
    " 'res_gpt': <statsmodels.tsa.ar_model.AutoRegResultsWrapper at 0x29f6f66a0>,\n",
    " 'res_arima': <statsmodels.tsa.ar_model.AutoRegResultsWrapper at 0x29e004f70>,\n",
    " 'ar_coefficients_gpt': y.L1    -0.046825\n",
    " y.L2     0.052282\n",
    " y.L3     0.194633\n",
    " y.L4     0.087136\n",
    " y.L5    -0.543619\n",
    " y.L6    -0.341012\n",
    " y.L7     0.470610\n",
    " y.L8    -0.123455\n",
    " y.L9    -0.069355\n",
    " y.L10   -0.370162\n",
    " y.L11   -0.033067\n",
    " y.L12    0.198632\n",
    " y.L13   -0.053798\n",
    " y.L14   -0.000506\n",
    " y.L15   -0.137116\n",
    " y.L16   -0.130382\n",
    " y.L17    0.228882\n",
    " y.L18   -0.298774\n",
    " y.L19   -0.094278\n",
    " y.L20    0.101257\n",
    " dtype: float64,\n",
    " 'ar_coefficients_arima': y.L1     0.000759\n",
    " y.L2     0.364658\n",
    " y.L3     0.399012\n",
    " y.L4     0.192251\n",
    " y.L5    -0.025352\n",
    " y.L6     0.157869\n",
    " y.L7     0.061042\n",
    " y.L8     0.121403\n",
    " y.L9     0.303031\n",
    " y.L10    0.566523\n",
    " y.L11    0.050437\n",
    " y.L12   -0.119027\n",
    " y.L13   -0.091215\n",
    " y.L14    0.062577\n",
    " y.L15    0.452950\n",
    " y.L16   -0.212350\n",
    " y.L17    0.361798\n",
    " y.L18    0.311891\n",
    " y.L19   -0.544964\n",
    " y.L20   -0.407397\n",
    " dtype: float64,\n",
    " '_79': [<matplotlib.lines.Line2D at 0x29fe344c0>],\n",
    " '_i80': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'ko')\\nplt.plot(ar_coefficients_gpt,'ro')\\nplt.plot(ar_coefficients_arima,'bo')\",\n",
    " '_80': [<matplotlib.lines.Line2D at 0x2adb847c0>],\n",
    " '_i81': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    " '_81': [<matplotlib.lines.Line2D at 0x2adc2b3d0>],\n",
    " '_i82': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=10).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    " '_82': [<matplotlib.lines.Line2D at 0x29fe41e80>],\n",
    " '_i83': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=30).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=30).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=30).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    " '_i84': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\\nplt.savefig('ar-coeff.png')\",\n",
    " '_i85': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_gpt_ar[\\'median\\'],\\'r\\')\\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\n\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\n\\nplt.savefig(\\'autoregressive.png\\')',\n",
    " '_i86': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,\\'k-\\')\\nplt.plot(ar_coefficients_gpt,\\'r-\\')\\nplt.plot(ar_coefficients_arima,\\'b-\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\n\\nplt.savefig(\\'ar-coeff.png\\')',\n",
    " '_i87': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\n\\nplt.savefig('autoregressive.png')\",\n",
    " '_i88': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\n\\nplt.savefig('autoregressive.png')\",\n",
    " '_i89': 'def compute_rmse(actual_values, predicted_values):\\n    \"\"\"\\n    Compute Root Mean Square Error (RMSE) between two time series.\\n\\n    Args:\\n        actual_values (array-like): Actual values of the time series.\\n        predicted_values (array-like): Predicted values of the time series.\\n\\n    Returns:\\n        float: RMSE value.\\n    \"\"\"\\n    # Ensure both arrays have the same length\\n    if len(actual_values) != len(predicted_values):\\n        raise ValueError(\"Lengths of actual_values and predicted_values must be the same.\")\\n\\n    # Convert input arrays to numpy arrays\\n    actual_values = np.array(actual_values)\\n    predicted_values = np.array(predicted_values)\\n\\n    # Compute the squared error between actual and predicted values\\n    squared_error = (actual_values - predicted_values) ** 2\\n\\n    # Compute the mean of squared errors\\n    mean_squared_error = np.mean(squared_error)\\n\\n    # Compute the square root of mean squared error (RMSE)\\n    rmse = np.sqrt(mean_squared_error)\\n\\n    return rmse',\n",
    " 'compute_rmse': <function __main__.compute_rmse(actual_values, predicted_values)>,\n",
    " '_i90': \"rmse_gpt = compute_rmse(time_series[50:100],pred_dict_gpt_ar['median'])\",\n",
    " 'rmse_gpt': 1.2499976890076867,\n",
    " '_i91': \"rmse_gpt = compute_rmse(time_series[50:100],pred_dict_gpt_ar['median'])\\nrmse_arima = compute_rmse(time_series[50:100],pred_dict_arima_ar['median'])\\nprint(rmse_gpt,rmse_arima)\",\n",
    " 'rmse_arima': 1.3168889243556772,\n",
    " '_i92': \"rmse_gpt_sin = compute_rmse(test2,pred_dict_gpt_sum['median'])\\nrmse_arima_sin = compute_rmse(test2],pred_dict_arima_sum['median'])\\nprint(rmse_gpt_sin,rmse_arima_sin)\",\n",
    " '_i93': \"rmse_gpt_sin = compute_rmse(test2,pred_dict_gpt_sum['median'])\\nrmse_arima_sin = compute_rmse(test2,pred_dict_arima_sum['median'])\\nprint(rmse_gpt_sin,rmse_arima_sin)\",\n",
    " 'rmse_gpt_sin': 1.375537107427445,\n",
    " 'rmse_arima_sin': 0.7621708999819137,\n",
    " '_i94': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,\\'k-\\')\\nplt.plot(ar_coefficients_gpt,\\'r-\\')\\nplt.plot(ar_coefficients_arima,\\'b-\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\n\\nplt.savefig(\\'ar-coeff.png\\')',\n",
    " '_i95': 'variables_dict = globals()',\n",
    " 'variables_dict': {...},\n",
    " '_i96': 'variables_dict',\n",
    " '_96': {...},\n",
    " '_i97': \"variables_dict['ar_coefficients]\",\n",
    " '_i98': \"variables_dict['ar_coefficients']\",\n",
    " '_98': array([-0.57073806, -0.25504165, -0.43684139, -0.39442566, -0.3266803 ,\n",
    "        -0.09596204, -0.1837547 , -0.01177321, -0.12021627, -0.1537689 ,\n",
    "         0.06362805, -0.3066356 , -0.18471353, -0.14508358, -0.45184114,\n",
    "        -0.12185355,  0.1268503 , -0.33401473, -0.45442659,  0.04557276]),\n",
    " '_i99': '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    " 'pickle_filename': 'all_variables.pickle',\n",
    " 'f': <_io.BufferedWriter name='all_variables.pickle'>,\n",
    " '_i100': '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    " '_i101': '# Specify the filename for the pickle file\\nimport pickle\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    " '_i102': 'import pickle\\n\\n# Assuming you have your variables already defined in memory in Jupyter Notebook\\n\\n# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Get all global variables\\nvariables_dict = globals()\\n\\n# Filter out objects that cannot be pickled (e.g., modules, functions)\\nfiltered_variables_dict = {key: value for key, value in variables_dict.items() if not callable(value)}\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the filtered variables dictionary into the pickle file\\n    pickle.dump(filtered_variables_dict, f)\\n\\nprint(\"Filtered variables stored in pickle file:\", pickle_filename)',\n",
    " 'filtered_variables_dict': {'__name__': '__main__',\n",
    "  '__doc__': 'Automatically created module for IPython interactive environment',\n",
    "  '__package__': None,\n",
    "  '__loader__': None,\n",
    "  '__spec__': None,\n",
    "  '__builtin__': <module 'builtins' (built-in)>,\n",
    "  '__builtins__': <module 'builtins' (built-in)>,\n",
    "  '_ih': ['',\n",
    "   'import os\\nos.environ[\\'OMP_NUM_THREADS\\'] = \\'4\\'\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\nimport openai\\n#openai.api_key = os.environ[\\'OPENAI_API_KEY\\']\\nopenai.api_key  = \\'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\\' #chandra2\\nopenai.api_base = os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\\nfrom data.serialize import SerializerSettings\\nfrom models.utils import grid_iter\\nfrom models.promptcast import get_promptcast_predictions_data\\nfrom models.darts import get_arima_predictions_data\\nfrom models.llmtime import get_llmtime_predictions_data\\nfrom data.small_context import get_datasets\\nfrom models.validation_likelihood_tuning import get_autotuned_predictions_data\\nimport logging\\nimport pickle',\n",
    "   \"def plot_preds(train, test, pred_dict, model_name, show_samples=False):\\n    pred = pred_dict['median']\\n    pred = pd.Series(pred, index=test.index)\\n    plt.figure(figsize=(8, 6), dpi=100)\\n    plt.plot(train)\\n    plt.plot(test, label='Truth', color='black')\\n    plt.plot(pred, label=model_name, color='purple')\\n    # shade 90% confidence interval\\n    samples = pred_dict['samples']\\n    lower = np.quantile(samples, 0.05, axis=0)\\n    upper = np.quantile(samples, 0.95, axis=0)\\n    plt.fill_between(pred.index, lower, upper, alpha=0.3, color='purple')\\n    if show_samples:\\n        samples = pred_dict['samples']\\n        # convert df to numpy array\\n        samples = samples.values if isinstance(samples, pd.DataFrame) else samples\\n        for i in range(min(10, samples.shape[0])):\\n            plt.plot(pred.index, samples[i], color='purple', alpha=0.3, linewidth=1)\\n    plt.legend(loc='upper left')\\n    if 'NLL/D' in pred_dict:\\n        nll = pred_dict['NLL/D']\\n        if nll is not None:\\n            plt.text(0.03, 0.85, f'NLL/D: {nll:.2f}', transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.5))\\n    plt.show()\\n\\n\\n\\ngpt4_hypers = dict(\\n    alpha=0.3,\\n    basic=True,\\n    temp=1.0,\\n    top_p=0.8,\\n    settings=SerializerSettings(base=10, prec=3, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\\n)\\n\\ngpt3_hypers = dict(\\n    temp=0.7,\\n    alpha=0.95,\\n    beta=0.3,\\n    basic=False,\\n    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True)\\n)\\n\\n\\npromptcast_hypers = dict(\\n    temp=0.7,\\n    settings=SerializerSettings(base=10, prec=0, signed=True, \\n                                time_sep=', ',\\n                                bit_sep='',\\n                                plus_sign='',\\n                                minus_sign='-',\\n                                half_bin_correction=False,\\n                                decimal_point='')\\n)\\n\\narima_hypers = dict(p=[12,30], d=[1,2], q=[0])\\n\\nmodel_hypers = {\\n    #'LLMTime GPT-3.5': {'model': 'gpt-3.5-turbo-instruct', **gpt3_hypers},\\n    'LLMTime GPT-4': {'model': 'gpt-4', **gpt4_hypers},\\n    #'LLMTime GPT-3': {'model': 'text-davinci-003', **gpt3_hypers},\\n    #'PromptCast GPT-3': {'model': 'text-davinci-003', **promptcast_hypers},\\n    'ARIMA': arima_hypers,\\n    \\n}\\n\\nmodel_predict_fns = {\\n\\n    #'LLMTime GPT-3': get_llmtime_predictions_data,\\n    #'LLMTime GPT-3.5': get_llmtime_predictions_data,\\n    'LLMTime GPT-4': get_llmtime_predictions_data,\\n    #'PromptCast GPT-3': get_promptcast_predictions_data,\\n    'ARIMA': get_arima_predictions_data,\\n}\\n\\nmodel_names = list(model_predict_fns.keys())\",\n",
    "   \"def print_full(x):\\n    pd.set_option('display.max_rows', len(x))\\n    print(x)\\n    pd.reset_option('display.max_rows')\",\n",
    "   'x = np.linspace(0,10,100)\\ntrain = np.sin(x[0:50])\\ntest = np.sin(x[50:100])',\n",
    "   \"for model in model_names: # GPT-4 takes a about a minute to run\\n    model_hypers[model].update({'dataset_name': ds_name}) # for promptcast\\n    hypers = list(grid_iter(model_hypers[model]))\\n    num_samples = 10\\n    pred_dict = get_autotuned_predictions_data(train, test, hypers, num_samples, model_predict_fns[model], verbose=False, parallel=False)\\n    out[model] = pred_dict\\n    plot_preds(train, test, pred_dict, model, show_samples=True)\",\n",
    "   \"model_hypers['LLMTime GPT-4']\",\n",
    "   \"hypers = list(grid_iter(model_hypers['LLMTime GPT-4']))\\nhypers\",\n",
    "   \"import matplotlib.pyplot as plt\\nplt.plot(train,'o')\\nplt.show()\",\n",
    "   \"pred_dict = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "   'pred_dict',\n",
    "   \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\",\n",
    "   \"pred_dict = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "   'pred_dict',\n",
    "   \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\",\n",
    "   \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "   \"pred_dict_arima = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['ARIMA'], verbose=False, parallel=False)\",\n",
    "   \"plt.plot(pred_dict['median'])\\nplt.plot(pred_dict_arima['median'],'b')\\nplt.plot(np.linspace(50,100,50),test,'r')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "   \"plt.plot(pred_dict['median'],'r')\\nplt.plot(pred_dict_arima['median'],'b')\\nplt.plot(np.linspace(50,100,50),test,'ko')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "   'plt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")',\n",
    "   'plt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "   'x2 = np.linspace(0,10,100)\\ntrain = np.sin(x2[0:50]) + 2*np.sin(x2[0:50]/2) + 3*np.sin(x2[0:50]/3)\\ntest = np.sin(x2[50:100]) + 2*np.sin(x2[50:100]/2) + 3*np.sin(x2[50:100]/3)',\n",
    "   \"plt.plot(np.linspace(50,100,50),test,'k')\",\n",
    "   'x2 = np.linspace(0,10,100)\\ntrain = np.sin(x2[0:50]) + 0.2*np.sin(x2[0:50]*10) + 0.03*np.sin(x2[0:50]*20)\\ntest = np.sin(x2[50:100]) + 0.2*np.sin(x2[50:100]*10) + 0.03*np.sin(x2[50:100]*20)',\n",
    "   \"plt.plot(np.linspace(50,100,50),test,'k')\",\n",
    "   'x2 = np.linspace(0,10,100)\\ntrain2 = np.sin(x2[0:50]) + 0.2*np.sin(x2[0:50]*10) + 0.03*np.sin(x2[0:50]*20)\\ntest2 = np.sin(x2[50:100]) + 0.2*np.sin(x2[50:100]*10) + 0.03*np.sin(x2[50:100]*20)',\n",
    "   \"plt.plot(np.linspace(50,100,50),test2,'k')\",\n",
    "   \"pred_dict_gpt_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "   'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "   'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "   'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'oscillator2.png\\')',\n",
    "   \"x3 = np.linspace(0,10,100)\\ntrain3 = np.sin(x3[0:50]) + 0.2*np.sin(x3[0:50]*10) + 0.1*np.sin(x3[0:50]*20)\\ntest3 = np.sin(x3[50:100]) + 0.2*np.sin(x3[50:100]*10) + 0.1*np.sin(x3[50:100]*20)\\nplt.plot(np.linspace(50,100,50),test3,'k')\",\n",
    "   \"fft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"time = np.linspace(50,100,50)\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"time = np.linspace(50,100,50)\\n\\n\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\n\\n# Calculate the squared amplitude or power\\nfft_power = np.abs(fft_result) ** 2\\n\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"time = np.linspace(50,100,50)\\n\\n\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\n\\n# Calculate the squared amplitude or power\\nfft_power = np.abs(fft_result) ** 2\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask])\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask])\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\n#plt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\n#plt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.show()',\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.show()',\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n# Normalize the power spectrum\\nfft_power = fft_power / np.max(fft_power)\\nfft_power_arima = fft_power_arima / np.max(fft_power_arima)\\nfft_power_gpt = fft_power_gpt / np.max(fft_power_gpt)\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n# Normalize the power spectrum\\nfft_power = fft_power / np.max(fft_power)\\nfft_power_arima = fft_power_arima / np.max(fft_power_arima)\\nfft_power_gpt = fft_power_gpt / np.max(fft_power_gpt)\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq >= 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j] + time_series[i-1]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j] + time_series[i-j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.05\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA], verbose=False, parallel=False)\\n\\n                                                    plt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA], verbose=False, parallel=False)\\n\\n                                                \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   'time_series',\n",
    "   'time_series[0:50]',\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\n                                                \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(time_series[50:100],\\'k\\')                                         \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   \"pred_dict_gpt_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_gpt_ar[\\'median\\'],\\'r\\')\\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\n\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   'import statsmodels.api as sm',\n",
    "   'import statsmodels.api as sm\\nar_model = sm.tsa.AR(time_series[50:100])\\nar_results = ar_model.fit(maxlag=150)  # You can adjust the maximum number of lags as needed\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg((time_series[50:100], lags=150)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg((time_series[50:100], lags=50)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg(time_series[50:100], lags=50)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels.api as sm\\n\\nres = sm.tsa.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels.api as sm\\n\\nres = sm.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=49).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients',\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'ko')\\nplt.plot(ar_coefficients_gpt,'ro')\\nplt.plot(ar_coefficients_arima,'ro')\",\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'ko')\\nplt.plot(ar_coefficients_gpt,'ro')\\nplt.plot(ar_coefficients_arima,'bo')\",\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=10).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=30).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=30).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=30).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\\nplt.savefig('ar-coeff.png')\",\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_gpt_ar[\\'median\\'],\\'r\\')\\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\n\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\n\\nplt.savefig(\\'autoregressive.png\\')',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,\\'k-\\')\\nplt.plot(ar_coefficients_gpt,\\'r-\\')\\nplt.plot(ar_coefficients_arima,\\'b-\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\n\\nplt.savefig(\\'ar-coeff.png\\')',\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\n\\nplt.savefig('autoregressive.png')\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\n\\nplt.savefig('autoregressive.png')\",\n",
    "   'def compute_rmse(actual_values, predicted_values):\\n    \"\"\"\\n    Compute Root Mean Square Error (RMSE) between two time series.\\n\\n    Args:\\n        actual_values (array-like): Actual values of the time series.\\n        predicted_values (array-like): Predicted values of the time series.\\n\\n    Returns:\\n        float: RMSE value.\\n    \"\"\"\\n    # Ensure both arrays have the same length\\n    if len(actual_values) != len(predicted_values):\\n        raise ValueError(\"Lengths of actual_values and predicted_values must be the same.\")\\n\\n    # Convert input arrays to numpy arrays\\n    actual_values = np.array(actual_values)\\n    predicted_values = np.array(predicted_values)\\n\\n    # Compute the squared error between actual and predicted values\\n    squared_error = (actual_values - predicted_values) ** 2\\n\\n    # Compute the mean of squared errors\\n    mean_squared_error = np.mean(squared_error)\\n\\n    # Compute the square root of mean squared error (RMSE)\\n    rmse = np.sqrt(mean_squared_error)\\n\\n    return rmse',\n",
    "   \"rmse_gpt = compute_rmse(time_series[50:100],pred_dict_gpt_ar['median'])\",\n",
    "   \"rmse_gpt = compute_rmse(time_series[50:100],pred_dict_gpt_ar['median'])\\nrmse_arima = compute_rmse(time_series[50:100],pred_dict_arima_ar['median'])\\nprint(rmse_gpt,rmse_arima)\",\n",
    "   \"rmse_gpt_sin = compute_rmse(test2,pred_dict_gpt_sum['median'])\\nrmse_arima_sin = compute_rmse(test2],pred_dict_arima_sum['median'])\\nprint(rmse_gpt_sin,rmse_arima_sin)\",\n",
    "   \"rmse_gpt_sin = compute_rmse(test2,pred_dict_gpt_sum['median'])\\nrmse_arima_sin = compute_rmse(test2,pred_dict_arima_sum['median'])\\nprint(rmse_gpt_sin,rmse_arima_sin)\",\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,\\'k-\\')\\nplt.plot(ar_coefficients_gpt,\\'r-\\')\\nplt.plot(ar_coefficients_arima,\\'b-\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\n\\nplt.savefig(\\'ar-coeff.png\\')',\n",
    "   'variables_dict = globals()',\n",
    "   'variables_dict',\n",
    "   \"variables_dict['ar_coefficients]\",\n",
    "   \"variables_dict['ar_coefficients']\",\n",
    "   '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "   '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "   '# Specify the filename for the pickle file\\nimport pickle\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "   'import pickle\\n\\n# Assuming you have your variables already defined in memory in Jupyter Notebook\\n\\n# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Get all global variables\\nvariables_dict = globals()\\n\\n# Filter out objects that cannot be pickled (e.g., modules, functions)\\nfiltered_variables_dict = {key: value for key, value in variables_dict.items() if not callable(value)}\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the filtered variables dictionary into the pickle file\\n    pickle.dump(filtered_variables_dict, f)\\n\\nprint(\"Filtered variables stored in pickle file:\", pickle_filename)',\n",
    "   'variables_dict'],\n",
    "  '_oh': {6: {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    "   7: [defaultdict(dict,\n",
    "                {'model': 'gpt-4',\n",
    "                 'alpha': 0.3,\n",
    "                 'basic': True,\n",
    "                 'temp': 1.0,\n",
    "                 'top_p': 0.8,\n",
    "                 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')})],\n",
    "   10: {'samples':          50        51        52        53        54        55        56  \\\n",
    "    0  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "    1  0.942804  0.904312  0.856679  0.799904  0.736393  0.664221  0.585794   \n",
    "    2 -0.941842 -0.902388 -0.853792 -0.796055 -0.730619 -0.657966 -0.578096   \n",
    "    3  0.942804  0.904312  0.856679  0.799904  0.735430  0.663259  0.584351   \n",
    "    4 -0.943285 -0.905275 -0.857641 -0.801347 -0.737836 -0.666146 -0.587719   \n",
    "    5 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "    6 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "    7  0.942323  0.903350  0.855236  0.797979  0.733025  0.660372  0.580983   \n",
    "    8 -0.942804 -0.904794 -0.857160 -0.800866 -0.735912 -0.663740 -0.585313   \n",
    "    9  0.943285  0.905275  0.857160  0.800866  0.736874  0.665183  0.586757   \n",
    "    \n",
    "             57        58        59  ...        90        91        92        93  \\\n",
    "    0  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "    1  0.501113  0.411620  0.318278  ... -0.321164 -0.224454 -0.126301 -0.027185   \n",
    "    2 -0.492452 -0.401516 -0.306730  ...  0.286041  0.188368  0.088771 -0.011788   \n",
    "    3  0.499669  0.409695  0.315872  ... -0.321164 -0.224454 -0.125338 -0.025260   \n",
    "    4 -0.503518 -0.414507 -0.320683  ...  0.362543  0.279305  0.194142  0.108017   \n",
    "    5 -0.503037 -0.413544 -0.320202  ...  0.303843  0.207133  0.108498  0.008901   \n",
    "    6 -0.502556 -0.413063 -0.320202  ...  0.213388  0.113310  0.012750 -0.087809   \n",
    "    7  0.495820  0.405365  0.311060  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "    8 -0.500632 -0.410657 -0.316834  ...  0.310098  0.212426  0.112347  0.011788   \n",
    "    9  0.502556  0.413063  0.319721  ... -0.310579 -0.213869 -0.114272 -0.013713   \n",
    "    \n",
    "             94        95        96        97        98        99  \n",
    "    0  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "    1  0.084441  0.185481  0.284116  0.284116  0.284116  0.284116  \n",
    "    2 -0.111866 -0.211463 -0.308655 -0.403921 -0.494858 -0.580502  \n",
    "    3  0.075780  0.175859  0.274012  0.369760  0.461659  0.549227  \n",
    "    4  0.021411 -0.065676 -0.151801 -0.236483 -0.319721 -0.401035  \n",
    "    5 -0.092139 -0.192218 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "    6 -0.187887 -0.285079 -0.379864 -0.470319 -0.556444 -0.636315  \n",
    "    7  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "    8 -0.088771 -0.188849 -0.286522 -0.382270 -0.472725 -0.559331  \n",
    "    9  0.087328  0.187406  0.187406  0.187406  0.187406  0.187406  \n",
    "    \n",
    "    [10 rows x 50 columns],\n",
    "    'median': 50    0.000241\n",
    "    51    0.000481\n",
    "    52    0.000481\n",
    "    53    0.000722\n",
    "    54    0.000962\n",
    "    55    0.000962\n",
    "    56    0.001203\n",
    "    57    0.001443\n",
    "    58    0.001684\n",
    "    59    0.001925\n",
    "    60    0.003368\n",
    "    61    0.003849\n",
    "    62    0.004571\n",
    "    63   -0.001925\n",
    "    64   -0.002406\n",
    "    65   -0.002887\n",
    "    66   -0.003368\n",
    "    67   -0.004090\n",
    "    68   -0.004571\n",
    "    69   -0.005052\n",
    "    70   -0.005533\n",
    "    71   -0.006014\n",
    "    72   -0.006255\n",
    "    73   -0.006977\n",
    "    74   -0.007217\n",
    "    75   -0.008661\n",
    "    76   -0.009382\n",
    "    77   -0.010104\n",
    "    78   -0.011066\n",
    "    79   -0.011547\n",
    "    80   -0.012269\n",
    "    81   -0.013231\n",
    "    82   -0.018524\n",
    "    83   -0.023336\n",
    "    84   -0.027906\n",
    "    85   -0.032477\n",
    "    86   -0.036567\n",
    "    87   -0.040176\n",
    "    88   -0.043303\n",
    "    89   -0.045468\n",
    "    90   -0.047393\n",
    "    91   -0.048596\n",
    "    92   -0.049077\n",
    "    93   -0.011066\n",
    "    94    0.048596\n",
    "    95    0.055091\n",
    "    96    0.017802\n",
    "    97   -0.024538\n",
    "    98   -0.066157\n",
    "    99   -0.106814\n",
    "    dtype: float64,\n",
    "    'info': {'Method': 'gpt-4'},\n",
    "    'completions_list': [['1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "      '1959, 1879, 1780, 1662, 1530, 1380, 1217, 1041, 855, 661, 459, 254, 47, -166, -376, -580, -780, -970, -1151, -1319, -1474, -1614, -1737, -1843, -1929, -1996, -2042, -2067, -2072, -2055, -2017, -1957, -1878, -1780, -1663, -1532, -1383, -1221, -1046, -860, -667, -466, -262, -56, 175, 385, 590',\n",
    "      '-1957, -1875, -1774, -1654, -1518, -1367, -1201, -1023, -834, -637, -428, -219, -7, 201, 409, 612, 809, 997, 1175, 1342, 1493, 1629, 1749, 1851, 1935, 1998, 2040, 2062, 2062, 2041, 1999, 1925, 1835, 1728, 1607, 1471, 1320, 1155, 977, 790, 594, 391, 184, -24, -232, -439, -641, -839, -1028, -1206, -1372, -1524, -1661, -1781, -1884, -1967, -2030, -2071, -2093, -',\n",
    "      '1959, 1879, 1780, 1662, 1528, 1378, 1214, 1038, 851, 656, 454, 247, 38, -172, -381, -585, -784, -974, -1155, -1323, -1478, -1618, -1741, -1847, -1933, -2000, -2046, -2071, -2076, -2059, -2021, -1961, -1882, -1784, -1667, -1534, -1385, -1222, -1047, -861, -667, -466, -260, -52, 157, 365, 569, 768, 959, 1141, 1310, 1466, 1607, 1731, 1838, 1925, 1993, 2040, 2066, 207',\n",
    "      '-1960, -1881, -1782, -1665, -1533, -1384, -1221, -1046, -861, -666, -465, -260, -53, 154, 360, 561, 757, 944, 1122, 1287, 1439, 1576, 1697, 1799, 1883, 1944, 1986, 2007, 2007, 1987, 1946, 1892, 1820, 1733, 1630, 1514, 1384, 1240, 1086, 923, 753, 580, 403, 224, 44, -136, -315, -491, -664, -833, -998, -1157, -1309, -1446, -1571, -1681, -1775, -1853, -1915, -1960',\n",
    "      '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -52, 157, 365, 567, 765, 954, 1134, 1301, 1455, 1594, 1716, 1820, 1904, 1970, 2015, 2039, 2043, 2025, 1986, 1926, 1847, 1748, 1631, 1498, 1349, 1186, 1011, 825, 631, 430, 225, 18, -191, -399, -601, -799, -988, -1168',\n",
    "      '-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -665, -464, -259, -51, 156, 363, 565, 762, 950, 1130, 1296, 1449, 1587, 1708, 1812, 1896, 1961, 2005, 2028, 2029, 2008, 1966, 1885, 1784, 1665, 1529, 1377, 1211, 1033, 844, 647, 443, 235, 26, -182, -390, -592, -789, -977, -1156, -1322, -1475, -1613, -1734, -1838, -1921, -1986, -2030, -2053, -2054, -',\n",
    "      '1958, 1877, 1777, 1658, 1523, 1372, 1207, 1030, 842, 646, 443, 236, 27, -182, -390, -593, -791, -980, -1160, -1327, -1481, -1620, -1742, -1847, -1932, -1998, -2043, -2067, -2071, -2053, -2014, -1952, -1871, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "      '-1959, -1880, -1781, -1664, -1529, -1379, -1216, -1040, -853, -658, -456, -248, -38, 170, 378, 581, 779, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2059, 2042, 2003, 1943, 1864, 1765, 1648, 1513, 1363, 1200, 1025, 839, 644, 441, 233, 24, -184, -392, -595, -794, -982, -1162, -1329, -1483, -1622, -1744, -1850, -1936, -2002, -2047, -2071, -',\n",
    "      '1960, 1881, 1781, 1664, 1531, 1382, 1219, 1044, 858, 664, 463, 256, 47, -162, -370, -573, -771, -961, -1141, -1308, -1462, -1601, -1723, -1828, -1913, -1980, -2025, -2049, -2053, -2035, -1997, -1940, -1861, -1762, -1645, -1512, -1363, -1200, -1025, -839, -645, -444, -237, -28, 181, 389']],\n",
    "    'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "    'best_hyper': {'model': 'gpt-4',\n",
    "     'alpha': 0.3,\n",
    "     'basic': True,\n",
    "     'temp': 1.0,\n",
    "     'top_p': 0.8,\n",
    "     'settings': {'base': 10,\n",
    "      'prec': 3,\n",
    "      'signed': True,\n",
    "      'fixed_length': False,\n",
    "      'max_val': 10000000.0,\n",
    "      'time_sep': ', ',\n",
    "      'bit_sep': '',\n",
    "      'plus_sign': '',\n",
    "      'minus_sign': '-',\n",
    "      'half_bin_correction': True,\n",
    "      'decimal_point': '',\n",
    "      'missing_str': ' Nan'}}},\n",
    "   11: [<matplotlib.lines.Line2D at 0x28ce64520>],\n",
    "   13: {'samples':          50        51        52        53        54        55        56  \\\n",
    "    0 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "    1  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "    2  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "    3  0.942804  0.904312  0.856198  0.799423  0.735430  0.663259  0.583870   \n",
    "    4  0.943285  0.905275  0.857641  0.801347  0.737355  0.665664  0.587238   \n",
    "    5 -0.943285 -0.905275 -0.857160 -0.800385 -0.736393 -0.664221 -0.585313   \n",
    "    6 -0.942804 -0.904312 -0.856679 -0.799904 -0.735912 -0.664221 -0.585794   \n",
    "    7 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "    8 -0.943285 -0.904794 -0.856679 -0.800385 -0.735912 -0.664221 -0.585313   \n",
    "    9 -0.943285 -0.904794 -0.857160 -0.800866 -0.735912 -0.664221 -0.584832   \n",
    "    \n",
    "             57        58        59  ...        90        91        92        93  \\\n",
    "    0 -0.502556 -0.413063 -0.319721  ...  0.305768  0.209058  0.109461  0.009382   \n",
    "    1  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "    2  0.495339  0.404884  0.310579  ... -0.309136 -0.211463 -0.111866 -0.011307   \n",
    "    3  0.499188  0.408733  0.314910  ... -0.321164 -0.223492 -0.123895 -0.023336   \n",
    "    4  0.503037  0.413544  0.320202  ... -0.307211 -0.210501 -0.111866 -0.012269   \n",
    "    5 -0.500632 -0.410657 -0.316834  ...  0.286041  0.187887  0.087809 -0.012750   \n",
    "    6 -0.501113 -0.411139 -0.317796  ...  0.307692  0.210020  0.110423  0.009863   \n",
    "    7 -0.503037 -0.413544 -0.320202  ...  0.271125  0.174415  0.075299 -0.024779   \n",
    "    8 -0.501113 -0.411139 -0.317796  ...  0.301437  0.203765  0.104168  0.003609   \n",
    "    9 -0.500632 -0.410176 -0.316353  ...  0.307211  0.209539  0.109942  0.009382   \n",
    "    \n",
    "             94        95        96        97        98        99  \n",
    "    0 -0.091658 -0.191736 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "    1  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "    2  0.089734  0.189812  0.287484  0.382751  0.473687  0.560294  \n",
    "    3  0.077705  0.178264  0.276899  0.373128  0.465027  0.552595  \n",
    "    4  0.088771  0.188849  0.286522  0.381789  0.473206  0.560294  \n",
    "    5 -0.112829 -0.211944 -0.309136 -0.403921 -0.494377 -0.580502  \n",
    "    6 -0.091177 -0.191255 -0.288928 -0.384194 -0.475131 -0.561737  \n",
    "    7 -0.124857 -0.223492 -0.320202 -0.413544 -0.503037 -0.587238  \n",
    "    8 -0.098394 -0.198472 -0.296145 -0.391412 -0.482348 -0.568954  \n",
    "    9 -0.092139 -0.192218 -0.289890 -0.385157 -0.476093 -0.562699  \n",
    "    \n",
    "    [10 rows x 50 columns],\n",
    "    'median': 50   -0.943045\n",
    "    51   -0.904553\n",
    "    52   -0.856679\n",
    "    53   -0.800144\n",
    "    54   -0.735912\n",
    "    55   -0.664221\n",
    "    56   -0.585073\n",
    "    57   -0.500632\n",
    "    58   -0.410417\n",
    "    59   -0.316594\n",
    "    60   -0.219162\n",
    "    61   -0.119565\n",
    "    62   -0.019246\n",
    "    63    0.076502\n",
    "    64    0.176099\n",
    "    65    0.273290\n",
    "    66    0.368076\n",
    "    67    0.458531\n",
    "    68    0.544656\n",
    "    69    0.624526\n",
    "    70    0.698142\n",
    "    71    0.764540\n",
    "    72    0.822999\n",
    "    73    0.872557\n",
    "    74    0.912973\n",
    "    75    0.943526\n",
    "    76    0.964215\n",
    "    77    0.975041\n",
    "    78    0.975041\n",
    "    79    0.965418\n",
    "    80    0.945450\n",
    "    81    0.915379\n",
    "    82    0.875684\n",
    "    83    0.826607\n",
    "    84    0.768389\n",
    "    85    0.702713\n",
    "    86    0.629578\n",
    "    87    0.549949\n",
    "    88    0.464305\n",
    "    89    0.373369\n",
    "    90    0.278583\n",
    "    91    0.181151\n",
    "    92    0.081554\n",
    "    93   -0.010826\n",
    "    94   -0.091418\n",
    "    95   -0.191496\n",
    "    96   -0.289168\n",
    "    97   -0.384435\n",
    "    98   -0.475371\n",
    "    99   -0.561978\n",
    "    dtype: float64,\n",
    "    'info': {'Method': 'gpt-4'},\n",
    "    'completions_list': [['-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -664, -463, -256, -48, 161, 369, 572, 770, 959, 1139, 1306, 1460, 1599, 1721, 1826, 1911, 1977, 2022, 2046, 2050, 2032, 1993, 1933, 1852, 1752, 1635, 1502, 1353, 1190, 1015, 829, 635, 434, 227, 19, -190, -398, -601, -799, -988, -1168, -1335, -1489, -1628, -1750, -1855, -1940, -2006, -2051, -2075, -',\n",
    "      '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853',\n",
    "      '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 233, 24, -185, -393, -596, -794, -983, -1163, -1330, -1484, -1623, -1745, -1850, -1935, -2001, -2046, -2070, -2074, -2056, -2017, -1955, -1874, -1773, -1654, -1519, -1368, -1203, -1026, -838, -642, -439, -232, -23, 186, 394, 597, 795, 984, 1164, 1331, 1485, 1624, 1746, 1851, 1936, 2002, 2047, 2071, 207',\n",
    "      '1959, 1879, 1779, 1661, 1528, 1378, 1213, 1037, 849, 654, 451, 244, 35, -174, -383, -587, -786, -976, -1157, -1325, -1480, -1620, -1743, -1849, -1935, -2002, -2048, -2073, -2078, -2061, -2023, -1963, -1884, -1785, -1668, -1536, -1387, -1223, -1048, -861, -667, -464, -257, -48, 161, 370, 575, 775, 966, 1148, 1317, 1473, 1614, 1738, 1845, 1932, 2000, 2047, 2072, 207',\n",
    "      '1960, 1881, 1782, 1665, 1532, 1383, 1220, 1045, 859, 665, 464, 259, 52, -157, -365, -568, -766, -956, -1137, -1304, -1458, -1597, -1719, -1824, -1910, -1976, -2021, -2045, -2049, -2031, -1992, -1933, -1854, -1755, -1638, -1505, -1356, -1193, -1018, -832, -638, -437, -232, -25, 184, 392, 595, 793, 983, 1164, 1331, 1485, 1624, 1746, 1851, 1937, 2003, 2048, 2072, 207',\n",
    "      '-1960, -1881, -1781, -1663, -1530, -1380, -1216, -1040, -853, -658, -456, -249, -40, 168, 375, 577, 775, 963, 1142, 1308, 1461, 1599, 1720, 1824, 1909, 1974, 2018, 2041, 2043, 2023, 1982, 1919, 1837, 1735, 1615, 1479, 1327, 1161, 983, 792, 594, 390, 182, -26, -234, -440, -642, -839, -1027, -1206, -1371, -1523, -1661',\n",
    "      '-1959, -1879, -1780, -1662, -1529, -1380, -1217, -1041, -854, -660, -457, -250, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1938, 1858, 1759, 1641, 1508, 1359, 1196, 1020, 833, 639, 436, 229, 20, -189, -397, -600, -798, -987, -1167, -1334, -1488, -1627, -1749, -1854, -1939, -2005, -2050, -2074, -',\n",
    "      '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -51, 156, 362, 563, 759, 946, 1124, 1289, 1441, 1578, 1700, 1802, 1885, 1947, 1989, 2011, 2009, 1989, 1947, 1885, 1802, 1700, 1578, 1441, 1289, 1124, 946, 759, 563, 362, 156, -51, -259, -464, -665, -859, -1045, -1220, -1383, -1532, -1665, -1782, -1881, -1960, -2020, -2059, -2077, -',\n",
    "      '-1960, -1880, -1780, -1663, -1529, -1380, -1216, -1041, -854, -660, -458, -252, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1939, 1858, 1757, 1638, 1503, 1352, 1187, 1010, 822, 626, 423, 216, 7, -204, -412, -615, -813, -1002, -1182, -1349, -1503, -1642, -1764, -1869, -1954, -2020, -2065, -2089,',\n",
    "      '-1960, -1880, -1781, -1664, -1529, -1380, -1215, -1040, -852, -657, -454, -247, -39, 169, 377, 580, 778, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2058, 2040, 2001, 1941, 1861, 1762, 1645, 1510, 1361, 1196, 1021, 833, 638, 435, 228, 19, -191, -399, -602, -800, -989, -1169, -1336, -1490, -1629, -1751, -1856, -1941, -2007, -2052, -2076, -']],\n",
    "    'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "    'best_hyper': {'model': 'gpt-4',\n",
    "     'alpha': 0.3,\n",
    "     'basic': True,\n",
    "     'temp': 1.0,\n",
    "     'top_p': 0.8,\n",
    "     'settings': {'base': 10,\n",
    "      'prec': 3,\n",
    "      'signed': True,\n",
    "      'fixed_length': False,\n",
    "      'max_val': 10000000.0,\n",
    "      'time_sep': ', ',\n",
    "      'bit_sep': '',\n",
    "      'plus_sign': '',\n",
    "      'minus_sign': '-',\n",
    "      'half_bin_correction': True,\n",
    "      'decimal_point': '',\n",
    "      'missing_str': ' Nan'}}},\n",
    "   14: [<matplotlib.lines.Line2D at 0x28e598ac0>],\n",
    "   15: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   17: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   18: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   19: <matplotlib.legend.Legend at 0x28f18c790>,\n",
    "   22: [<matplotlib.lines.Line2D at 0x28f3fb1c0>],\n",
    "   24: [<matplotlib.lines.Line2D at 0x28f3bdf70>],\n",
    "   26: [<matplotlib.lines.Line2D at 0x28f4aaa30>],\n",
    "   31: [<matplotlib.lines.Line2D at 0x28f65f130>],\n",
    "   60: array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "           1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "          -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "           0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "          -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "           0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "           0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "           1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "          -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "           0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149,\n",
    "           0.18718621, -0.4757239 , -1.64344264, -0.09358268,  0.10309571,\n",
    "           0.095137  ,  1.06676763, -1.8428797 , -1.04016223, -0.1471965 ,\n",
    "           1.1094952 , -1.38843155, -1.34927948,  2.2983403 , -0.5684549 ,\n",
    "           0.74208654,  0.46162906,  1.62492308, -0.75288572, -0.6291802 ,\n",
    "           0.46314307,  0.64471457,  0.19379909, -1.41415266, -1.23427455,\n",
    "          -0.40777303,  0.81886616,  0.40483561, -0.5155421 , -0.566217  ,\n",
    "          -0.29358193,  0.88388512, -1.1597346 , -0.41722568,  0.55364882,\n",
    "           0.32269808, -1.18005105, -0.63975452,  1.24861017,  1.32987551,\n",
    "           0.75395216,  0.47690589,  0.29144071,  0.84784154,  0.82063337,\n",
    "           0.44373127, -1.11129098,  0.71013579,  0.89859217, -1.24352553]),\n",
    "   61: array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "           1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "          -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "           0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "          -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "           0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "           0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "           1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "          -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "           0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149]),\n",
    "   62: Text(24.00000000000002, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   63: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   64: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   66: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   78: array([ 0.42459049, -0.71090158,  0.28381361,  0.19212327, -0.10471756,\n",
    "           0.23711138, -0.25102066, -0.39702093, -0.19640616, -0.40924017,\n",
    "          -0.35815403,  0.14991523, -0.01944757,  0.11782569, -0.29788144,\n",
    "          -0.19526565, -0.48413894, -0.03631446, -0.47901333,  0.0322904 ]),\n",
    "   79: [<matplotlib.lines.Line2D at 0x29fe344c0>],\n",
    "   80: [<matplotlib.lines.Line2D at 0x2adb847c0>],\n",
    "   81: [<matplotlib.lines.Line2D at 0x2adc2b3d0>],\n",
    "   82: [<matplotlib.lines.Line2D at 0x29fe41e80>],\n",
    "   96: {...},\n",
    "   98: array([-0.57073806, -0.25504165, -0.43684139, -0.39442566, -0.3266803 ,\n",
    "          -0.09596204, -0.1837547 , -0.01177321, -0.12021627, -0.1537689 ,\n",
    "           0.06362805, -0.3066356 , -0.18471353, -0.14508358, -0.45184114,\n",
    "          -0.12185355,  0.1268503 , -0.33401473, -0.45442659,  0.04557276])},\n",
    "  '_dh': [PosixPath('/Users/rdey33/Downloads/llmtime/llmtime-dynamics')],\n",
    "  'In': ['',\n",
    "   'import os\\nos.environ[\\'OMP_NUM_THREADS\\'] = \\'4\\'\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\nimport openai\\n#openai.api_key = os.environ[\\'OPENAI_API_KEY\\']\\nopenai.api_key  = \\'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\\' #chandra2\\nopenai.api_base = os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\\nfrom data.serialize import SerializerSettings\\nfrom models.utils import grid_iter\\nfrom models.promptcast import get_promptcast_predictions_data\\nfrom models.darts import get_arima_predictions_data\\nfrom models.llmtime import get_llmtime_predictions_data\\nfrom data.small_context import get_datasets\\nfrom models.validation_likelihood_tuning import get_autotuned_predictions_data\\nimport logging\\nimport pickle',\n",
    "   \"def plot_preds(train, test, pred_dict, model_name, show_samples=False):\\n    pred = pred_dict['median']\\n    pred = pd.Series(pred, index=test.index)\\n    plt.figure(figsize=(8, 6), dpi=100)\\n    plt.plot(train)\\n    plt.plot(test, label='Truth', color='black')\\n    plt.plot(pred, label=model_name, color='purple')\\n    # shade 90% confidence interval\\n    samples = pred_dict['samples']\\n    lower = np.quantile(samples, 0.05, axis=0)\\n    upper = np.quantile(samples, 0.95, axis=0)\\n    plt.fill_between(pred.index, lower, upper, alpha=0.3, color='purple')\\n    if show_samples:\\n        samples = pred_dict['samples']\\n        # convert df to numpy array\\n        samples = samples.values if isinstance(samples, pd.DataFrame) else samples\\n        for i in range(min(10, samples.shape[0])):\\n            plt.plot(pred.index, samples[i], color='purple', alpha=0.3, linewidth=1)\\n    plt.legend(loc='upper left')\\n    if 'NLL/D' in pred_dict:\\n        nll = pred_dict['NLL/D']\\n        if nll is not None:\\n            plt.text(0.03, 0.85, f'NLL/D: {nll:.2f}', transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.5))\\n    plt.show()\\n\\n\\n\\ngpt4_hypers = dict(\\n    alpha=0.3,\\n    basic=True,\\n    temp=1.0,\\n    top_p=0.8,\\n    settings=SerializerSettings(base=10, prec=3, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\\n)\\n\\ngpt3_hypers = dict(\\n    temp=0.7,\\n    alpha=0.95,\\n    beta=0.3,\\n    basic=False,\\n    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True)\\n)\\n\\n\\npromptcast_hypers = dict(\\n    temp=0.7,\\n    settings=SerializerSettings(base=10, prec=0, signed=True, \\n                                time_sep=', ',\\n                                bit_sep='',\\n                                plus_sign='',\\n                                minus_sign='-',\\n                                half_bin_correction=False,\\n                                decimal_point='')\\n)\\n\\narima_hypers = dict(p=[12,30], d=[1,2], q=[0])\\n\\nmodel_hypers = {\\n    #'LLMTime GPT-3.5': {'model': 'gpt-3.5-turbo-instruct', **gpt3_hypers},\\n    'LLMTime GPT-4': {'model': 'gpt-4', **gpt4_hypers},\\n    #'LLMTime GPT-3': {'model': 'text-davinci-003', **gpt3_hypers},\\n    #'PromptCast GPT-3': {'model': 'text-davinci-003', **promptcast_hypers},\\n    'ARIMA': arima_hypers,\\n    \\n}\\n\\nmodel_predict_fns = {\\n\\n    #'LLMTime GPT-3': get_llmtime_predictions_data,\\n    #'LLMTime GPT-3.5': get_llmtime_predictions_data,\\n    'LLMTime GPT-4': get_llmtime_predictions_data,\\n    #'PromptCast GPT-3': get_promptcast_predictions_data,\\n    'ARIMA': get_arima_predictions_data,\\n}\\n\\nmodel_names = list(model_predict_fns.keys())\",\n",
    "   \"def print_full(x):\\n    pd.set_option('display.max_rows', len(x))\\n    print(x)\\n    pd.reset_option('display.max_rows')\",\n",
    "   'x = np.linspace(0,10,100)\\ntrain = np.sin(x[0:50])\\ntest = np.sin(x[50:100])',\n",
    "   \"for model in model_names: # GPT-4 takes a about a minute to run\\n    model_hypers[model].update({'dataset_name': ds_name}) # for promptcast\\n    hypers = list(grid_iter(model_hypers[model]))\\n    num_samples = 10\\n    pred_dict = get_autotuned_predictions_data(train, test, hypers, num_samples, model_predict_fns[model], verbose=False, parallel=False)\\n    out[model] = pred_dict\\n    plot_preds(train, test, pred_dict, model, show_samples=True)\",\n",
    "   \"model_hypers['LLMTime GPT-4']\",\n",
    "   \"hypers = list(grid_iter(model_hypers['LLMTime GPT-4']))\\nhypers\",\n",
    "   \"import matplotlib.pyplot as plt\\nplt.plot(train,'o')\\nplt.show()\",\n",
    "   \"pred_dict = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "   'pred_dict',\n",
    "   \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\",\n",
    "   \"pred_dict = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "   'pred_dict',\n",
    "   \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\",\n",
    "   \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "   \"pred_dict_arima = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['ARIMA'], verbose=False, parallel=False)\",\n",
    "   \"plt.plot(pred_dict['median'])\\nplt.plot(pred_dict_arima['median'],'b')\\nplt.plot(np.linspace(50,100,50),test,'r')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "   \"plt.plot(pred_dict['median'],'r')\\nplt.plot(pred_dict_arima['median'],'b')\\nplt.plot(np.linspace(50,100,50),test,'ko')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "   'plt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")',\n",
    "   'plt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "   'x2 = np.linspace(0,10,100)\\ntrain = np.sin(x2[0:50]) + 2*np.sin(x2[0:50]/2) + 3*np.sin(x2[0:50]/3)\\ntest = np.sin(x2[50:100]) + 2*np.sin(x2[50:100]/2) + 3*np.sin(x2[50:100]/3)',\n",
    "   \"plt.plot(np.linspace(50,100,50),test,'k')\",\n",
    "   'x2 = np.linspace(0,10,100)\\ntrain = np.sin(x2[0:50]) + 0.2*np.sin(x2[0:50]*10) + 0.03*np.sin(x2[0:50]*20)\\ntest = np.sin(x2[50:100]) + 0.2*np.sin(x2[50:100]*10) + 0.03*np.sin(x2[50:100]*20)',\n",
    "   \"plt.plot(np.linspace(50,100,50),test,'k')\",\n",
    "   'x2 = np.linspace(0,10,100)\\ntrain2 = np.sin(x2[0:50]) + 0.2*np.sin(x2[0:50]*10) + 0.03*np.sin(x2[0:50]*20)\\ntest2 = np.sin(x2[50:100]) + 0.2*np.sin(x2[50:100]*10) + 0.03*np.sin(x2[50:100]*20)',\n",
    "   \"plt.plot(np.linspace(50,100,50),test2,'k')\",\n",
    "   \"pred_dict_gpt_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "   'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "   'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "   'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'oscillator2.png\\')',\n",
    "   \"x3 = np.linspace(0,10,100)\\ntrain3 = np.sin(x3[0:50]) + 0.2*np.sin(x3[0:50]*10) + 0.1*np.sin(x3[0:50]*20)\\ntest3 = np.sin(x3[50:100]) + 0.2*np.sin(x3[50:100]*10) + 0.1*np.sin(x3[50:100]*20)\\nplt.plot(np.linspace(50,100,50),test3,'k')\",\n",
    "   \"fft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"time = np.linspace(50,100,50)\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"time = np.linspace(50,100,50)\\n\\n\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\n\\n# Calculate the squared amplitude or power\\nfft_power = np.abs(fft_result) ** 2\\n\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"time = np.linspace(50,100,50)\\n\\n\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\n\\n# Calculate the squared amplitude or power\\nfft_power = np.abs(fft_result) ** 2\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask])\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask])\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\n#plt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\n#plt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.show()',\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.show()',\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n# Normalize the power spectrum\\nfft_power = fft_power / np.max(fft_power)\\nfft_power_arima = fft_power_arima / np.max(fft_power_arima)\\nfft_power_gpt = fft_power_gpt / np.max(fft_power_gpt)\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "   'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n# Normalize the power spectrum\\nfft_power = fft_power / np.max(fft_power)\\nfft_power_arima = fft_power_arima / np.max(fft_power_arima)\\nfft_power_gpt = fft_power_gpt / np.max(fft_power_gpt)\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq >= 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j] + time_series[i-1]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j] + time_series[i-j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.05\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA], verbose=False, parallel=False)\\n\\n                                                    plt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA], verbose=False, parallel=False)\\n\\n                                                \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   'time_series',\n",
    "   'time_series[0:50]',\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\n                                                \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(time_series[50:100],\\'k\\')                                         \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   \"pred_dict_gpt_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_gpt_ar[\\'median\\'],\\'r\\')\\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\n\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "   'import statsmodels.api as sm',\n",
    "   'import statsmodels.api as sm\\nar_model = sm.tsa.AR(time_series[50:100])\\nar_results = ar_model.fit(maxlag=150)  # You can adjust the maximum number of lags as needed\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg((time_series[50:100], lags=150)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg((time_series[50:100], lags=50)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg(time_series[50:100], lags=50)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels.api as sm\\n\\nres = sm.tsa.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels.api as sm\\n\\nres = sm.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=49).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients',\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'ko')\\nplt.plot(ar_coefficients_gpt,'ro')\\nplt.plot(ar_coefficients_arima,'ro')\",\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'ko')\\nplt.plot(ar_coefficients_gpt,'ro')\\nplt.plot(ar_coefficients_arima,'bo')\",\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=10).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=30).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=30).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=30).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "   \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\\nplt.savefig('ar-coeff.png')\",\n",
    "   'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_gpt_ar[\\'median\\'],\\'r\\')\\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\n\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\n\\nplt.savefig(\\'autoregressive.png\\')',\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,\\'k-\\')\\nplt.plot(ar_coefficients_gpt,\\'r-\\')\\nplt.plot(ar_coefficients_arima,\\'b-\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\n\\nplt.savefig(\\'ar-coeff.png\\')',\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\n\\nplt.savefig('autoregressive.png')\",\n",
    "   \"def generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\n\\nplt.savefig('autoregressive.png')\",\n",
    "   'def compute_rmse(actual_values, predicted_values):\\n    \"\"\"\\n    Compute Root Mean Square Error (RMSE) between two time series.\\n\\n    Args:\\n        actual_values (array-like): Actual values of the time series.\\n        predicted_values (array-like): Predicted values of the time series.\\n\\n    Returns:\\n        float: RMSE value.\\n    \"\"\"\\n    # Ensure both arrays have the same length\\n    if len(actual_values) != len(predicted_values):\\n        raise ValueError(\"Lengths of actual_values and predicted_values must be the same.\")\\n\\n    # Convert input arrays to numpy arrays\\n    actual_values = np.array(actual_values)\\n    predicted_values = np.array(predicted_values)\\n\\n    # Compute the squared error between actual and predicted values\\n    squared_error = (actual_values - predicted_values) ** 2\\n\\n    # Compute the mean of squared errors\\n    mean_squared_error = np.mean(squared_error)\\n\\n    # Compute the square root of mean squared error (RMSE)\\n    rmse = np.sqrt(mean_squared_error)\\n\\n    return rmse',\n",
    "   \"rmse_gpt = compute_rmse(time_series[50:100],pred_dict_gpt_ar['median'])\",\n",
    "   \"rmse_gpt = compute_rmse(time_series[50:100],pred_dict_gpt_ar['median'])\\nrmse_arima = compute_rmse(time_series[50:100],pred_dict_arima_ar['median'])\\nprint(rmse_gpt,rmse_arima)\",\n",
    "   \"rmse_gpt_sin = compute_rmse(test2,pred_dict_gpt_sum['median'])\\nrmse_arima_sin = compute_rmse(test2],pred_dict_arima_sum['median'])\\nprint(rmse_gpt_sin,rmse_arima_sin)\",\n",
    "   \"rmse_gpt_sin = compute_rmse(test2,pred_dict_gpt_sum['median'])\\nrmse_arima_sin = compute_rmse(test2,pred_dict_arima_sum['median'])\\nprint(rmse_gpt_sin,rmse_arima_sin)\",\n",
    "   'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,\\'k-\\')\\nplt.plot(ar_coefficients_gpt,\\'r-\\')\\nplt.plot(ar_coefficients_arima,\\'b-\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\n\\nplt.savefig(\\'ar-coeff.png\\')',\n",
    "   'variables_dict = globals()',\n",
    "   'variables_dict',\n",
    "   \"variables_dict['ar_coefficients]\",\n",
    "   \"variables_dict['ar_coefficients']\",\n",
    "   '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "   '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "   '# Specify the filename for the pickle file\\nimport pickle\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "   'import pickle\\n\\n# Assuming you have your variables already defined in memory in Jupyter Notebook\\n\\n# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Get all global variables\\nvariables_dict = globals()\\n\\n# Filter out objects that cannot be pickled (e.g., modules, functions)\\nfiltered_variables_dict = {key: value for key, value in variables_dict.items() if not callable(value)}\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the filtered variables dictionary into the pickle file\\n    pickle.dump(filtered_variables_dict, f)\\n\\nprint(\"Filtered variables stored in pickle file:\", pickle_filename)',\n",
    "   'variables_dict'],\n",
    "  'Out': {6: {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    "   7: [defaultdict(dict,\n",
    "                {'model': 'gpt-4',\n",
    "                 'alpha': 0.3,\n",
    "                 'basic': True,\n",
    "                 'temp': 1.0,\n",
    "                 'top_p': 0.8,\n",
    "                 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')})],\n",
    "   10: {'samples':          50        51        52        53        54        55        56  \\\n",
    "    0  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "    1  0.942804  0.904312  0.856679  0.799904  0.736393  0.664221  0.585794   \n",
    "    2 -0.941842 -0.902388 -0.853792 -0.796055 -0.730619 -0.657966 -0.578096   \n",
    "    3  0.942804  0.904312  0.856679  0.799904  0.735430  0.663259  0.584351   \n",
    "    4 -0.943285 -0.905275 -0.857641 -0.801347 -0.737836 -0.666146 -0.587719   \n",
    "    5 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "    6 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "    7  0.942323  0.903350  0.855236  0.797979  0.733025  0.660372  0.580983   \n",
    "    8 -0.942804 -0.904794 -0.857160 -0.800866 -0.735912 -0.663740 -0.585313   \n",
    "    9  0.943285  0.905275  0.857160  0.800866  0.736874  0.665183  0.586757   \n",
    "    \n",
    "             57        58        59  ...        90        91        92        93  \\\n",
    "    0  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "    1  0.501113  0.411620  0.318278  ... -0.321164 -0.224454 -0.126301 -0.027185   \n",
    "    2 -0.492452 -0.401516 -0.306730  ...  0.286041  0.188368  0.088771 -0.011788   \n",
    "    3  0.499669  0.409695  0.315872  ... -0.321164 -0.224454 -0.125338 -0.025260   \n",
    "    4 -0.503518 -0.414507 -0.320683  ...  0.362543  0.279305  0.194142  0.108017   \n",
    "    5 -0.503037 -0.413544 -0.320202  ...  0.303843  0.207133  0.108498  0.008901   \n",
    "    6 -0.502556 -0.413063 -0.320202  ...  0.213388  0.113310  0.012750 -0.087809   \n",
    "    7  0.495820  0.405365  0.311060  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "    8 -0.500632 -0.410657 -0.316834  ...  0.310098  0.212426  0.112347  0.011788   \n",
    "    9  0.502556  0.413063  0.319721  ... -0.310579 -0.213869 -0.114272 -0.013713   \n",
    "    \n",
    "             94        95        96        97        98        99  \n",
    "    0  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "    1  0.084441  0.185481  0.284116  0.284116  0.284116  0.284116  \n",
    "    2 -0.111866 -0.211463 -0.308655 -0.403921 -0.494858 -0.580502  \n",
    "    3  0.075780  0.175859  0.274012  0.369760  0.461659  0.549227  \n",
    "    4  0.021411 -0.065676 -0.151801 -0.236483 -0.319721 -0.401035  \n",
    "    5 -0.092139 -0.192218 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "    6 -0.187887 -0.285079 -0.379864 -0.470319 -0.556444 -0.636315  \n",
    "    7  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "    8 -0.088771 -0.188849 -0.286522 -0.382270 -0.472725 -0.559331  \n",
    "    9  0.087328  0.187406  0.187406  0.187406  0.187406  0.187406  \n",
    "    \n",
    "    [10 rows x 50 columns],\n",
    "    'median': 50    0.000241\n",
    "    51    0.000481\n",
    "    52    0.000481\n",
    "    53    0.000722\n",
    "    54    0.000962\n",
    "    55    0.000962\n",
    "    56    0.001203\n",
    "    57    0.001443\n",
    "    58    0.001684\n",
    "    59    0.001925\n",
    "    60    0.003368\n",
    "    61    0.003849\n",
    "    62    0.004571\n",
    "    63   -0.001925\n",
    "    64   -0.002406\n",
    "    65   -0.002887\n",
    "    66   -0.003368\n",
    "    67   -0.004090\n",
    "    68   -0.004571\n",
    "    69   -0.005052\n",
    "    70   -0.005533\n",
    "    71   -0.006014\n",
    "    72   -0.006255\n",
    "    73   -0.006977\n",
    "    74   -0.007217\n",
    "    75   -0.008661\n",
    "    76   -0.009382\n",
    "    77   -0.010104\n",
    "    78   -0.011066\n",
    "    79   -0.011547\n",
    "    80   -0.012269\n",
    "    81   -0.013231\n",
    "    82   -0.018524\n",
    "    83   -0.023336\n",
    "    84   -0.027906\n",
    "    85   -0.032477\n",
    "    86   -0.036567\n",
    "    87   -0.040176\n",
    "    88   -0.043303\n",
    "    89   -0.045468\n",
    "    90   -0.047393\n",
    "    91   -0.048596\n",
    "    92   -0.049077\n",
    "    93   -0.011066\n",
    "    94    0.048596\n",
    "    95    0.055091\n",
    "    96    0.017802\n",
    "    97   -0.024538\n",
    "    98   -0.066157\n",
    "    99   -0.106814\n",
    "    dtype: float64,\n",
    "    'info': {'Method': 'gpt-4'},\n",
    "    'completions_list': [['1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "      '1959, 1879, 1780, 1662, 1530, 1380, 1217, 1041, 855, 661, 459, 254, 47, -166, -376, -580, -780, -970, -1151, -1319, -1474, -1614, -1737, -1843, -1929, -1996, -2042, -2067, -2072, -2055, -2017, -1957, -1878, -1780, -1663, -1532, -1383, -1221, -1046, -860, -667, -466, -262, -56, 175, 385, 590',\n",
    "      '-1957, -1875, -1774, -1654, -1518, -1367, -1201, -1023, -834, -637, -428, -219, -7, 201, 409, 612, 809, 997, 1175, 1342, 1493, 1629, 1749, 1851, 1935, 1998, 2040, 2062, 2062, 2041, 1999, 1925, 1835, 1728, 1607, 1471, 1320, 1155, 977, 790, 594, 391, 184, -24, -232, -439, -641, -839, -1028, -1206, -1372, -1524, -1661, -1781, -1884, -1967, -2030, -2071, -2093, -',\n",
    "      '1959, 1879, 1780, 1662, 1528, 1378, 1214, 1038, 851, 656, 454, 247, 38, -172, -381, -585, -784, -974, -1155, -1323, -1478, -1618, -1741, -1847, -1933, -2000, -2046, -2071, -2076, -2059, -2021, -1961, -1882, -1784, -1667, -1534, -1385, -1222, -1047, -861, -667, -466, -260, -52, 157, 365, 569, 768, 959, 1141, 1310, 1466, 1607, 1731, 1838, 1925, 1993, 2040, 2066, 207',\n",
    "      '-1960, -1881, -1782, -1665, -1533, -1384, -1221, -1046, -861, -666, -465, -260, -53, 154, 360, 561, 757, 944, 1122, 1287, 1439, 1576, 1697, 1799, 1883, 1944, 1986, 2007, 2007, 1987, 1946, 1892, 1820, 1733, 1630, 1514, 1384, 1240, 1086, 923, 753, 580, 403, 224, 44, -136, -315, -491, -664, -833, -998, -1157, -1309, -1446, -1571, -1681, -1775, -1853, -1915, -1960',\n",
    "      '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -52, 157, 365, 567, 765, 954, 1134, 1301, 1455, 1594, 1716, 1820, 1904, 1970, 2015, 2039, 2043, 2025, 1986, 1926, 1847, 1748, 1631, 1498, 1349, 1186, 1011, 825, 631, 430, 225, 18, -191, -399, -601, -799, -988, -1168',\n",
    "      '-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -665, -464, -259, -51, 156, 363, 565, 762, 950, 1130, 1296, 1449, 1587, 1708, 1812, 1896, 1961, 2005, 2028, 2029, 2008, 1966, 1885, 1784, 1665, 1529, 1377, 1211, 1033, 844, 647, 443, 235, 26, -182, -390, -592, -789, -977, -1156, -1322, -1475, -1613, -1734, -1838, -1921, -1986, -2030, -2053, -2054, -',\n",
    "      '1958, 1877, 1777, 1658, 1523, 1372, 1207, 1030, 842, 646, 443, 236, 27, -182, -390, -593, -791, -980, -1160, -1327, -1481, -1620, -1742, -1847, -1932, -1998, -2043, -2067, -2071, -2053, -2014, -1952, -1871, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "      '-1959, -1880, -1781, -1664, -1529, -1379, -1216, -1040, -853, -658, -456, -248, -38, 170, 378, 581, 779, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2059, 2042, 2003, 1943, 1864, 1765, 1648, 1513, 1363, 1200, 1025, 839, 644, 441, 233, 24, -184, -392, -595, -794, -982, -1162, -1329, -1483, -1622, -1744, -1850, -1936, -2002, -2047, -2071, -',\n",
    "      '1960, 1881, 1781, 1664, 1531, 1382, 1219, 1044, 858, 664, 463, 256, 47, -162, -370, -573, -771, -961, -1141, -1308, -1462, -1601, -1723, -1828, -1913, -1980, -2025, -2049, -2053, -2035, -1997, -1940, -1861, -1762, -1645, -1512, -1363, -1200, -1025, -839, -645, -444, -237, -28, 181, 389']],\n",
    "    'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "    'best_hyper': {'model': 'gpt-4',\n",
    "     'alpha': 0.3,\n",
    "     'basic': True,\n",
    "     'temp': 1.0,\n",
    "     'top_p': 0.8,\n",
    "     'settings': {'base': 10,\n",
    "      'prec': 3,\n",
    "      'signed': True,\n",
    "      'fixed_length': False,\n",
    "      'max_val': 10000000.0,\n",
    "      'time_sep': ', ',\n",
    "      'bit_sep': '',\n",
    "      'plus_sign': '',\n",
    "      'minus_sign': '-',\n",
    "      'half_bin_correction': True,\n",
    "      'decimal_point': '',\n",
    "      'missing_str': ' Nan'}}},\n",
    "   11: [<matplotlib.lines.Line2D at 0x28ce64520>],\n",
    "   13: {'samples':          50        51        52        53        54        55        56  \\\n",
    "    0 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "    1  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "    2  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "    3  0.942804  0.904312  0.856198  0.799423  0.735430  0.663259  0.583870   \n",
    "    4  0.943285  0.905275  0.857641  0.801347  0.737355  0.665664  0.587238   \n",
    "    5 -0.943285 -0.905275 -0.857160 -0.800385 -0.736393 -0.664221 -0.585313   \n",
    "    6 -0.942804 -0.904312 -0.856679 -0.799904 -0.735912 -0.664221 -0.585794   \n",
    "    7 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "    8 -0.943285 -0.904794 -0.856679 -0.800385 -0.735912 -0.664221 -0.585313   \n",
    "    9 -0.943285 -0.904794 -0.857160 -0.800866 -0.735912 -0.664221 -0.584832   \n",
    "    \n",
    "             57        58        59  ...        90        91        92        93  \\\n",
    "    0 -0.502556 -0.413063 -0.319721  ...  0.305768  0.209058  0.109461  0.009382   \n",
    "    1  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "    2  0.495339  0.404884  0.310579  ... -0.309136 -0.211463 -0.111866 -0.011307   \n",
    "    3  0.499188  0.408733  0.314910  ... -0.321164 -0.223492 -0.123895 -0.023336   \n",
    "    4  0.503037  0.413544  0.320202  ... -0.307211 -0.210501 -0.111866 -0.012269   \n",
    "    5 -0.500632 -0.410657 -0.316834  ...  0.286041  0.187887  0.087809 -0.012750   \n",
    "    6 -0.501113 -0.411139 -0.317796  ...  0.307692  0.210020  0.110423  0.009863   \n",
    "    7 -0.503037 -0.413544 -0.320202  ...  0.271125  0.174415  0.075299 -0.024779   \n",
    "    8 -0.501113 -0.411139 -0.317796  ...  0.301437  0.203765  0.104168  0.003609   \n",
    "    9 -0.500632 -0.410176 -0.316353  ...  0.307211  0.209539  0.109942  0.009382   \n",
    "    \n",
    "             94        95        96        97        98        99  \n",
    "    0 -0.091658 -0.191736 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "    1  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "    2  0.089734  0.189812  0.287484  0.382751  0.473687  0.560294  \n",
    "    3  0.077705  0.178264  0.276899  0.373128  0.465027  0.552595  \n",
    "    4  0.088771  0.188849  0.286522  0.381789  0.473206  0.560294  \n",
    "    5 -0.112829 -0.211944 -0.309136 -0.403921 -0.494377 -0.580502  \n",
    "    6 -0.091177 -0.191255 -0.288928 -0.384194 -0.475131 -0.561737  \n",
    "    7 -0.124857 -0.223492 -0.320202 -0.413544 -0.503037 -0.587238  \n",
    "    8 -0.098394 -0.198472 -0.296145 -0.391412 -0.482348 -0.568954  \n",
    "    9 -0.092139 -0.192218 -0.289890 -0.385157 -0.476093 -0.562699  \n",
    "    \n",
    "    [10 rows x 50 columns],\n",
    "    'median': 50   -0.943045\n",
    "    51   -0.904553\n",
    "    52   -0.856679\n",
    "    53   -0.800144\n",
    "    54   -0.735912\n",
    "    55   -0.664221\n",
    "    56   -0.585073\n",
    "    57   -0.500632\n",
    "    58   -0.410417\n",
    "    59   -0.316594\n",
    "    60   -0.219162\n",
    "    61   -0.119565\n",
    "    62   -0.019246\n",
    "    63    0.076502\n",
    "    64    0.176099\n",
    "    65    0.273290\n",
    "    66    0.368076\n",
    "    67    0.458531\n",
    "    68    0.544656\n",
    "    69    0.624526\n",
    "    70    0.698142\n",
    "    71    0.764540\n",
    "    72    0.822999\n",
    "    73    0.872557\n",
    "    74    0.912973\n",
    "    75    0.943526\n",
    "    76    0.964215\n",
    "    77    0.975041\n",
    "    78    0.975041\n",
    "    79    0.965418\n",
    "    80    0.945450\n",
    "    81    0.915379\n",
    "    82    0.875684\n",
    "    83    0.826607\n",
    "    84    0.768389\n",
    "    85    0.702713\n",
    "    86    0.629578\n",
    "    87    0.549949\n",
    "    88    0.464305\n",
    "    89    0.373369\n",
    "    90    0.278583\n",
    "    91    0.181151\n",
    "    92    0.081554\n",
    "    93   -0.010826\n",
    "    94   -0.091418\n",
    "    95   -0.191496\n",
    "    96   -0.289168\n",
    "    97   -0.384435\n",
    "    98   -0.475371\n",
    "    99   -0.561978\n",
    "    dtype: float64,\n",
    "    'info': {'Method': 'gpt-4'},\n",
    "    'completions_list': [['-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -664, -463, -256, -48, 161, 369, 572, 770, 959, 1139, 1306, 1460, 1599, 1721, 1826, 1911, 1977, 2022, 2046, 2050, 2032, 1993, 1933, 1852, 1752, 1635, 1502, 1353, 1190, 1015, 829, 635, 434, 227, 19, -190, -398, -601, -799, -988, -1168, -1335, -1489, -1628, -1750, -1855, -1940, -2006, -2051, -2075, -',\n",
    "      '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853',\n",
    "      '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 233, 24, -185, -393, -596, -794, -983, -1163, -1330, -1484, -1623, -1745, -1850, -1935, -2001, -2046, -2070, -2074, -2056, -2017, -1955, -1874, -1773, -1654, -1519, -1368, -1203, -1026, -838, -642, -439, -232, -23, 186, 394, 597, 795, 984, 1164, 1331, 1485, 1624, 1746, 1851, 1936, 2002, 2047, 2071, 207',\n",
    "      '1959, 1879, 1779, 1661, 1528, 1378, 1213, 1037, 849, 654, 451, 244, 35, -174, -383, -587, -786, -976, -1157, -1325, -1480, -1620, -1743, -1849, -1935, -2002, -2048, -2073, -2078, -2061, -2023, -1963, -1884, -1785, -1668, -1536, -1387, -1223, -1048, -861, -667, -464, -257, -48, 161, 370, 575, 775, 966, 1148, 1317, 1473, 1614, 1738, 1845, 1932, 2000, 2047, 2072, 207',\n",
    "      '1960, 1881, 1782, 1665, 1532, 1383, 1220, 1045, 859, 665, 464, 259, 52, -157, -365, -568, -766, -956, -1137, -1304, -1458, -1597, -1719, -1824, -1910, -1976, -2021, -2045, -2049, -2031, -1992, -1933, -1854, -1755, -1638, -1505, -1356, -1193, -1018, -832, -638, -437, -232, -25, 184, 392, 595, 793, 983, 1164, 1331, 1485, 1624, 1746, 1851, 1937, 2003, 2048, 2072, 207',\n",
    "      '-1960, -1881, -1781, -1663, -1530, -1380, -1216, -1040, -853, -658, -456, -249, -40, 168, 375, 577, 775, 963, 1142, 1308, 1461, 1599, 1720, 1824, 1909, 1974, 2018, 2041, 2043, 2023, 1982, 1919, 1837, 1735, 1615, 1479, 1327, 1161, 983, 792, 594, 390, 182, -26, -234, -440, -642, -839, -1027, -1206, -1371, -1523, -1661',\n",
    "      '-1959, -1879, -1780, -1662, -1529, -1380, -1217, -1041, -854, -660, -457, -250, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1938, 1858, 1759, 1641, 1508, 1359, 1196, 1020, 833, 639, 436, 229, 20, -189, -397, -600, -798, -987, -1167, -1334, -1488, -1627, -1749, -1854, -1939, -2005, -2050, -2074, -',\n",
    "      '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -51, 156, 362, 563, 759, 946, 1124, 1289, 1441, 1578, 1700, 1802, 1885, 1947, 1989, 2011, 2009, 1989, 1947, 1885, 1802, 1700, 1578, 1441, 1289, 1124, 946, 759, 563, 362, 156, -51, -259, -464, -665, -859, -1045, -1220, -1383, -1532, -1665, -1782, -1881, -1960, -2020, -2059, -2077, -',\n",
    "      '-1960, -1880, -1780, -1663, -1529, -1380, -1216, -1041, -854, -660, -458, -252, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1939, 1858, 1757, 1638, 1503, 1352, 1187, 1010, 822, 626, 423, 216, 7, -204, -412, -615, -813, -1002, -1182, -1349, -1503, -1642, -1764, -1869, -1954, -2020, -2065, -2089,',\n",
    "      '-1960, -1880, -1781, -1664, -1529, -1380, -1215, -1040, -852, -657, -454, -247, -39, 169, 377, 580, 778, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2058, 2040, 2001, 1941, 1861, 1762, 1645, 1510, 1361, 1196, 1021, 833, 638, 435, 228, 19, -191, -399, -602, -800, -989, -1169, -1336, -1490, -1629, -1751, -1856, -1941, -2007, -2052, -2076, -']],\n",
    "    'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "    'best_hyper': {'model': 'gpt-4',\n",
    "     'alpha': 0.3,\n",
    "     'basic': True,\n",
    "     'temp': 1.0,\n",
    "     'top_p': 0.8,\n",
    "     'settings': {'base': 10,\n",
    "      'prec': 3,\n",
    "      'signed': True,\n",
    "      'fixed_length': False,\n",
    "      'max_val': 10000000.0,\n",
    "      'time_sep': ', ',\n",
    "      'bit_sep': '',\n",
    "      'plus_sign': '',\n",
    "      'minus_sign': '-',\n",
    "      'half_bin_correction': True,\n",
    "      'decimal_point': '',\n",
    "      'missing_str': ' Nan'}}},\n",
    "   14: [<matplotlib.lines.Line2D at 0x28e598ac0>],\n",
    "   15: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   17: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   18: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   19: <matplotlib.legend.Legend at 0x28f18c790>,\n",
    "   22: [<matplotlib.lines.Line2D at 0x28f3fb1c0>],\n",
    "   24: [<matplotlib.lines.Line2D at 0x28f3bdf70>],\n",
    "   26: [<matplotlib.lines.Line2D at 0x28f4aaa30>],\n",
    "   31: [<matplotlib.lines.Line2D at 0x28f65f130>],\n",
    "   60: array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "           1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "          -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "           0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "          -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "           0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "           0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "           1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "          -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "           0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149,\n",
    "           0.18718621, -0.4757239 , -1.64344264, -0.09358268,  0.10309571,\n",
    "           0.095137  ,  1.06676763, -1.8428797 , -1.04016223, -0.1471965 ,\n",
    "           1.1094952 , -1.38843155, -1.34927948,  2.2983403 , -0.5684549 ,\n",
    "           0.74208654,  0.46162906,  1.62492308, -0.75288572, -0.6291802 ,\n",
    "           0.46314307,  0.64471457,  0.19379909, -1.41415266, -1.23427455,\n",
    "          -0.40777303,  0.81886616,  0.40483561, -0.5155421 , -0.566217  ,\n",
    "          -0.29358193,  0.88388512, -1.1597346 , -0.41722568,  0.55364882,\n",
    "           0.32269808, -1.18005105, -0.63975452,  1.24861017,  1.32987551,\n",
    "           0.75395216,  0.47690589,  0.29144071,  0.84784154,  0.82063337,\n",
    "           0.44373127, -1.11129098,  0.71013579,  0.89859217, -1.24352553]),\n",
    "   61: array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "           1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "          -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "           0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "          -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "           0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "           0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "           1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "          -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "           0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149]),\n",
    "   62: Text(24.00000000000002, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   63: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   64: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   66: Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "   78: array([ 0.42459049, -0.71090158,  0.28381361,  0.19212327, -0.10471756,\n",
    "           0.23711138, -0.25102066, -0.39702093, -0.19640616, -0.40924017,\n",
    "          -0.35815403,  0.14991523, -0.01944757,  0.11782569, -0.29788144,\n",
    "          -0.19526565, -0.48413894, -0.03631446, -0.47901333,  0.0322904 ]),\n",
    "   79: [<matplotlib.lines.Line2D at 0x29fe344c0>],\n",
    "   80: [<matplotlib.lines.Line2D at 0x2adb847c0>],\n",
    "   81: [<matplotlib.lines.Line2D at 0x2adc2b3d0>],\n",
    "   82: [<matplotlib.lines.Line2D at 0x29fe41e80>],\n",
    "   96: {...},\n",
    "   98: array([-0.57073806, -0.25504165, -0.43684139, -0.39442566, -0.3266803 ,\n",
    "          -0.09596204, -0.1837547 , -0.01177321, -0.12021627, -0.1537689 ,\n",
    "           0.06362805, -0.3066356 , -0.18471353, -0.14508358, -0.45184114,\n",
    "          -0.12185355,  0.1268503 , -0.33401473, -0.45442659,  0.04557276])},\n",
    "  '_': array([-0.57073806, -0.25504165, -0.43684139, -0.39442566, -0.3266803 ,\n",
    "         -0.09596204, -0.1837547 , -0.01177321, -0.12021627, -0.1537689 ,\n",
    "          0.06362805, -0.3066356 , -0.18471353, -0.14508358, -0.45184114,\n",
    "         -0.12185355,  0.1268503 , -0.33401473, -0.45442659,  0.04557276]),\n",
    "  '__': {...},\n",
    "  '___': [<matplotlib.lines.Line2D at 0x29fe41e80>],\n",
    "  '__session__': '/Users/rdey33/Downloads/llmtime/llmtime-dynamics/physics_demo.ipynb',\n",
    "  '_i': '# Specify the filename for the pickle file\\nimport pickle\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "  '_ii': '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "  '_iii': '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "  '_i1': 'import os\\nos.environ[\\'OMP_NUM_THREADS\\'] = \\'4\\'\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\nimport openai\\n#openai.api_key = os.environ[\\'OPENAI_API_KEY\\']\\nopenai.api_key  = \\'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\\' #chandra2\\nopenai.api_base = os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\\nfrom data.serialize import SerializerSettings\\nfrom models.utils import grid_iter\\nfrom models.promptcast import get_promptcast_predictions_data\\nfrom models.darts import get_arima_predictions_data\\nfrom models.llmtime import get_llmtime_predictions_data\\nfrom data.small_context import get_datasets\\nfrom models.validation_likelihood_tuning import get_autotuned_predictions_data\\nimport logging\\nimport pickle',\n",
    "  'os': <module 'os' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/os.py'>,\n",
    "  'np': <module 'numpy' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/numpy/__init__.py'>,\n",
    "  'pd': <module 'pandas' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/pandas/__init__.py'>,\n",
    "  'plt': <module 'matplotlib.pyplot' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/matplotlib/pyplot.py'>,\n",
    "  'openai': <module 'openai' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/openai/__init__.py'>,\n",
    "  'logging': <module 'logging' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/logging/__init__.py'>,\n",
    "  'pickle': <module 'pickle' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/pickle.py'>,\n",
    "  '_i2': \"def plot_preds(train, test, pred_dict, model_name, show_samples=False):\\n    pred = pred_dict['median']\\n    pred = pd.Series(pred, index=test.index)\\n    plt.figure(figsize=(8, 6), dpi=100)\\n    plt.plot(train)\\n    plt.plot(test, label='Truth', color='black')\\n    plt.plot(pred, label=model_name, color='purple')\\n    # shade 90% confidence interval\\n    samples = pred_dict['samples']\\n    lower = np.quantile(samples, 0.05, axis=0)\\n    upper = np.quantile(samples, 0.95, axis=0)\\n    plt.fill_between(pred.index, lower, upper, alpha=0.3, color='purple')\\n    if show_samples:\\n        samples = pred_dict['samples']\\n        # convert df to numpy array\\n        samples = samples.values if isinstance(samples, pd.DataFrame) else samples\\n        for i in range(min(10, samples.shape[0])):\\n            plt.plot(pred.index, samples[i], color='purple', alpha=0.3, linewidth=1)\\n    plt.legend(loc='upper left')\\n    if 'NLL/D' in pred_dict:\\n        nll = pred_dict['NLL/D']\\n        if nll is not None:\\n            plt.text(0.03, 0.85, f'NLL/D: {nll:.2f}', transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.5))\\n    plt.show()\\n\\n\\n\\ngpt4_hypers = dict(\\n    alpha=0.3,\\n    basic=True,\\n    temp=1.0,\\n    top_p=0.8,\\n    settings=SerializerSettings(base=10, prec=3, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\\n)\\n\\ngpt3_hypers = dict(\\n    temp=0.7,\\n    alpha=0.95,\\n    beta=0.3,\\n    basic=False,\\n    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True)\\n)\\n\\n\\npromptcast_hypers = dict(\\n    temp=0.7,\\n    settings=SerializerSettings(base=10, prec=0, signed=True, \\n                                time_sep=', ',\\n                                bit_sep='',\\n                                plus_sign='',\\n                                minus_sign='-',\\n                                half_bin_correction=False,\\n                                decimal_point='')\\n)\\n\\narima_hypers = dict(p=[12,30], d=[1,2], q=[0])\\n\\nmodel_hypers = {\\n    #'LLMTime GPT-3.5': {'model': 'gpt-3.5-turbo-instruct', **gpt3_hypers},\\n    'LLMTime GPT-4': {'model': 'gpt-4', **gpt4_hypers},\\n    #'LLMTime GPT-3': {'model': 'text-davinci-003', **gpt3_hypers},\\n    #'PromptCast GPT-3': {'model': 'text-davinci-003', **promptcast_hypers},\\n    'ARIMA': arima_hypers,\\n    \\n}\\n\\nmodel_predict_fns = {\\n\\n    #'LLMTime GPT-3': get_llmtime_predictions_data,\\n    #'LLMTime GPT-3.5': get_llmtime_predictions_data,\\n    'LLMTime GPT-4': get_llmtime_predictions_data,\\n    #'PromptCast GPT-3': get_promptcast_predictions_data,\\n    'ARIMA': get_arima_predictions_data,\\n}\\n\\nmodel_names = list(model_predict_fns.keys())\",\n",
    "  'gpt4_hypers': {'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    "  'gpt3_hypers': {'temp': 0.7,\n",
    "   'alpha': 0.95,\n",
    "   'beta': 0.3,\n",
    "   'basic': False,\n",
    "   'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=' ,', bit_sep=' ', plus_sign='', minus_sign=' -', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    "  'promptcast_hypers': {'temp': 0.7,\n",
    "   'settings': SerializerSettings(base=10, prec=0, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=False, decimal_point='', missing_str=' Nan')},\n",
    "  'arima_hypers': {'p': [12, 30], 'd': [1, 2], 'q': [0]},\n",
    "  'model_hypers': {'LLMTime GPT-4': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    "   'ARIMA': {'p': [12, 30], 'd': [1, 2], 'q': [0]}},\n",
    "  'model_predict_fns': {'LLMTime GPT-4': <function models.llmtime.get_llmtime_predictions_data(train, test, model, settings, num_samples=10, temp=0.7, alpha=0.95, beta=0.3, basic=False, parallel=True, **kwargs)>,\n",
    "   'ARIMA': <function models.darts.get_arima_predictions_data(train, test, p=12, d=1, q=0, num_samples=100, **kwargs)>},\n",
    "  'model_names': ['LLMTime GPT-4', 'ARIMA'],\n",
    "  '_i3': \"def print_full(x):\\n    pd.set_option('display.max_rows', len(x))\\n    print(x)\\n    pd.reset_option('display.max_rows')\",\n",
    "  '_i4': 'x = np.linspace(0,10,100)\\ntrain = np.sin(x[0:50])\\ntest = np.sin(x[50:100])',\n",
    "  'x': array([ 0.        ,  0.1010101 ,  0.2020202 ,  0.3030303 ,  0.4040404 ,\n",
    "          0.50505051,  0.60606061,  0.70707071,  0.80808081,  0.90909091,\n",
    "          1.01010101,  1.11111111,  1.21212121,  1.31313131,  1.41414141,\n",
    "          1.51515152,  1.61616162,  1.71717172,  1.81818182,  1.91919192,\n",
    "          2.02020202,  2.12121212,  2.22222222,  2.32323232,  2.42424242,\n",
    "          2.52525253,  2.62626263,  2.72727273,  2.82828283,  2.92929293,\n",
    "          3.03030303,  3.13131313,  3.23232323,  3.33333333,  3.43434343,\n",
    "          3.53535354,  3.63636364,  3.73737374,  3.83838384,  3.93939394,\n",
    "          4.04040404,  4.14141414,  4.24242424,  4.34343434,  4.44444444,\n",
    "          4.54545455,  4.64646465,  4.74747475,  4.84848485,  4.94949495,\n",
    "          5.05050505,  5.15151515,  5.25252525,  5.35353535,  5.45454545,\n",
    "          5.55555556,  5.65656566,  5.75757576,  5.85858586,  5.95959596,\n",
    "          6.06060606,  6.16161616,  6.26262626,  6.36363636,  6.46464646,\n",
    "          6.56565657,  6.66666667,  6.76767677,  6.86868687,  6.96969697,\n",
    "          7.07070707,  7.17171717,  7.27272727,  7.37373737,  7.47474747,\n",
    "          7.57575758,  7.67676768,  7.77777778,  7.87878788,  7.97979798,\n",
    "          8.08080808,  8.18181818,  8.28282828,  8.38383838,  8.48484848,\n",
    "          8.58585859,  8.68686869,  8.78787879,  8.88888889,  8.98989899,\n",
    "          9.09090909,  9.19191919,  9.29292929,  9.39393939,  9.49494949,\n",
    "          9.5959596 ,  9.6969697 ,  9.7979798 ,  9.8989899 , 10.        ]),\n",
    "  'train': array([ 0.        ,  0.2972367 ,  0.35731232,  0.31400343,  0.26585066,\n",
    "          0.27639963,  0.51256688,  0.8213306 ,  0.904692  ,  0.83590927,\n",
    "          0.75100161,  0.69065491,  0.8269244 ,  1.10119197,  1.18749806,\n",
    "          1.07717744,  0.93495622,  0.79682455,  0.81654052,  1.02603832,\n",
    "          1.10864503,  0.96282708,  0.76279164,  0.55916882,  0.47259406,\n",
    "          0.60907063,  0.69685163,  0.54379641,  0.3070198 ,  0.06723   ,\n",
    "         -0.09212802, -0.01636787,  0.09607604, -0.02163259, -0.2585526 ,\n",
    "         -0.49658592, -0.68292178, -0.64326164, -0.48587393, -0.52472469,\n",
    "         -0.72099784, -0.92253453, -1.09233244, -1.06357349, -0.851197  ,\n",
    "         -0.78119449, -0.90437415, -1.04875937, -1.17414227, -1.14131212]),\n",
    "  'test': array([-0.88209427, -0.6973774 , -0.73270271, -0.81938345, -0.89577425,\n",
    "         -0.86009574, -0.58199325, -0.30401812, -0.25741528, -0.304764  ,\n",
    "         -0.35037054, -0.32835171, -0.0733774 ,  0.25444065,  0.36049572,\n",
    "          0.32328515,  0.27583927,  0.25965338,  0.44691271,  0.77132079,\n",
    "          0.90728793,  0.85243785,  0.76933234,  0.69306657,  0.7788732 ,\n",
    "          1.05163056,  1.19205516,  1.10521015,  0.96486774,  0.81934952,\n",
    "          0.79155354,  0.98211495,  1.11423813,  1.0018416 ,  0.80394875,\n",
    "          0.59821144,  0.47047521,  0.57244203,  0.69909477,  0.58828182,\n",
    "          0.35534332,  0.11544319, -0.07670492, -0.04722262,  0.08857259,\n",
    "          0.01931833, -0.20967662, -0.44819378, -0.65833188, -0.67149316]),\n",
    "  '_i5': \"for model in model_names: # GPT-4 takes a about a minute to run\\n    model_hypers[model].update({'dataset_name': ds_name}) # for promptcast\\n    hypers = list(grid_iter(model_hypers[model]))\\n    num_samples = 10\\n    pred_dict = get_autotuned_predictions_data(train, test, hypers, num_samples, model_predict_fns[model], verbose=False, parallel=False)\\n    out[model] = pred_dict\\n    plot_preds(train, test, pred_dict, model, show_samples=True)\",\n",
    "  'model': 'LLMTime GPT-4',\n",
    "  '_i6': \"model_hypers['LLMTime GPT-4']\",\n",
    "  '_6': {'model': 'gpt-4',\n",
    "   'alpha': 0.3,\n",
    "   'basic': True,\n",
    "   'temp': 1.0,\n",
    "   'top_p': 0.8,\n",
    "   'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')},\n",
    "  '_i7': \"hypers = list(grid_iter(model_hypers['LLMTime GPT-4']))\\nhypers\",\n",
    "  'hypers': [defaultdict(dict,\n",
    "               {'model': 'gpt-4',\n",
    "                'alpha': 0.3,\n",
    "                'basic': True,\n",
    "                'temp': 1.0,\n",
    "                'top_p': 0.8,\n",
    "                'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')})],\n",
    "  '_7': [defaultdict(dict,\n",
    "               {'model': 'gpt-4',\n",
    "                'alpha': 0.3,\n",
    "                'basic': True,\n",
    "                'temp': 1.0,\n",
    "                'top_p': 0.8,\n",
    "                'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan')})],\n",
    "  '_i8': \"import matplotlib.pyplot as plt\\nplt.plot(train,'o')\\nplt.show()\",\n",
    "  '_i9': \"pred_dict = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "  'pred_dict': {'samples':          50        51        52        53        54        55        56  \\\n",
    "   0 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "   1  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   2  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   3  0.942804  0.904312  0.856198  0.799423  0.735430  0.663259  0.583870   \n",
    "   4  0.943285  0.905275  0.857641  0.801347  0.737355  0.665664  0.587238   \n",
    "   5 -0.943285 -0.905275 -0.857160 -0.800385 -0.736393 -0.664221 -0.585313   \n",
    "   6 -0.942804 -0.904312 -0.856679 -0.799904 -0.735912 -0.664221 -0.585794   \n",
    "   7 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "   8 -0.943285 -0.904794 -0.856679 -0.800385 -0.735912 -0.664221 -0.585313   \n",
    "   9 -0.943285 -0.904794 -0.857160 -0.800866 -0.735912 -0.664221 -0.584832   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0 -0.502556 -0.413063 -0.319721  ...  0.305768  0.209058  0.109461  0.009382   \n",
    "   1  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "   2  0.495339  0.404884  0.310579  ... -0.309136 -0.211463 -0.111866 -0.011307   \n",
    "   3  0.499188  0.408733  0.314910  ... -0.321164 -0.223492 -0.123895 -0.023336   \n",
    "   4  0.503037  0.413544  0.320202  ... -0.307211 -0.210501 -0.111866 -0.012269   \n",
    "   5 -0.500632 -0.410657 -0.316834  ...  0.286041  0.187887  0.087809 -0.012750   \n",
    "   6 -0.501113 -0.411139 -0.317796  ...  0.307692  0.210020  0.110423  0.009863   \n",
    "   7 -0.503037 -0.413544 -0.320202  ...  0.271125  0.174415  0.075299 -0.024779   \n",
    "   8 -0.501113 -0.411139 -0.317796  ...  0.301437  0.203765  0.104168  0.003609   \n",
    "   9 -0.500632 -0.410176 -0.316353  ...  0.307211  0.209539  0.109942  0.009382   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0 -0.091658 -0.191736 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "   1  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "   2  0.089734  0.189812  0.287484  0.382751  0.473687  0.560294  \n",
    "   3  0.077705  0.178264  0.276899  0.373128  0.465027  0.552595  \n",
    "   4  0.088771  0.188849  0.286522  0.381789  0.473206  0.560294  \n",
    "   5 -0.112829 -0.211944 -0.309136 -0.403921 -0.494377 -0.580502  \n",
    "   6 -0.091177 -0.191255 -0.288928 -0.384194 -0.475131 -0.561737  \n",
    "   7 -0.124857 -0.223492 -0.320202 -0.413544 -0.503037 -0.587238  \n",
    "   8 -0.098394 -0.198472 -0.296145 -0.391412 -0.482348 -0.568954  \n",
    "   9 -0.092139 -0.192218 -0.289890 -0.385157 -0.476093 -0.562699  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50   -0.943045\n",
    "   51   -0.904553\n",
    "   52   -0.856679\n",
    "   53   -0.800144\n",
    "   54   -0.735912\n",
    "   55   -0.664221\n",
    "   56   -0.585073\n",
    "   57   -0.500632\n",
    "   58   -0.410417\n",
    "   59   -0.316594\n",
    "   60   -0.219162\n",
    "   61   -0.119565\n",
    "   62   -0.019246\n",
    "   63    0.076502\n",
    "   64    0.176099\n",
    "   65    0.273290\n",
    "   66    0.368076\n",
    "   67    0.458531\n",
    "   68    0.544656\n",
    "   69    0.624526\n",
    "   70    0.698142\n",
    "   71    0.764540\n",
    "   72    0.822999\n",
    "   73    0.872557\n",
    "   74    0.912973\n",
    "   75    0.943526\n",
    "   76    0.964215\n",
    "   77    0.975041\n",
    "   78    0.975041\n",
    "   79    0.965418\n",
    "   80    0.945450\n",
    "   81    0.915379\n",
    "   82    0.875684\n",
    "   83    0.826607\n",
    "   84    0.768389\n",
    "   85    0.702713\n",
    "   86    0.629578\n",
    "   87    0.549949\n",
    "   88    0.464305\n",
    "   89    0.373369\n",
    "   90    0.278583\n",
    "   91    0.181151\n",
    "   92    0.081554\n",
    "   93   -0.010826\n",
    "   94   -0.091418\n",
    "   95   -0.191496\n",
    "   96   -0.289168\n",
    "   97   -0.384435\n",
    "   98   -0.475371\n",
    "   99   -0.561978\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'gpt-4'},\n",
    "   'completions_list': [['-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -664, -463, -256, -48, 161, 369, 572, 770, 959, 1139, 1306, 1460, 1599, 1721, 1826, 1911, 1977, 2022, 2046, 2050, 2032, 1993, 1933, 1852, 1752, 1635, 1502, 1353, 1190, 1015, 829, 635, 434, 227, 19, -190, -398, -601, -799, -988, -1168, -1335, -1489, -1628, -1750, -1855, -1940, -2006, -2051, -2075, -',\n",
    "     '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853',\n",
    "     '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 233, 24, -185, -393, -596, -794, -983, -1163, -1330, -1484, -1623, -1745, -1850, -1935, -2001, -2046, -2070, -2074, -2056, -2017, -1955, -1874, -1773, -1654, -1519, -1368, -1203, -1026, -838, -642, -439, -232, -23, 186, 394, 597, 795, 984, 1164, 1331, 1485, 1624, 1746, 1851, 1936, 2002, 2047, 2071, 207',\n",
    "     '1959, 1879, 1779, 1661, 1528, 1378, 1213, 1037, 849, 654, 451, 244, 35, -174, -383, -587, -786, -976, -1157, -1325, -1480, -1620, -1743, -1849, -1935, -2002, -2048, -2073, -2078, -2061, -2023, -1963, -1884, -1785, -1668, -1536, -1387, -1223, -1048, -861, -667, -464, -257, -48, 161, 370, 575, 775, 966, 1148, 1317, 1473, 1614, 1738, 1845, 1932, 2000, 2047, 2072, 207',\n",
    "     '1960, 1881, 1782, 1665, 1532, 1383, 1220, 1045, 859, 665, 464, 259, 52, -157, -365, -568, -766, -956, -1137, -1304, -1458, -1597, -1719, -1824, -1910, -1976, -2021, -2045, -2049, -2031, -1992, -1933, -1854, -1755, -1638, -1505, -1356, -1193, -1018, -832, -638, -437, -232, -25, 184, 392, 595, 793, 983, 1164, 1331, 1485, 1624, 1746, 1851, 1937, 2003, 2048, 2072, 207',\n",
    "     '-1960, -1881, -1781, -1663, -1530, -1380, -1216, -1040, -853, -658, -456, -249, -40, 168, 375, 577, 775, 963, 1142, 1308, 1461, 1599, 1720, 1824, 1909, 1974, 2018, 2041, 2043, 2023, 1982, 1919, 1837, 1735, 1615, 1479, 1327, 1161, 983, 792, 594, 390, 182, -26, -234, -440, -642, -839, -1027, -1206, -1371, -1523, -1661',\n",
    "     '-1959, -1879, -1780, -1662, -1529, -1380, -1217, -1041, -854, -660, -457, -250, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1938, 1858, 1759, 1641, 1508, 1359, 1196, 1020, 833, 639, 436, 229, 20, -189, -397, -600, -798, -987, -1167, -1334, -1488, -1627, -1749, -1854, -1939, -2005, -2050, -2074, -',\n",
    "     '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -51, 156, 362, 563, 759, 946, 1124, 1289, 1441, 1578, 1700, 1802, 1885, 1947, 1989, 2011, 2009, 1989, 1947, 1885, 1802, 1700, 1578, 1441, 1289, 1124, 946, 759, 563, 362, 156, -51, -259, -464, -665, -859, -1045, -1220, -1383, -1532, -1665, -1782, -1881, -1960, -2020, -2059, -2077, -',\n",
    "     '-1960, -1880, -1780, -1663, -1529, -1380, -1216, -1041, -854, -660, -458, -252, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1939, 1858, 1757, 1638, 1503, 1352, 1187, 1010, 822, 626, 423, 216, 7, -204, -412, -615, -813, -1002, -1182, -1349, -1503, -1642, -1764, -1869, -1954, -2020, -2065, -2089,',\n",
    "     '-1960, -1880, -1781, -1664, -1529, -1380, -1215, -1040, -852, -657, -454, -247, -39, 169, 377, 580, 778, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2058, 2040, 2001, 1941, 1861, 1762, 1645, 1510, 1361, 1196, 1021, 833, 638, 435, 228, 19, -191, -399, -602, -800, -989, -1169, -1336, -1490, -1629, -1751, -1856, -1941, -2007, -2052, -2076, -']],\n",
    "   'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  '_i10': 'pred_dict',\n",
    "  '_10': {'samples':          50        51        52        53        54        55        56  \\\n",
    "   0  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   1  0.942804  0.904312  0.856679  0.799904  0.736393  0.664221  0.585794   \n",
    "   2 -0.941842 -0.902388 -0.853792 -0.796055 -0.730619 -0.657966 -0.578096   \n",
    "   3  0.942804  0.904312  0.856679  0.799904  0.735430  0.663259  0.584351   \n",
    "   4 -0.943285 -0.905275 -0.857641 -0.801347 -0.737836 -0.666146 -0.587719   \n",
    "   5 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "   6 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "   7  0.942323  0.903350  0.855236  0.797979  0.733025  0.660372  0.580983   \n",
    "   8 -0.942804 -0.904794 -0.857160 -0.800866 -0.735912 -0.663740 -0.585313   \n",
    "   9  0.943285  0.905275  0.857160  0.800866  0.736874  0.665183  0.586757   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "   1  0.501113  0.411620  0.318278  ... -0.321164 -0.224454 -0.126301 -0.027185   \n",
    "   2 -0.492452 -0.401516 -0.306730  ...  0.286041  0.188368  0.088771 -0.011788   \n",
    "   3  0.499669  0.409695  0.315872  ... -0.321164 -0.224454 -0.125338 -0.025260   \n",
    "   4 -0.503518 -0.414507 -0.320683  ...  0.362543  0.279305  0.194142  0.108017   \n",
    "   5 -0.503037 -0.413544 -0.320202  ...  0.303843  0.207133  0.108498  0.008901   \n",
    "   6 -0.502556 -0.413063 -0.320202  ...  0.213388  0.113310  0.012750 -0.087809   \n",
    "   7  0.495820  0.405365  0.311060  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "   8 -0.500632 -0.410657 -0.316834  ...  0.310098  0.212426  0.112347  0.011788   \n",
    "   9  0.502556  0.413063  0.319721  ... -0.310579 -0.213869 -0.114272 -0.013713   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "   1  0.084441  0.185481  0.284116  0.284116  0.284116  0.284116  \n",
    "   2 -0.111866 -0.211463 -0.308655 -0.403921 -0.494858 -0.580502  \n",
    "   3  0.075780  0.175859  0.274012  0.369760  0.461659  0.549227  \n",
    "   4  0.021411 -0.065676 -0.151801 -0.236483 -0.319721 -0.401035  \n",
    "   5 -0.092139 -0.192218 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "   6 -0.187887 -0.285079 -0.379864 -0.470319 -0.556444 -0.636315  \n",
    "   7  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "   8 -0.088771 -0.188849 -0.286522 -0.382270 -0.472725 -0.559331  \n",
    "   9  0.087328  0.187406  0.187406  0.187406  0.187406  0.187406  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50    0.000241\n",
    "   51    0.000481\n",
    "   52    0.000481\n",
    "   53    0.000722\n",
    "   54    0.000962\n",
    "   55    0.000962\n",
    "   56    0.001203\n",
    "   57    0.001443\n",
    "   58    0.001684\n",
    "   59    0.001925\n",
    "   60    0.003368\n",
    "   61    0.003849\n",
    "   62    0.004571\n",
    "   63   -0.001925\n",
    "   64   -0.002406\n",
    "   65   -0.002887\n",
    "   66   -0.003368\n",
    "   67   -0.004090\n",
    "   68   -0.004571\n",
    "   69   -0.005052\n",
    "   70   -0.005533\n",
    "   71   -0.006014\n",
    "   72   -0.006255\n",
    "   73   -0.006977\n",
    "   74   -0.007217\n",
    "   75   -0.008661\n",
    "   76   -0.009382\n",
    "   77   -0.010104\n",
    "   78   -0.011066\n",
    "   79   -0.011547\n",
    "   80   -0.012269\n",
    "   81   -0.013231\n",
    "   82   -0.018524\n",
    "   83   -0.023336\n",
    "   84   -0.027906\n",
    "   85   -0.032477\n",
    "   86   -0.036567\n",
    "   87   -0.040176\n",
    "   88   -0.043303\n",
    "   89   -0.045468\n",
    "   90   -0.047393\n",
    "   91   -0.048596\n",
    "   92   -0.049077\n",
    "   93   -0.011066\n",
    "   94    0.048596\n",
    "   95    0.055091\n",
    "   96    0.017802\n",
    "   97   -0.024538\n",
    "   98   -0.066157\n",
    "   99   -0.106814\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'gpt-4'},\n",
    "   'completions_list': [['1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "     '1959, 1879, 1780, 1662, 1530, 1380, 1217, 1041, 855, 661, 459, 254, 47, -166, -376, -580, -780, -970, -1151, -1319, -1474, -1614, -1737, -1843, -1929, -1996, -2042, -2067, -2072, -2055, -2017, -1957, -1878, -1780, -1663, -1532, -1383, -1221, -1046, -860, -667, -466, -262, -56, 175, 385, 590',\n",
    "     '-1957, -1875, -1774, -1654, -1518, -1367, -1201, -1023, -834, -637, -428, -219, -7, 201, 409, 612, 809, 997, 1175, 1342, 1493, 1629, 1749, 1851, 1935, 1998, 2040, 2062, 2062, 2041, 1999, 1925, 1835, 1728, 1607, 1471, 1320, 1155, 977, 790, 594, 391, 184, -24, -232, -439, -641, -839, -1028, -1206, -1372, -1524, -1661, -1781, -1884, -1967, -2030, -2071, -2093, -',\n",
    "     '1959, 1879, 1780, 1662, 1528, 1378, 1214, 1038, 851, 656, 454, 247, 38, -172, -381, -585, -784, -974, -1155, -1323, -1478, -1618, -1741, -1847, -1933, -2000, -2046, -2071, -2076, -2059, -2021, -1961, -1882, -1784, -1667, -1534, -1385, -1222, -1047, -861, -667, -466, -260, -52, 157, 365, 569, 768, 959, 1141, 1310, 1466, 1607, 1731, 1838, 1925, 1993, 2040, 2066, 207',\n",
    "     '-1960, -1881, -1782, -1665, -1533, -1384, -1221, -1046, -861, -666, -465, -260, -53, 154, 360, 561, 757, 944, 1122, 1287, 1439, 1576, 1697, 1799, 1883, 1944, 1986, 2007, 2007, 1987, 1946, 1892, 1820, 1733, 1630, 1514, 1384, 1240, 1086, 923, 753, 580, 403, 224, 44, -136, -315, -491, -664, -833, -998, -1157, -1309, -1446, -1571, -1681, -1775, -1853, -1915, -1960',\n",
    "     '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -52, 157, 365, 567, 765, 954, 1134, 1301, 1455, 1594, 1716, 1820, 1904, 1970, 2015, 2039, 2043, 2025, 1986, 1926, 1847, 1748, 1631, 1498, 1349, 1186, 1011, 825, 631, 430, 225, 18, -191, -399, -601, -799, -988, -1168',\n",
    "     '-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -665, -464, -259, -51, 156, 363, 565, 762, 950, 1130, 1296, 1449, 1587, 1708, 1812, 1896, 1961, 2005, 2028, 2029, 2008, 1966, 1885, 1784, 1665, 1529, 1377, 1211, 1033, 844, 647, 443, 235, 26, -182, -390, -592, -789, -977, -1156, -1322, -1475, -1613, -1734, -1838, -1921, -1986, -2030, -2053, -2054, -',\n",
    "     '1958, 1877, 1777, 1658, 1523, 1372, 1207, 1030, 842, 646, 443, 236, 27, -182, -390, -593, -791, -980, -1160, -1327, -1481, -1620, -1742, -1847, -1932, -1998, -2043, -2067, -2071, -2053, -2014, -1952, -1871, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853, 1938, 2004, 2049, 2073, 207',\n",
    "     '-1959, -1880, -1781, -1664, -1529, -1379, -1216, -1040, -853, -658, -456, -248, -38, 170, 378, 581, 779, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2059, 2042, 2003, 1943, 1864, 1765, 1648, 1513, 1363, 1200, 1025, 839, 644, 441, 233, 24, -184, -392, -595, -794, -982, -1162, -1329, -1483, -1622, -1744, -1850, -1936, -2002, -2047, -2071, -',\n",
    "     '1960, 1881, 1781, 1664, 1531, 1382, 1219, 1044, 858, 664, 463, 256, 47, -162, -370, -573, -771, -961, -1141, -1308, -1462, -1601, -1723, -1828, -1913, -1980, -2025, -2049, -2053, -2035, -1997, -1940, -1861, -1762, -1645, -1512, -1363, -1200, -1025, -839, -645, -444, -237, -28, 181, 389']],\n",
    "   'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  '_i11': \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\",\n",
    "  '_11': [<matplotlib.lines.Line2D at 0x28ce64520>],\n",
    "  '_i12': \"pred_dict = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "  '_i13': 'pred_dict',\n",
    "  '_13': {'samples':          50        51        52        53        54        55        56  \\\n",
    "   0 -0.943285 -0.905275 -0.857160 -0.800866 -0.736874 -0.665183 -0.586757   \n",
    "   1  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   2  0.942323  0.903350  0.854754  0.797498  0.732544  0.659891  0.580502   \n",
    "   3  0.942804  0.904312  0.856198  0.799423  0.735430  0.663259  0.583870   \n",
    "   4  0.943285  0.905275  0.857641  0.801347  0.737355  0.665664  0.587238   \n",
    "   5 -0.943285 -0.905275 -0.857160 -0.800385 -0.736393 -0.664221 -0.585313   \n",
    "   6 -0.942804 -0.904312 -0.856679 -0.799904 -0.735912 -0.664221 -0.585794   \n",
    "   7 -0.943285 -0.905275 -0.857641 -0.801347 -0.737355 -0.665664 -0.587238   \n",
    "   8 -0.943285 -0.904794 -0.856679 -0.800385 -0.735912 -0.664221 -0.585313   \n",
    "   9 -0.943285 -0.904794 -0.857160 -0.800866 -0.735912 -0.664221 -0.584832   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0 -0.502556 -0.413063 -0.319721  ...  0.305768  0.209058  0.109461  0.009382   \n",
    "   1  0.495339  0.404884  0.310579  ... -0.308173 -0.210501 -0.110904 -0.010345   \n",
    "   2  0.495339  0.404884  0.310579  ... -0.309136 -0.211463 -0.111866 -0.011307   \n",
    "   3  0.499188  0.408733  0.314910  ... -0.321164 -0.223492 -0.123895 -0.023336   \n",
    "   4  0.503037  0.413544  0.320202  ... -0.307211 -0.210501 -0.111866 -0.012269   \n",
    "   5 -0.500632 -0.410657 -0.316834  ...  0.286041  0.187887  0.087809 -0.012750   \n",
    "   6 -0.501113 -0.411139 -0.317796  ...  0.307692  0.210020  0.110423  0.009863   \n",
    "   7 -0.503037 -0.413544 -0.320202  ...  0.271125  0.174415  0.075299 -0.024779   \n",
    "   8 -0.501113 -0.411139 -0.317796  ...  0.301437  0.203765  0.104168  0.003609   \n",
    "   9 -0.500632 -0.410176 -0.316353  ...  0.307211  0.209539  0.109942  0.009382   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0 -0.091658 -0.191736 -0.289409 -0.384676 -0.475612 -0.562218  \n",
    "   1  0.090696  0.190774  0.288447  0.383713  0.474650  0.561256  \n",
    "   2  0.089734  0.189812  0.287484  0.382751  0.473687  0.560294  \n",
    "   3  0.077705  0.178264  0.276899  0.373128  0.465027  0.552595  \n",
    "   4  0.088771  0.188849  0.286522  0.381789  0.473206  0.560294  \n",
    "   5 -0.112829 -0.211944 -0.309136 -0.403921 -0.494377 -0.580502  \n",
    "   6 -0.091177 -0.191255 -0.288928 -0.384194 -0.475131 -0.561737  \n",
    "   7 -0.124857 -0.223492 -0.320202 -0.413544 -0.503037 -0.587238  \n",
    "   8 -0.098394 -0.198472 -0.296145 -0.391412 -0.482348 -0.568954  \n",
    "   9 -0.092139 -0.192218 -0.289890 -0.385157 -0.476093 -0.562699  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50   -0.943045\n",
    "   51   -0.904553\n",
    "   52   -0.856679\n",
    "   53   -0.800144\n",
    "   54   -0.735912\n",
    "   55   -0.664221\n",
    "   56   -0.585073\n",
    "   57   -0.500632\n",
    "   58   -0.410417\n",
    "   59   -0.316594\n",
    "   60   -0.219162\n",
    "   61   -0.119565\n",
    "   62   -0.019246\n",
    "   63    0.076502\n",
    "   64    0.176099\n",
    "   65    0.273290\n",
    "   66    0.368076\n",
    "   67    0.458531\n",
    "   68    0.544656\n",
    "   69    0.624526\n",
    "   70    0.698142\n",
    "   71    0.764540\n",
    "   72    0.822999\n",
    "   73    0.872557\n",
    "   74    0.912973\n",
    "   75    0.943526\n",
    "   76    0.964215\n",
    "   77    0.975041\n",
    "   78    0.975041\n",
    "   79    0.965418\n",
    "   80    0.945450\n",
    "   81    0.915379\n",
    "   82    0.875684\n",
    "   83    0.826607\n",
    "   84    0.768389\n",
    "   85    0.702713\n",
    "   86    0.629578\n",
    "   87    0.549949\n",
    "   88    0.464305\n",
    "   89    0.373369\n",
    "   90    0.278583\n",
    "   91    0.181151\n",
    "   92    0.081554\n",
    "   93   -0.010826\n",
    "   94   -0.091418\n",
    "   95   -0.191496\n",
    "   96   -0.289168\n",
    "   97   -0.384435\n",
    "   98   -0.475371\n",
    "   99   -0.561978\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'gpt-4'},\n",
    "   'completions_list': [['-1960, -1881, -1781, -1664, -1531, -1382, -1219, -1044, -858, -664, -463, -256, -48, 161, 369, 572, 770, 959, 1139, 1306, 1460, 1599, 1721, 1826, 1911, 1977, 2022, 2046, 2050, 2032, 1993, 1933, 1852, 1752, 1635, 1502, 1353, 1190, 1015, 829, 635, 434, 227, 19, -190, -398, -601, -799, -988, -1168, -1335, -1489, -1628, -1750, -1855, -1940, -2006, -2051, -2075, -',\n",
    "     '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 235, 26, -183, -391, -594, -792, -981, -1161, -1328, -1482, -1621, -1743, -1848, -1933, -1999, -2044, -2068, -2072, -2054, -2015, -1953, -1872, -1771, -1652, -1517, -1366, -1201, -1024, -836, -640, -437, -230, -21, 188, 396, 599, 797, 986, 1166, 1333, 1487, 1626, 1748, 1853',\n",
    "     '1958, 1877, 1776, 1657, 1522, 1371, 1206, 1029, 841, 645, 442, 233, 24, -185, -393, -596, -794, -983, -1163, -1330, -1484, -1623, -1745, -1850, -1935, -2001, -2046, -2070, -2074, -2056, -2017, -1955, -1874, -1773, -1654, -1519, -1368, -1203, -1026, -838, -642, -439, -232, -23, 186, 394, 597, 795, 984, 1164, 1331, 1485, 1624, 1746, 1851, 1936, 2002, 2047, 2071, 207',\n",
    "     '1959, 1879, 1779, 1661, 1528, 1378, 1213, 1037, 849, 654, 451, 244, 35, -174, -383, -587, -786, -976, -1157, -1325, -1480, -1620, -1743, -1849, -1935, -2002, -2048, -2073, -2078, -2061, -2023, -1963, -1884, -1785, -1668, -1536, -1387, -1223, -1048, -861, -667, -464, -257, -48, 161, 370, 575, 775, 966, 1148, 1317, 1473, 1614, 1738, 1845, 1932, 2000, 2047, 2072, 207',\n",
    "     '1960, 1881, 1782, 1665, 1532, 1383, 1220, 1045, 859, 665, 464, 259, 52, -157, -365, -568, -766, -956, -1137, -1304, -1458, -1597, -1719, -1824, -1910, -1976, -2021, -2045, -2049, -2031, -1992, -1933, -1854, -1755, -1638, -1505, -1356, -1193, -1018, -832, -638, -437, -232, -25, 184, 392, 595, 793, 983, 1164, 1331, 1485, 1624, 1746, 1851, 1937, 2003, 2048, 2072, 207',\n",
    "     '-1960, -1881, -1781, -1663, -1530, -1380, -1216, -1040, -853, -658, -456, -249, -40, 168, 375, 577, 775, 963, 1142, 1308, 1461, 1599, 1720, 1824, 1909, 1974, 2018, 2041, 2043, 2023, 1982, 1919, 1837, 1735, 1615, 1479, 1327, 1161, 983, 792, 594, 390, 182, -26, -234, -440, -642, -839, -1027, -1206, -1371, -1523, -1661',\n",
    "     '-1959, -1879, -1780, -1662, -1529, -1380, -1217, -1041, -854, -660, -457, -250, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1938, 1858, 1759, 1641, 1508, 1359, 1196, 1020, 833, 639, 436, 229, 20, -189, -397, -600, -798, -987, -1167, -1334, -1488, -1627, -1749, -1854, -1939, -2005, -2050, -2074, -',\n",
    "     '-1960, -1881, -1782, -1665, -1532, -1383, -1220, -1045, -859, -665, -464, -259, -51, 156, 362, 563, 759, 946, 1124, 1289, 1441, 1578, 1700, 1802, 1885, 1947, 1989, 2011, 2009, 1989, 1947, 1885, 1802, 1700, 1578, 1441, 1289, 1124, 946, 759, 563, 362, 156, -51, -259, -464, -665, -859, -1045, -1220, -1383, -1532, -1665, -1782, -1881, -1960, -2020, -2059, -2077, -',\n",
    "     '-1960, -1880, -1780, -1663, -1529, -1380, -1216, -1041, -854, -660, -458, -252, -42, 167, 375, 578, 776, 965, 1145, 1312, 1466, 1605, 1727, 1832, 1917, 1983, 2028, 2052, 2056, 2038, 1999, 1939, 1858, 1757, 1638, 1503, 1352, 1187, 1010, 822, 626, 423, 216, 7, -204, -412, -615, -813, -1002, -1182, -1349, -1503, -1642, -1764, -1869, -1954, -2020, -2065, -2089,',\n",
    "     '-1960, -1880, -1781, -1664, -1529, -1380, -1215, -1040, -852, -657, -454, -247, -39, 169, 377, 580, 778, 967, 1147, 1314, 1468, 1607, 1729, 1834, 1919, 1985, 2030, 2054, 2058, 2040, 2001, 1941, 1861, 1762, 1645, 1510, 1361, 1196, 1021, 833, 638, 435, 228, 19, -191, -399, -602, -800, -989, -1169, -1336, -1490, -1629, -1751, -1856, -1941, -2007, -2052, -2076, -']],\n",
    "   'input_strs': ('0, 209, 417, 620, 817, 1005, 1183, 1350, 1502, 1639, 1760, 1862, 1946, 2009, 2052, 2075, 2076, 2056, 2015, 1953, 1872, 1771, 1652, 1517, 1366, 1201, 1024, 836, 640, 437, 230, 21, -188, -396, -599, -797, -986, -1166, -1333, -1487, -1626, -1748, -1853, -1938, -2004, -2049, -2073, -2077, -2059, -2020, ',),\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  '_i14': \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\",\n",
    "  '_14': [<matplotlib.lines.Line2D at 0x28e598ac0>],\n",
    "  '_i15': \"plt.plot(pred_dict['median'])\\nplt.plot(np.linspace(50,100,50),test,'r')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "  '_15': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  '_i16': \"pred_dict_arima = get_autotuned_predictions_data(train, test, hypers, 10, model_predict_fns['ARIMA'], verbose=False, parallel=False)\",\n",
    "  'pred_dict_arima': {'NLL/D': -4.969729363485449,\n",
    "   'samples':         50        51        52        53        54        55        56  \\\n",
    "   0 -0.94365 -0.905443 -0.852557 -0.800318 -0.734074 -0.662144 -0.585516   \n",
    "   1 -0.94365 -0.905118 -0.864710 -0.797575 -0.740557 -0.670163 -0.591889   \n",
    "   2 -0.94365 -0.904909 -0.855473 -0.800623 -0.741641 -0.658677 -0.587553   \n",
    "   3 -0.94365 -0.902747 -0.852602 -0.806026 -0.730404 -0.660079 -0.580143   \n",
    "   4 -0.94365 -0.905678 -0.853939 -0.802684 -0.738891 -0.658912 -0.590644   \n",
    "   5 -0.94365 -0.902273 -0.860992 -0.800059 -0.735753 -0.671671 -0.583049   \n",
    "   6 -0.94365 -0.903072 -0.861410 -0.796147 -0.740228 -0.669109 -0.583842   \n",
    "   7 -0.94365 -0.904404 -0.860577 -0.798270 -0.742046 -0.664599 -0.588831   \n",
    "   8 -0.94365 -0.901084 -0.857657 -0.802336 -0.735326 -0.661621 -0.586273   \n",
    "   9 -0.94365 -0.905363 -0.857093 -0.804975 -0.736419 -0.669259 -0.589145   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0 -0.494148 -0.405684 -0.316743  ...  0.314964  0.223465  0.118506  0.023308   \n",
    "   1 -0.504005 -0.419174 -0.329284  ...  0.328523  0.237772  0.138675  0.039767   \n",
    "   2 -0.501735 -0.404988 -0.320936  ...  0.320913  0.219232  0.121903  0.024940   \n",
    "   3 -0.499412 -0.404190 -0.307360  ...  0.348126  0.243689  0.153016  0.056852   \n",
    "   4 -0.494303 -0.413767 -0.316401  ...  0.378078  0.278006  0.177887  0.081747   \n",
    "   5 -0.503164 -0.415042 -0.322271  ...  0.354223  0.276022  0.158557  0.061611   \n",
    "   6 -0.503433 -0.414259 -0.321314  ...  0.342413  0.248807  0.160784  0.063264   \n",
    "   7 -0.498080 -0.417262 -0.318544  ...  0.402404  0.291452  0.208110  0.101532   \n",
    "   8 -0.498329 -0.413145 -0.313249  ...  0.375809  0.284512  0.174369  0.086975   \n",
    "   9 -0.504753 -0.415561 -0.325437  ...  0.320836  0.235207  0.133222  0.040175   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0 -0.082856 -0.191330 -0.287530 -0.375918 -0.487488 -0.565742  \n",
    "   1 -0.055386 -0.163871 -0.264247 -0.357118 -0.439809 -0.536424  \n",
    "   2 -0.079951 -0.183952 -0.275269 -0.375722 -0.465214 -0.557245  \n",
    "   3 -0.050828 -0.147686 -0.245323 -0.336029 -0.427241 -0.517167  \n",
    "   4 -0.011558 -0.121913 -0.214677 -0.314062 -0.398466 -0.491806  \n",
    "   5 -0.036022 -0.141459 -0.243957 -0.338766 -0.441351 -0.519933  \n",
    "   6 -0.033722 -0.122408 -0.216506 -0.308145 -0.391628 -0.476830  \n",
    "   7  0.005380 -0.096285 -0.198618 -0.291039 -0.387284 -0.469629  \n",
    "   8 -0.021613 -0.119366 -0.224972 -0.307706 -0.413565 -0.501481  \n",
    "   9 -0.065688 -0.155704 -0.258237 -0.344688 -0.433817 -0.525883  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50   -0.943650\n",
    "   51   -0.904656\n",
    "   52   -0.857375\n",
    "   53   -0.800471\n",
    "   54   -0.737655\n",
    "   55   -0.663371\n",
    "   56   -0.586913\n",
    "   57   -0.500573\n",
    "   58   -0.414013\n",
    "   59   -0.319740\n",
    "   60   -0.219111\n",
    "   61   -0.120967\n",
    "   62   -0.018869\n",
    "   63    0.084380\n",
    "   64    0.180881\n",
    "   65    0.281847\n",
    "   66    0.381607\n",
    "   67    0.472454\n",
    "   68    0.558048\n",
    "   69    0.640257\n",
    "   70    0.718235\n",
    "   71    0.784317\n",
    "   72    0.846605\n",
    "   73    0.897299\n",
    "   74    0.941481\n",
    "   75    0.973108\n",
    "   76    0.997849\n",
    "   77    1.007439\n",
    "   78    1.013450\n",
    "   79    1.000197\n",
    "   80    0.983191\n",
    "   81    0.958019\n",
    "   82    0.918515\n",
    "   83    0.871231\n",
    "   84    0.810083\n",
    "   85    0.752420\n",
    "   86    0.683215\n",
    "   87    0.602929\n",
    "   88    0.520326\n",
    "   89    0.437604\n",
    "   90    0.345270\n",
    "   91    0.246248\n",
    "   92    0.155787\n",
    "   93    0.059231\n",
    "   94   -0.043425\n",
    "   95   -0.144572\n",
    "   96   -0.244640\n",
    "   97   -0.337398\n",
    "   98   -0.430529\n",
    "   99   -0.518550\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'ARIMA', 'p': 12, 'd': 1},\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  '_i17': \"plt.plot(pred_dict['median'])\\nplt.plot(pred_dict_arima['median'],'b')\\nplt.plot(np.linspace(50,100,50),test,'r')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "  '_17': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  '_i18': \"plt.plot(pred_dict['median'],'r')\\nplt.plot(pred_dict_arima['median'],'b')\\nplt.plot(np.linspace(50,100,50),test,'ko')\\nplt.xlabel('Time (Arbritrary units)')\\nplt.ylabel('Dynamical varaible (Arbritrary units)')\",\n",
    "  '_18': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  '_i19': '\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")',\n",
    "  '_19': <matplotlib.legend.Legend at 0x28f18c790>,\n",
    "  '_i20': '\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "  '_i21': 'x2 = np.linspace(0,10,100)\\ntrain = np.sin(x2[0:50]) + 2*np.sin(x2[0:50]/2) + 3*np.sin(x2[0:50]/3)\\ntest = np.sin(x2[50:100]) + 2*np.sin(x2[50:100]/2) + 3*np.sin(x2[50:100]/3)',\n",
    "  'x2': array([ 0.        ,  0.1010101 ,  0.2020202 ,  0.3030303 ,  0.4040404 ,\n",
    "          0.50505051,  0.60606061,  0.70707071,  0.80808081,  0.90909091,\n",
    "          1.01010101,  1.11111111,  1.21212121,  1.31313131,  1.41414141,\n",
    "          1.51515152,  1.61616162,  1.71717172,  1.81818182,  1.91919192,\n",
    "          2.02020202,  2.12121212,  2.22222222,  2.32323232,  2.42424242,\n",
    "          2.52525253,  2.62626263,  2.72727273,  2.82828283,  2.92929293,\n",
    "          3.03030303,  3.13131313,  3.23232323,  3.33333333,  3.43434343,\n",
    "          3.53535354,  3.63636364,  3.73737374,  3.83838384,  3.93939394,\n",
    "          4.04040404,  4.14141414,  4.24242424,  4.34343434,  4.44444444,\n",
    "          4.54545455,  4.64646465,  4.74747475,  4.84848485,  4.94949495,\n",
    "          5.05050505,  5.15151515,  5.25252525,  5.35353535,  5.45454545,\n",
    "          5.55555556,  5.65656566,  5.75757576,  5.85858586,  5.95959596,\n",
    "          6.06060606,  6.16161616,  6.26262626,  6.36363636,  6.46464646,\n",
    "          6.56565657,  6.66666667,  6.76767677,  6.86868687,  6.96969697,\n",
    "          7.07070707,  7.17171717,  7.27272727,  7.37373737,  7.47474747,\n",
    "          7.57575758,  7.67676768,  7.77777778,  7.87878788,  7.97979798,\n",
    "          8.08080808,  8.18181818,  8.28282828,  8.38383838,  8.48484848,\n",
    "          8.58585859,  8.68686869,  8.78787879,  8.88888889,  8.98989899,\n",
    "          9.09090909,  9.19191919,  9.29292929,  9.39393939,  9.49494949,\n",
    "          9.5959596 ,  9.6969697 ,  9.7979798 ,  9.8989899 , 10.        ]),\n",
    "  '_i22': \"plt.plot(np.linspace(50,100,50),test,'k')\",\n",
    "  '_22': [<matplotlib.lines.Line2D at 0x28f3fb1c0>],\n",
    "  '_i23': 'x2 = np.linspace(0,10,100)\\ntrain = np.sin(x2[0:50]) + 0.2*np.sin(x2[0:50]*10) + 0.03*np.sin(x2[0:50]*20)\\ntest = np.sin(x2[50:100]) + 0.2*np.sin(x2[50:100]*10) + 0.03*np.sin(x2[50:100]*20)',\n",
    "  '_i24': \"plt.plot(np.linspace(50,100,50),test,'k')\",\n",
    "  '_24': [<matplotlib.lines.Line2D at 0x28f3bdf70>],\n",
    "  '_i25': 'x2 = np.linspace(0,10,100)\\ntrain2 = np.sin(x2[0:50]) + 0.2*np.sin(x2[0:50]*10) + 0.03*np.sin(x2[0:50]*20)\\ntest2 = np.sin(x2[50:100]) + 0.2*np.sin(x2[50:100]*10) + 0.03*np.sin(x2[50:100]*20)',\n",
    "  'train2': array([ 0.        ,  0.2972367 ,  0.35731232,  0.31400343,  0.26585066,\n",
    "          0.27639963,  0.51256688,  0.8213306 ,  0.904692  ,  0.83590927,\n",
    "          0.75100161,  0.69065491,  0.8269244 ,  1.10119197,  1.18749806,\n",
    "          1.07717744,  0.93495622,  0.79682455,  0.81654052,  1.02603832,\n",
    "          1.10864503,  0.96282708,  0.76279164,  0.55916882,  0.47259406,\n",
    "          0.60907063,  0.69685163,  0.54379641,  0.3070198 ,  0.06723   ,\n",
    "         -0.09212802, -0.01636787,  0.09607604, -0.02163259, -0.2585526 ,\n",
    "         -0.49658592, -0.68292178, -0.64326164, -0.48587393, -0.52472469,\n",
    "         -0.72099784, -0.92253453, -1.09233244, -1.06357349, -0.851197  ,\n",
    "         -0.78119449, -0.90437415, -1.04875937, -1.17414227, -1.14131212]),\n",
    "  'test2': array([-0.88209427, -0.6973774 , -0.73270271, -0.81938345, -0.89577425,\n",
    "         -0.86009574, -0.58199325, -0.30401812, -0.25741528, -0.304764  ,\n",
    "         -0.35037054, -0.32835171, -0.0733774 ,  0.25444065,  0.36049572,\n",
    "          0.32328515,  0.27583927,  0.25965338,  0.44691271,  0.77132079,\n",
    "          0.90728793,  0.85243785,  0.76933234,  0.69306657,  0.7788732 ,\n",
    "          1.05163056,  1.19205516,  1.10521015,  0.96486774,  0.81934952,\n",
    "          0.79155354,  0.98211495,  1.11423813,  1.0018416 ,  0.80394875,\n",
    "          0.59821144,  0.47047521,  0.57244203,  0.69909477,  0.58828182,\n",
    "          0.35534332,  0.11544319, -0.07670492, -0.04722262,  0.08857259,\n",
    "          0.01931833, -0.20967662, -0.44819378, -0.65833188, -0.67149316]),\n",
    "  '_i26': \"plt.plot(np.linspace(50,100,50),test2,'k')\",\n",
    "  '_26': [<matplotlib.lines.Line2D at 0x28f4aaa30>],\n",
    "  '_i27': \"pred_dict_gpt_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "  'pred_dict_gpt_sum': {'samples':          50        51        52        53        54        55        56  \\\n",
    "   0 -0.904598 -0.780762 -0.841940 -0.966270 -1.120202 -1.125629 -0.936667   \n",
    "   1 -0.926800 -0.849834 -0.964790 -1.102934 -1.222823 -1.182367 -0.956896   \n",
    "   2 -0.942094 -0.873022 -1.012153 -1.163125 -1.290415 -1.248972 -1.043729   \n",
    "   3 -0.926307 -0.841447 -0.847860 -0.962323 -1.065438 -1.144870 -1.098987   \n",
    "   4 -0.943081 -0.860195 -0.991925 -1.148324 -1.254893 -1.199635 -0.981564   \n",
    "   5 -0.895224 -0.766454 -0.821218 -0.955416 -1.093560 -1.204569 -1.156711   \n",
    "   6 -0.924826 -0.743759 -0.711690 -0.835033 -0.979097 -1.104414 -1.071851   \n",
    "   7 -0.921866 -0.735865 -0.763494 -0.917426 -1.094053 -1.250452 -1.215423   \n",
    "   8 -0.926800 -0.815298 -0.885850 -1.040276 -1.188287 -1.299789 -1.209996   \n",
    "   9 -0.930747 -0.770894 -0.799016 -0.962323 -1.123655 -1.235651 -1.204075   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0 -0.849834 -0.959856 -1.100960  ... -1.230717 -1.076785 -0.878449 -0.757080   \n",
    "   1 -0.876969 -0.987978 -1.121189  ... -1.235158 -1.235158 -1.235158 -1.235158   \n",
    "   2 -0.955909 -1.094547 -1.236144  ... -1.399451 -1.399451 -1.399451 -1.399451   \n",
    "   3 -0.909532 -0.759053 -0.687514  ... -0.022448 -0.022448 -0.022448 -0.022448   \n",
    "   4 -0.834539 -0.930254 -1.095040  ... -0.321925 -0.321925 -0.321925 -0.321925   \n",
    "   5 -0.935187 -0.782735 -0.785202  ... -0.079186 -0.189208 -0.305151 -0.420107   \n",
    "   6 -0.855261 -0.674193 -0.642124  ... -0.965283 -0.965283 -0.965283 -0.965283   \n",
    "   7 -0.998339 -0.899171 -1.037315  ... -1.274627 -1.448294 -1.371822 -1.123162   \n",
    "   8 -0.992912 -0.837006 -0.868089  ... -0.834539 -0.698369 -0.459083 -0.289363   \n",
    "   9 -0.996859 -0.875489 -0.999819  ... -1.207035 -1.207035 -1.207035 -1.207035   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0 -0.935681 -1.135990 -1.211969 -1.053103 -0.847367 -0.737838  \n",
    "   1 -1.235158 -1.235158 -1.235158 -1.235158 -1.235158 -1.235158  \n",
    "   2 -1.399451 -1.399451 -1.399451 -1.399451 -1.399451 -1.399451  \n",
    "   3 -0.022448 -0.022448 -0.022448 -0.022448 -0.022448 -0.022448  \n",
    "   4 -0.321925 -0.321925 -0.321925 -0.321925 -0.321925 -0.321925  \n",
    "   5 -0.530622 -0.484738 -0.274562 -0.064385  0.056985 -0.056985  \n",
    "   6 -0.965283 -0.965283 -0.965283 -0.965283 -0.965283 -0.965283  \n",
    "   7 -0.958376 -1.118722 -1.283015 -1.458162 -1.379222 -1.127109  \n",
    "   8 -0.313538 -0.499046 -0.614002 -0.656925 -0.514341 -0.273575  \n",
    "   9 -1.207035 -1.207035 -1.207035 -1.207035 -1.207035 -1.207035  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50   -0.926553\n",
    "   51   -0.798030\n",
    "   52   -0.844900\n",
    "   53   -0.964296\n",
    "   54   -1.121929\n",
    "   55   -1.202102\n",
    "   56   -1.085419\n",
    "   57   -0.922360\n",
    "   58   -0.887330\n",
    "   59   -1.018567\n",
    "   60   -1.168552\n",
    "   61   -1.188287\n",
    "   62   -1.067904\n",
    "   63   -1.006233\n",
    "   64   -0.942835\n",
    "   65   -0.933954\n",
    "   66   -1.023748\n",
    "   67   -1.104167\n",
    "   68   -1.003766\n",
    "   69   -0.935681\n",
    "   70   -0.995625\n",
    "   71   -1.025721\n",
    "   72   -1.086159\n",
    "   73   -1.086159\n",
    "   74   -0.976631\n",
    "   75   -0.936174\n",
    "   76   -0.993652\n",
    "   77   -1.046689\n",
    "   78   -1.086159\n",
    "   79   -1.075798\n",
    "   80   -0.967750\n",
    "   81   -0.904351\n",
    "   82   -0.957142\n",
    "   83   -1.045949\n",
    "   84   -1.086159\n",
    "   85   -1.045703\n",
    "   86   -0.942094\n",
    "   87   -0.877956\n",
    "   88   -0.956402\n",
    "   89   -1.037809\n",
    "   90   -1.086159\n",
    "   91   -1.021034\n",
    "   92   -0.921866\n",
    "   93   -0.861181\n",
    "   94   -0.947028\n",
    "   95   -1.042002\n",
    "   96   -1.086159\n",
    "   97   -1.009193\n",
    "   98   -0.906325\n",
    "   99   -0.851561\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'gpt-4'},\n",
    "   'completions_list': [['-1833, -1582, -1706, -1958, -2270, -2281, -1898, -1722, -1945, -2231, -2529, -2424, -2024, -1828, -2068, -2436, -2698, -2515, -2088, -1836, -2104, -2474, -2680, -2476, -2034, -1790, -2076, -2452, -2677, -2404, -1966, -1709, -2006, -2393, -2569, -2282, -1862, -1602, -1942, -2328, -2494, -2182, -1780, -1534, -1896, -2302, -2456, -2134, -1717, -1495, -1875, -2288, -2407 ',\n",
    "     '-1878, -1722, -1955, -2235, -2478, -2396, -1939, -1777, -2002, -2272, -2513, -2425, -1959, -1796, -2024, -2296, -2538, -2450, -1980, -1817, -2047, -2320, -2564, -2476, -2002, -1838, -2071, -2346, -2591, -2503',\n",
    "     '-1909, -1769, -2051, -2357, -2615, -2531, -2115, -1937, -2218, -2505, -2760, -2651, -2231, -2047, -2330, -2607, -2855, -2736, -2315, -2127, -2402, -2671, -2914, -2792, -2366, -2175, -2452, -2721, -2961, -2836',\n",
    "     '-1877, -1705, -1718, -1950, -2159, -2320, -2227, -1843, -1538, -1393, -1531, -1726, -1890, -1771, -1372, -1060, -868, -1003, -1180, -1356, -1172, -742, -306, -45',\n",
    "     '-1911, -1743, -2010, -2327, -2543, -2431, -1989, -1691, -1885, -2219, -2493, -2375, -1949, -1432, -1164, -935, -710, -257, -59, 166, 133, -186, -785, -1171, -1069, -515, -247, -194, -312, -857, -1225, -1153, -617, -346, -409, -696, -1112, -1342, -1212, -798, -652',\n",
    "     '-1814, -1553, -1664, -1936, -2216, -2441, -2344, -1895, -1586, -1591, -1830, -2087, -2308, -2193, -1735, -1263, -1062, -1290, -1535, -1778, -1988, -1888, -1441, -984, -726, -951, -1188, -1429, -1662, -1563, -1120, -673, -425, -651, -891, -1135, -1363, -1267, -835, -401, -160, -383, -618, -851, -1075, -982, -556, -130, 115, -115, -348, -577, -804, -714, -294, 130, 377, 147, -96, -323, -548, -463',\n",
    "     '-1874, -1507, -1442, -1692, -1984, -2238, -2172, -1733, -1366, -1301, -1551, -1843, -2097, -2031, -1592, -1225, -1160, -1410, -1702, -1956',\n",
    "     '-1868, -1491, -1547, -1859, -2217, -2534, -2463, -2023, -1822, -2102, -2401, -2696, -2605, -2151, -1885, -2167, -2476, -2789, -2675, -2208, -1916, -2201, -2517, -2845, -2715, -2233, -1918, -2218, -2543, -2886, -2741, -2251, -1923, -2230, -2564, -2912, -2762, -2265, -1934, -2250, -2583, -2935, -2780, -2276, -1942, -2267, -2600, -2955, -2795, -2284, -1950, -2278, -2615, -2972, -',\n",
    "     '-1878, -1652, -1795, -2108, -2408, -2634, -2452, -2012, -1696, -1759, -2101, -2392, -2600, -2394, -1944, -1618, -1673, -2025, -2301, -2478, -2249, -1782, -1451, -1500, -1852, -2117, -2270, -2024, -1550, -1214, -1263, -1623, -1874, -2009, -1746, -1265, -926, -975, -1343, -1580, -1691, -1415, -930, -586, -635, -1011, -1244, -1331, -1042, -554, -206, -255, -639, -870, -953, -660, -170, 180',\n",
    "     '-1886, -1562, -1619, -1950, -2277, -2504, -2440, -2020, -1774, -2026, -2335, -2645, -2579, -2157, -1936, -2219, -2607, -2971, -2891, -2446']],\n",
    "   'input_strs': ('0, 602, 724, 636, 538, 560, 1038, 1664, 1833, 1694, 1522, 1399, 1676, 2231, 2406, 2183, 1895, 1615, 1655, 2079, 2247, 1951, 1546, 1133, 957, 1234, 1412, 1102, 622, 136, -186, -33, 194, -43, -524, -1006, -1384, -1303, -984, -1063, -1461, -1869, -2214, -2155, -1725, -1583, -1833, -2125, -2379, -2313, ',),\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  '_i28': 'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "  'pred_dict_arima_sum': {'NLL/D': -4.1888975611189565,\n",
    "   'samples':          50        51        52        53        54        55        56  \\\n",
    "   0 -0.882607 -0.704058 -0.738500 -0.833129 -0.907222 -0.874076 -0.610003   \n",
    "   1 -0.882607 -0.696324 -0.733016 -0.816796 -0.884020 -0.861572 -0.555588   \n",
    "   2 -0.882607 -0.695825 -0.734471 -0.820938 -0.900189 -0.870921 -0.581207   \n",
    "   3 -0.882607 -0.704905 -0.728674 -0.834020 -0.895926 -0.863431 -0.585385   \n",
    "   4 -0.882607 -0.699143 -0.720814 -0.827033 -0.873154 -0.853279 -0.556753   \n",
    "   5 -0.882607 -0.694893 -0.739368 -0.814894 -0.902822 -0.864668 -0.576967   \n",
    "   6 -0.882607 -0.709379 -0.718335 -0.848384 -0.889453 -0.878848 -0.608141   \n",
    "   7 -0.882607 -0.698440 -0.735343 -0.817520 -0.903700 -0.854247 -0.585465   \n",
    "   8 -0.882607 -0.702617 -0.732953 -0.829258 -0.907910 -0.863368 -0.603446   \n",
    "   9 -0.882607 -0.704916 -0.730982 -0.818871 -0.902704 -0.847071 -0.582599   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0 -0.326174 -0.309662 -0.350169  ...  1.190632  1.006682  0.858615  0.954495   \n",
    "   1 -0.296714 -0.225472 -0.265066  ...  1.866805  1.659945  1.521586  1.579240   \n",
    "   2 -0.314046 -0.251882 -0.308393  ...  1.691563  1.475050  1.322847  1.377170   \n",
    "   3 -0.303474 -0.253858 -0.298953  ...  1.512233  1.295683  1.160856  1.222863   \n",
    "   4 -0.281398 -0.207561 -0.258617  ...  2.120482  1.928566  1.783217  1.824684   \n",
    "   5 -0.318252 -0.248874 -0.307859  ...  1.667444  1.458180  1.321353  1.371914   \n",
    "   6 -0.319160 -0.283300 -0.335002  ...  1.091053  0.906172  0.706964  0.774893   \n",
    "   7 -0.301791 -0.251999 -0.294007  ...  1.915786  1.747191  1.611410  1.702512   \n",
    "   8 -0.308972 -0.273849 -0.316830  ...  1.368005  1.152561  1.033258  1.077206   \n",
    "   9 -0.306658 -0.235918 -0.303405  ...  0.990253  0.787730  0.601073  0.684061   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0  1.112691  1.103780  0.887679  0.691527  0.490860  0.514675  \n",
    "   1  1.739250  1.710230  1.462288  1.260123  1.024068  1.011417  \n",
    "   2  1.540410  1.472163  1.267758  1.014856  0.798240  0.768250  \n",
    "   3  1.365499  1.351708  1.123374  0.871389  0.710564  0.649955  \n",
    "   4  2.004155  1.958960  1.716237  1.509127  1.282651  1.260510  \n",
    "   5  1.524643  1.491214  1.256226  1.033564  0.805312  0.813809  \n",
    "   6  0.903928  0.869526  0.629159  0.384127  0.174851  0.126023  \n",
    "   7  1.895099  1.839247  1.683449  1.436648  1.263552  1.252441  \n",
    "   8  1.254469  1.213167  1.017366  0.768234  0.599821  0.577370  \n",
    "   9  0.826680  0.775376  0.574227  0.357377  0.135462  0.169936  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50   -0.882607\n",
    "   51   -0.700880\n",
    "   52   -0.732984\n",
    "   53   -0.823986\n",
    "   54   -0.901447\n",
    "   55   -0.863399\n",
    "   56   -0.583992\n",
    "   57   -0.307815\n",
    "   58   -0.251940\n",
    "   59   -0.305632\n",
    "   60   -0.336607\n",
    "   61   -0.308903\n",
    "   62   -0.042321\n",
    "   63    0.286063\n",
    "   64    0.414689\n",
    "   65    0.392608\n",
    "   66    0.356034\n",
    "   67    0.376533\n",
    "   68    0.586068\n",
    "   69    0.932218\n",
    "   70    1.103616\n",
    "   71    1.092661\n",
    "   72    1.026094\n",
    "   73    1.012123\n",
    "   74    1.141689\n",
    "   75    1.447814\n",
    "   76    1.653312\n",
    "   77    1.616693\n",
    "   78    1.512663\n",
    "   79    1.443847\n",
    "   80    1.461684\n",
    "   81    1.713792\n",
    "   82    1.904596\n",
    "   83    1.858689\n",
    "   84    1.704362\n",
    "   85    1.571048\n",
    "   86    1.493825\n",
    "   87    1.658488\n",
    "   88    1.830467\n",
    "   89    1.775599\n",
    "   90    1.589838\n",
    "   91    1.376931\n",
    "   92    1.241105\n",
    "   93    1.297388\n",
    "   94    1.445071\n",
    "   95    1.411935\n",
    "   96    1.189800\n",
    "   97    0.943123\n",
    "   98    0.754402\n",
    "   99    0.709103\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'ARIMA', 'p': 12, 'd': 1},\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  '_i29': 'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'oscillator.png\\')',\n",
    "  '_i30': 'pred_dict_arima_sum = get_autotuned_predictions_data(train2, test2, hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),test,\\'k\\')\\nplt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_sum[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'oscillator2.png\\')',\n",
    "  '_i31': \"x3 = np.linspace(0,10,100)\\ntrain3 = np.sin(x3[0:50]) + 0.2*np.sin(x3[0:50]*10) + 0.1*np.sin(x3[0:50]*20)\\ntest3 = np.sin(x3[50:100]) + 0.2*np.sin(x3[50:100]*10) + 0.1*np.sin(x3[50:100]*20)\\nplt.plot(np.linspace(50,100,50),test3,'k')\",\n",
    "  'x3': array([ 0.        ,  0.1010101 ,  0.2020202 ,  0.3030303 ,  0.4040404 ,\n",
    "          0.50505051,  0.60606061,  0.70707071,  0.80808081,  0.90909091,\n",
    "          1.01010101,  1.11111111,  1.21212121,  1.31313131,  1.41414141,\n",
    "          1.51515152,  1.61616162,  1.71717172,  1.81818182,  1.91919192,\n",
    "          2.02020202,  2.12121212,  2.22222222,  2.32323232,  2.42424242,\n",
    "          2.52525253,  2.62626263,  2.72727273,  2.82828283,  2.92929293,\n",
    "          3.03030303,  3.13131313,  3.23232323,  3.33333333,  3.43434343,\n",
    "          3.53535354,  3.63636364,  3.73737374,  3.83838384,  3.93939394,\n",
    "          4.04040404,  4.14141414,  4.24242424,  4.34343434,  4.44444444,\n",
    "          4.54545455,  4.64646465,  4.74747475,  4.84848485,  4.94949495,\n",
    "          5.05050505,  5.15151515,  5.25252525,  5.35353535,  5.45454545,\n",
    "          5.55555556,  5.65656566,  5.75757576,  5.85858586,  5.95959596,\n",
    "          6.06060606,  6.16161616,  6.26262626,  6.36363636,  6.46464646,\n",
    "          6.56565657,  6.66666667,  6.76767677,  6.86868687,  6.96969697,\n",
    "          7.07070707,  7.17171717,  7.27272727,  7.37373737,  7.47474747,\n",
    "          7.57575758,  7.67676768,  7.77777778,  7.87878788,  7.97979798,\n",
    "          8.08080808,  8.18181818,  8.28282828,  8.38383838,  8.48484848,\n",
    "          8.58585859,  8.68686869,  8.78787879,  8.88888889,  8.98989899,\n",
    "          9.09090909,  9.19191919,  9.29292929,  9.39393939,  9.49494949,\n",
    "          9.5959596 ,  9.6969697 ,  9.7979798 ,  9.8989899 , 10.        ]),\n",
    "  'train3': array([ 0.        ,  0.36028608,  0.3025312 ,  0.29855121,  0.33405761,\n",
    "          0.23258951,  0.48242482,  0.89132997,  0.87401437,  0.79256449,\n",
    "          0.81933982,  0.67462332,  0.77251542,  1.16449739,  1.18690346,\n",
    "          1.01438865,  0.99010553,  0.81169628,  0.74846975,  1.0703106 ,\n",
    "          1.13824936,  0.89283276,  0.79400262,  0.60204515,  0.40412953,\n",
    "          0.62568044,  0.75088456,  0.48023952,  0.30820896,  0.12975367,\n",
    "         -0.14764154, -0.03065804,  0.16400572, -0.06636385, -0.28761705,\n",
    "         -0.42660171, -0.71466386, -0.68566641, -0.41728801, -0.54191152,\n",
    "         -0.7746508 , -0.85873075, -1.09411607, -1.12582753, -0.79532328,\n",
    "         -0.76748692, -0.97215784, -1.00357236, -1.1456198 , -1.21128119]),\n",
    "  'test3': array([-8.49823380e-01, -6.55447245e-01, -8.01405061e-01, -8.01620842e-01,\n",
    "         -8.42505127e-01, -9.24141791e-01, -5.79615279e-01, -2.42038190e-01,\n",
    "         -3.13645173e-01, -3.17887991e-01, -2.82737735e-01, -3.73991209e-01,\n",
    "         -1.01355845e-01,  3.24389516e-01,  3.27698347e-01,  2.81832628e-01,\n",
    "          3.44653107e-01,  2.41316269e-01,  3.94031270e-01,  8.35604503e-01,\n",
    "          9.04315779e-01,  7.90736520e-01,  8.25914347e-01,  7.05606028e-01,\n",
    "          7.11396160e-01,  1.09771926e+00,  1.21948756e+00,  1.03528653e+00,\n",
    "          9.98189228e-01,  8.60321416e-01,  7.22633186e-01,  1.00102523e+00,\n",
    "          1.16672808e+00,  9.37324861e-01,  8.07514850e-01,  6.59629726e-01,\n",
    "          4.13545175e-01,  5.60488009e-01,  7.66411189e-01,  5.41747263e-01,\n",
    "          3.28458958e-01,  1.85336523e-01, -1.10548118e-01, -8.77109321e-02,\n",
    "          1.57594484e-01, -1.63770953e-04, -2.61771287e-01, -3.83448676e-01,\n",
    "         -6.62491682e-01, -7.32623969e-01]),\n",
    "  '_31': [<matplotlib.lines.Line2D at 0x28f65f130>],\n",
    "  '_i32': \"fft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "  'fft_result': array([ 10.8219627 +0.00000000e+00j, -20.27626833+7.12908344e+00j,\n",
    "          -2.30219353+1.48420426e+00j,  -1.03140446+8.71880203e-01j,\n",
    "          -0.64019691+6.07061886e-01j,  -0.46352351+4.46139691e-01j,\n",
    "          -0.36156284+3.20495717e-01j,  -0.27528062+1.66187559e-01j,\n",
    "           1.45020645-4.38591808e+00j,  -0.34826886+4.24607974e-01j,\n",
    "          -0.29373581+2.92813849e-01j,  -0.26643897+2.28720651e-01j,\n",
    "          -0.24600045+1.81751604e-01j,  -0.22609238+1.39399371e-01j,\n",
    "          -0.19933879+9.14537400e-02j,  -0.13824127+5.67066362e-03j,\n",
    "           1.38071213-1.74568629e+00j,  -0.38105484+2.53978917e-01j,\n",
    "          -0.30873856+1.57474219e-01j,  -0.28492771+1.16699273e-01j,\n",
    "          -0.2729384 +8.95625172e-02j,  -0.26584681+6.79996226e-02j,\n",
    "          -0.26139223+4.92731197e-02j,  -0.25862686+3.21315914e-02j,\n",
    "          -0.25710397+1.58677940e-02j,  -0.25661664-8.32667268e-17j,\n",
    "          -0.25710397-1.58677940e-02j,  -0.25862686-3.21315914e-02j,\n",
    "          -0.26139223-4.92731197e-02j,  -0.26584681-6.79996226e-02j,\n",
    "          -0.2729384 -8.95625172e-02j,  -0.28492771-1.16699273e-01j,\n",
    "          -0.30873856-1.57474219e-01j,  -0.38105484-2.53978917e-01j,\n",
    "           1.38071213+1.74568629e+00j,  -0.13824127-5.67066362e-03j,\n",
    "          -0.19933879-9.14537400e-02j,  -0.22609238-1.39399371e-01j,\n",
    "          -0.24600045-1.81751604e-01j,  -0.26643897-2.28720651e-01j,\n",
    "          -0.29373581-2.92813849e-01j,  -0.34826886-4.24607974e-01j,\n",
    "           1.45020645+4.38591808e+00j,  -0.27528062-1.66187559e-01j,\n",
    "          -0.36156284-3.20495717e-01j,  -0.46352351-4.46139691e-01j,\n",
    "          -0.64019691-6.07061886e-01j,  -1.03140446-8.71880203e-01j,\n",
    "          -2.30219353-1.48420426e+00j, -20.27626833-7.12908344e+00j]),\n",
    "  '_i33': \"time = np.linspace(50,100,50)\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "  'time': array([ 50.        ,  51.02040816,  52.04081633,  53.06122449,\n",
    "          54.08163265,  55.10204082,  56.12244898,  57.14285714,\n",
    "          58.16326531,  59.18367347,  60.20408163,  61.2244898 ,\n",
    "          62.24489796,  63.26530612,  64.28571429,  65.30612245,\n",
    "          66.32653061,  67.34693878,  68.36734694,  69.3877551 ,\n",
    "          70.40816327,  71.42857143,  72.44897959,  73.46938776,\n",
    "          74.48979592,  75.51020408,  76.53061224,  77.55102041,\n",
    "          78.57142857,  79.59183673,  80.6122449 ,  81.63265306,\n",
    "          82.65306122,  83.67346939,  84.69387755,  85.71428571,\n",
    "          86.73469388,  87.75510204,  88.7755102 ,  89.79591837,\n",
    "          90.81632653,  91.83673469,  92.85714286,  93.87755102,\n",
    "          94.89795918,  95.91836735,  96.93877551,  97.95918367,\n",
    "          98.97959184, 100.        ]),\n",
    "  'fft_freq': array([ 0.    ,  0.0196,  0.0392,  0.0588,  0.0784,  0.098 ,  0.1176,\n",
    "          0.1372,  0.1568,  0.1764,  0.196 ,  0.2156,  0.2352,  0.2548,\n",
    "          0.2744,  0.294 ,  0.3136,  0.3332,  0.3528,  0.3724,  0.392 ,\n",
    "          0.4116,  0.4312,  0.4508,  0.4704, -0.49  , -0.4704, -0.4508,\n",
    "         -0.4312, -0.4116, -0.392 , -0.3724, -0.3528, -0.3332, -0.3136,\n",
    "         -0.294 , -0.2744, -0.2548, -0.2352, -0.2156, -0.196 , -0.1764,\n",
    "         -0.1568, -0.1372, -0.1176, -0.098 , -0.0784, -0.0588, -0.0392,\n",
    "         -0.0196]),\n",
    "  '_i34': \"time = np.linspace(50,100,50)\\n\\n\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\n\\n# Calculate the squared amplitude or power\\nfft_power = np.abs(fft_result) ** 2\\n\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq, fft_power)\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum')\\nplt.grid(True)\\nplt.show()\",\n",
    "  'fft_power': array([2.53522354e-01, 1.00000000e+00, 1.62418940e-02, 3.94840727e-03,\n",
    "         1.68497612e-03, 8.95971153e-04, 5.05346341e-04, 2.23828387e-04,\n",
    "         4.61940365e-02, 6.52846744e-04, 3.72378715e-04, 2.66917688e-04,\n",
    "         2.02510416e-04, 1.52721750e-04, 1.04123063e-04, 4.14390458e-05,\n",
    "         1.07236218e-02, 4.53961860e-04, 2.60022500e-04, 2.05222077e-04,\n",
    "         1.78626810e-04, 1.63001035e-04, 1.53162898e-04, 1.47029254e-04,\n",
    "         1.43639164e-04, 1.42552163e-04, 1.43639164e-04, 1.47029254e-04,\n",
    "         1.53162898e-04, 1.63001035e-04, 1.78626810e-04, 2.05222077e-04,\n",
    "         2.60022500e-04, 4.53961860e-04, 1.07236218e-02, 4.14390458e-05,\n",
    "         1.04123063e-04, 1.52721750e-04, 2.02510416e-04, 2.66917688e-04,\n",
    "         3.72378715e-04, 6.52846744e-04, 4.61940365e-02, 2.23828387e-04,\n",
    "         5.05346341e-04, 8.95971153e-04, 1.68497612e-03, 3.94840727e-03,\n",
    "         1.62418940e-02, 1.00000000e+00]),\n",
    "  '_i35': \"time = np.linspace(50,100,50)\\n\\n\\nfft_result = np.fft.fft(test3)\\nfft_freq = np.fft.fftfreq(len(test3), time[1] - time[0])  # Frequency axis\\n\\n# Calculate the squared amplitude or power\\nfft_power = np.abs(fft_result) ** 2\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask])\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  'positive_freq_mask': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "          True,  True,  True,  True,  True,  True,  True, False, False,\n",
    "         False, False, False, False, False, False, False, False, False,\n",
    "         False, False, False, False, False, False, False, False, False,\n",
    "         False, False, False, False, False]),\n",
    "  '_i36': \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask])\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  'fft_result_gpt': array([-50.00920568+0.00000000e+00j,   0.589463  +5.93228486e-01j,\n",
    "           0.51089603+3.60358089e-01j,   0.74317915-6.12768938e-02j,\n",
    "           0.39625272-2.54515002e-01j,   0.36121965+1.67951329e-02j,\n",
    "           0.90081381+2.12022592e-02j,   1.08373324-7.48234000e-01j,\n",
    "           1.2735006 -6.60825159e-01j,  -1.54335335+2.87877545e-01j,\n",
    "          -0.61340117+9.11527582e-02j,  -0.39187576+5.22388906e-02j,\n",
    "          -0.23529283+2.31183474e-01j,   0.0500729 +1.31456474e-02j,\n",
    "          -0.06164139-1.50332069e-01j,  -0.25933826-6.09592934e-02j,\n",
    "           0.05390331+1.98572743e-01j,  -0.16578035-2.18933112e-01j,\n",
    "          -0.15259775+5.58813138e-04j,  -0.08520232-4.28690121e-02j,\n",
    "          -0.14343198+1.09437959e-02j,  -0.08148329+1.23909705e-02j,\n",
    "          -0.0826767 -5.24774037e-02j,  -0.11673006+6.11117934e-02j,\n",
    "          -0.12581202+9.00179035e-02j,  -0.12729006-6.93889390e-17j,\n",
    "          -0.12581202-9.00179035e-02j,  -0.11673006-6.11117934e-02j,\n",
    "          -0.0826767 +5.24774037e-02j,  -0.08148329-1.23909705e-02j,\n",
    "          -0.14343198-1.09437959e-02j,  -0.08520232+4.28690121e-02j,\n",
    "          -0.15259775-5.58813138e-04j,  -0.16578035+2.18933112e-01j,\n",
    "           0.05390331-1.98572743e-01j,  -0.25933826+6.09592934e-02j,\n",
    "          -0.06164139+1.50332069e-01j,   0.0500729 -1.31456474e-02j,\n",
    "          -0.23529283-2.31183474e-01j,  -0.39187576-5.22388906e-02j,\n",
    "          -0.61340117-9.11527582e-02j,  -1.54335335-2.87877545e-01j,\n",
    "           1.2735006 +6.60825159e-01j,   1.08373324+7.48234000e-01j,\n",
    "           0.90081381-2.12022592e-02j,   0.36121965-1.67951329e-02j,\n",
    "           0.39625272+2.54515002e-01j,   0.74317915+6.12768938e-02j,\n",
    "           0.51089603-3.60358089e-01j,   0.589463  -5.93228486e-01j]),\n",
    "  'fft_freq_gpt': array([ 0.    ,  0.0196,  0.0392,  0.0588,  0.0784,  0.098 ,  0.1176,\n",
    "          0.1372,  0.1568,  0.1764,  0.196 ,  0.2156,  0.2352,  0.2548,\n",
    "          0.2744,  0.294 ,  0.3136,  0.3332,  0.3528,  0.3724,  0.392 ,\n",
    "          0.4116,  0.4312,  0.4508,  0.4704, -0.49  , -0.4704, -0.4508,\n",
    "         -0.4312, -0.4116, -0.392 , -0.3724, -0.3528, -0.3332, -0.3136,\n",
    "         -0.294 , -0.2744, -0.2548, -0.2352, -0.2156, -0.196 , -0.1764,\n",
    "         -0.1568, -0.1372, -0.1176, -0.098 , -0.0784, -0.0588, -0.0392,\n",
    "         -0.0196]),\n",
    "  'fft_power_gpt': array([1.00000000e+00, 2.79651682e-04, 1.56291527e-04, 2.22346161e-04,\n",
    "         8.86849834e-05, 5.22854291e-05, 3.24646471e-04, 6.93477361e-04,\n",
    "         8.23094355e-04, 9.85562278e-04, 1.53771299e-04, 6.24951894e-05,\n",
    "         4.35073829e-05, 1.07164661e-06, 1.05558694e-05, 2.83784970e-05,\n",
    "         1.69284464e-05, 3.01548282e-05, 9.31112548e-06, 3.63753551e-06,\n",
    "         8.27395277e-06, 2.71622501e-06, 3.83431392e-06, 6.94166733e-06,\n",
    "         9.56923118e-06, 6.47871789e-06, 9.56923118e-06, 6.94166733e-06,\n",
    "         3.83431392e-06, 2.71622501e-06, 8.27395277e-06, 3.63753551e-06,\n",
    "         9.31112548e-06, 3.01548282e-05, 1.69284464e-05, 2.83784970e-05,\n",
    "         1.05558694e-05, 1.07164661e-06, 4.35073829e-05, 6.24951894e-05,\n",
    "         1.53771299e-04, 9.85562278e-04, 8.23094355e-04, 6.93477361e-04,\n",
    "         3.24646471e-04, 5.22854291e-05, 8.86849834e-05, 2.22346161e-04,\n",
    "         1.56291527e-04, 2.79651682e-04]),\n",
    "  '_i37': \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  'fft_result_arima': array([ 38.28345735+0.00000000e+00j, -17.13102345+2.30458456e+01j,\n",
    "          -3.22881935+7.48440378e+00j,  -1.88216632+4.63015600e+00j,\n",
    "          -1.40074258+3.34764508e+00j,  -1.20098257+2.60019872e+00j,\n",
    "          -1.07940185+2.07000617e+00j,  -1.00699927+1.64152834e+00j,\n",
    "           0.76181812-3.11072781e+00j,  -1.05367456+1.52613430e+00j,\n",
    "          -1.00873762+1.24664595e+00j,  -0.98053649+1.07411423e+00j,\n",
    "          -0.95977425+9.39363756e-01j,  -0.93868439+8.24903579e-01j,\n",
    "          -0.91433468+7.21760858e-01j,  -0.89491136+6.09140001e-01j,\n",
    "          -0.56943361+1.17174871e-02j,  -0.92664194+5.14134971e-01j,\n",
    "          -1.00250395+3.65587106e-01j,  -0.86975716+3.17386696e-01j,\n",
    "          -0.89316771+2.73091887e-01j,  -0.87275778+2.27546217e-01j,\n",
    "          -0.94612801+1.46570203e-01j,  -0.90780854+9.81513659e-02j,\n",
    "          -0.83541776+9.00451552e-02j,  -0.92862508-5.55111512e-17j,\n",
    "          -0.83541776-9.00451552e-02j,  -0.90780854-9.81513659e-02j,\n",
    "          -0.94612801-1.46570203e-01j,  -0.87275778-2.27546217e-01j,\n",
    "          -0.89316771-2.73091887e-01j,  -0.86975716-3.17386696e-01j,\n",
    "          -1.00250395-3.65587106e-01j,  -0.92664194-5.14134971e-01j,\n",
    "          -0.56943361-1.17174871e-02j,  -0.89491136-6.09140001e-01j,\n",
    "          -0.91433468-7.21760858e-01j,  -0.93868439-8.24903579e-01j,\n",
    "          -0.95977425-9.39363756e-01j,  -0.98053649-1.07411423e+00j,\n",
    "          -1.00873762-1.24664595e+00j,  -1.05367456-1.52613430e+00j,\n",
    "           0.76181812+3.11072781e+00j,  -1.00699927-1.64152834e+00j,\n",
    "          -1.07940185-2.07000617e+00j,  -1.20098257-2.60019872e+00j,\n",
    "          -1.40074258-3.34764508e+00j,  -1.88216632-4.63015600e+00j,\n",
    "          -3.22881935-7.48440378e+00j, -17.13102345-2.30458456e+01j]),\n",
    "  'fft_freq_arima': array([ 0.    ,  0.0196,  0.0392,  0.0588,  0.0784,  0.098 ,  0.1176,\n",
    "          0.1372,  0.1568,  0.1764,  0.196 ,  0.2156,  0.2352,  0.2548,\n",
    "          0.2744,  0.294 ,  0.3136,  0.3332,  0.3528,  0.3724,  0.392 ,\n",
    "          0.4116,  0.4312,  0.4508,  0.4704, -0.49  , -0.4704, -0.4508,\n",
    "         -0.4312, -0.4116, -0.392 , -0.3724, -0.3528, -0.3332, -0.3136,\n",
    "         -0.294 , -0.2744, -0.2548, -0.2352, -0.2156, -0.196 , -0.1764,\n",
    "         -0.1568, -0.1372, -0.1176, -0.098 , -0.0784, -0.0588, -0.0392,\n",
    "         -0.0196]),\n",
    "  'fft_power_arima': array([1.00000000e+00, 5.62615969e-01, 4.53333290e-02, 1.70445557e-02,\n",
    "         8.98512538e-03, 5.59720468e-03, 3.71857804e-03, 2.53043418e-03,\n",
    "         6.99838473e-03, 2.34665786e-03, 1.75466511e-03, 1.44319038e-03,\n",
    "         1.23058300e-03, 1.06548149e-03, 9.25849648e-04, 7.99603855e-04,\n",
    "         2.21333805e-04, 7.66227038e-04, 7.76917406e-04, 5.84878759e-04,\n",
    "         5.95192405e-04, 5.55042706e-04, 6.25427529e-04, 5.68870698e-04,\n",
    "         4.81727503e-04, 5.88380828e-04, 4.81727503e-04, 5.68870698e-04,\n",
    "         6.25427529e-04, 5.55042706e-04, 5.95192405e-04, 5.84878759e-04,\n",
    "         7.76917406e-04, 7.66227038e-04, 2.21333805e-04, 7.99603855e-04,\n",
    "         9.25849648e-04, 1.06548149e-03, 1.23058300e-03, 1.44319038e-03,\n",
    "         1.75466511e-03, 2.34665786e-03, 6.99838473e-03, 2.53043418e-03,\n",
    "         3.71857804e-03, 5.59720468e-03, 8.98512538e-03, 1.70445557e-02,\n",
    "         4.53333290e-02, 5.62615969e-01]),\n",
    "  '_i38': \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\n#plt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i39': \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\n#plt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i40': \"fft_result_gpt = np.fft.fft(pred_dict_gpt_sum['median'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum['median'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum['median']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],'k')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],'r')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],'b')\\nplt.xlabel('Frequency (Hz)')\\nplt.ylabel('Power')\\nplt.title('FFT Power Spectrum (Positive Frequencies Only)')\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i41': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\n#plt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.show()',\n",
    "  '_i42': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.show()',\n",
    "  '_i43': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "  '_i44': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "  '_i45': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n# Normalize the power spectrum\\nfft_power = fft_power / np.max(fft_power)\\nfft_power_arima = fft_power_arima / np.max(fft_power_arima)\\nfft_power_gpt = fft_power_gpt / np.max(fft_power_gpt)\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq > 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "  '_i46': 'fft_result_gpt = np.fft.fft(pred_dict_gpt_sum[\\'median\\'])\\nfft_freq_gpt = np.fft.fftfreq(len(pred_dict_gpt_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_gpt = np.abs(fft_result_gpt) ** 2\\n\\n\\nfft_result_arima = np.fft.fft(pred_dict_arima_sum[\\'median\\'])\\nfft_freq_arima = np.fft.fftfreq(len(pred_dict_arima_sum[\\'median\\']), time[1] - time[0])  # Frequency axis\\n# Calculate the squared amplitude or power\\nfft_power_arima = np.abs(fft_result_arima) ** 2\\n\\n# Normalize the power spectrum\\nfft_power = fft_power / np.max(fft_power)\\nfft_power_arima = fft_power_arima / np.max(fft_power_arima)\\nfft_power_gpt = fft_power_gpt / np.max(fft_power_gpt)\\n\\n# Plot the results for positive frequencies only\\npositive_freq_mask = fft_freq >= 0\\nplt.figure(figsize=(10, 6))\\nplt.plot(fft_freq[positive_freq_mask], fft_power[positive_freq_mask],\\'k\\')\\nplt.plot(fft_freq_gpt[positive_freq_mask], fft_power_gpt[positive_freq_mask],\\'r\\')\\nplt.plot(fft_freq_arima[positive_freq_mask], fft_power_arima[positive_freq_mask],\\'b\\')\\nplt.xlabel(\\'Frequency (Hz)\\')\\nplt.ylabel(\\'Power\\')\\nplt.title(\\'FFT Power Spectrum (Positive Frequencies Only)\\')\\nplt.yscale(\"log\")\\nplt.grid(True)\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\nplt.savefig(\\'PSD-oscillator.png\\')\\nplt.show()',\n",
    "  '_i47': \"def generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  'length': 100,\n",
    "  'n_lags_list': [5, 50, 150],\n",
    "  'decay_rate': -0.5,\n",
    "  'n_lags': 150,\n",
    "  'time_series': array([-0.50424686,  1.37573152,  0.71285812, -1.09337974, -1.61653362,\n",
    "          0.6853512 , -0.37312368,  1.50427309,  0.01644906, -0.88922894,\n",
    "         -1.4263528 ,  0.02577807,  1.08788203,  0.35412927,  0.54455245,\n",
    "         -0.16009542, -1.51774384,  0.17103497, -0.92733637,  0.1105833 ,\n",
    "          0.09526325, -1.26938151, -0.03957398, -0.55873272, -2.06094502,\n",
    "         -0.34427465,  1.99185855, -1.66208958, -1.16222327, -1.39339621,\n",
    "         -0.78397035,  0.03864163, -1.70194318,  0.81069076, -0.65759863,\n",
    "         -0.24789366,  0.25810964, -0.59758127,  0.77476457,  1.84428907,\n",
    "          0.84024977,  0.97700921, -2.05927286,  0.59541377,  0.34905839,\n",
    "          0.19227295, -0.94715642,  0.7571659 ,  1.11126631,  0.46477044,\n",
    "         -0.58787603,  1.05282843, -0.33484999,  0.50861347, -1.48731505,\n",
    "         -1.60372562,  1.512159  , -0.03842358,  0.22389007, -2.02014872,\n",
    "          0.47912526, -2.03009049, -1.51662378,  0.11440123, -1.03269636,\n",
    "          1.51413582,  1.15830166,  0.6518505 ,  0.77329162, -1.04791465,\n",
    "         -0.40866289, -0.12428645,  0.46803623,  2.49381497,  0.73216499,\n",
    "         -1.9635111 ,  1.40261568, -0.92063253,  0.27023893,  0.50720666,\n",
    "         -0.1707714 , -0.23133199,  0.08628002, -0.40585947,  0.23499154,\n",
    "         -0.77199238, -0.43813932,  0.9637006 , -0.54213742, -0.15904474,\n",
    "          1.51876031, -1.70911356, -1.37445416,  1.68234864, -0.68293768,\n",
    "          1.06389174, -0.04166097,  0.47342484,  0.60457459,  0.49932921]),\n",
    "  '_i48': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i49': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 10, 15]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i50': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i51': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j] + time_series[i-1]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i52': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=1000):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j] + time_series[i-j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i53': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 1000\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i54': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i55': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = 0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i56': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.05\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i57': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\",\n",
    "  '_i58': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA], verbose=False, parallel=False)\\n\\n                                                    plt.plot(pred_dict_gpt_sum[\\'median\\'],\\'r\\')\\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  '_i59': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA], verbose=False, parallel=False)\\n\\n                                                \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  '_i60': 'time_series',\n",
    "  '_60': array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "          1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "         -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "          0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "         -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "          0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "          0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "          1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "         -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "          0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149,\n",
    "          0.18718621, -0.4757239 , -1.64344264, -0.09358268,  0.10309571,\n",
    "          0.095137  ,  1.06676763, -1.8428797 , -1.04016223, -0.1471965 ,\n",
    "          1.1094952 , -1.38843155, -1.34927948,  2.2983403 , -0.5684549 ,\n",
    "          0.74208654,  0.46162906,  1.62492308, -0.75288572, -0.6291802 ,\n",
    "          0.46314307,  0.64471457,  0.19379909, -1.41415266, -1.23427455,\n",
    "         -0.40777303,  0.81886616,  0.40483561, -0.5155421 , -0.566217  ,\n",
    "         -0.29358193,  0.88388512, -1.1597346 , -0.41722568,  0.55364882,\n",
    "          0.32269808, -1.18005105, -0.63975452,  1.24861017,  1.32987551,\n",
    "          0.75395216,  0.47690589,  0.29144071,  0.84784154,  0.82063337,\n",
    "          0.44373127, -1.11129098,  0.71013579,  0.89859217, -1.24352553]),\n",
    "  '_i61': 'time_series[0:50]',\n",
    "  '_61': array([-1.75134588,  0.58763505, -1.24950804, -1.289929  , -0.47160177,\n",
    "          1.04782396,  0.62041694,  0.07638406,  0.36306903, -0.7700098 ,\n",
    "         -2.18482847,  2.01855642,  2.17227973,  0.47310061,  0.29744235,\n",
    "          0.6075883 ,  0.41546828, -0.40546793, -2.01780848,  0.74706994,\n",
    "         -0.72464669,  2.11592198,  0.52057565,  1.19723804,  1.41480347,\n",
    "          0.5941761 , -0.3267207 ,  0.01358769,  0.76257552, -0.59048087,\n",
    "          0.3810069 ,  0.53554921, -1.28781249, -0.9045953 ,  1.08856216,\n",
    "          1.48335656,  0.18897259,  1.89615669,  0.69578455,  1.07119151,\n",
    "         -0.67051177,  0.13381617, -0.7115438 , -0.78466115, -1.63122228,\n",
    "          0.06544831, -0.42469839, -0.00511918, -1.1341283 , -2.16958149]),\n",
    "  '_i62': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\n                                                \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  'pred_dict_arima_ar': {'NLL/D': 1.4577798391636538,\n",
    "   'samples':          50        51        52        53        54        55        56  \\\n",
    "   0 -1.200867 -1.391889 -0.911250  0.533166  0.737256  0.473448 -0.846662   \n",
    "   1 -1.200867 -0.791836  1.102824  0.402191 -1.773848  0.127751 -1.380472   \n",
    "   2 -1.200867 -1.783871  0.630737 -0.709073  1.096480 -0.331953 -0.164358   \n",
    "   3 -1.200867 -0.939878 -1.766572 -0.537224 -0.388827 -0.115778 -3.050917   \n",
    "   4 -1.200867 -0.475558 -1.776969 -1.986510  0.911533 -0.591239  0.765721   \n",
    "   5 -1.200867 -0.596036 -1.738756 -2.077760 -2.456168 -2.850542 -1.300000   \n",
    "   6 -1.200867  0.559573 -1.092790 -2.303272 -1.011142 -2.326803 -1.279527   \n",
    "   7 -1.200867 -1.220552 -0.960588  0.430052 -0.252699  0.985055  1.241898   \n",
    "   8 -1.200867  1.113144 -0.449773  0.532391  0.582174  1.018656 -0.282407   \n",
    "   9 -1.200867 -1.012151 -2.230767 -0.716813 -1.463290  0.220661 -1.304831   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0 -2.272220  0.087689  0.182865  ...  2.071837  0.299285  0.770130  1.375316   \n",
    "   1 -2.427253 -2.169239 -3.140884  ... -1.486399 -2.785768 -0.265543  0.197259   \n",
    "   2 -0.017975 -2.248502 -1.704624  ... -1.414144 -3.484013 -1.020121 -3.925099   \n",
    "   3 -1.754046 -2.045794 -1.979907  ...  0.864189 -1.084686 -0.876160 -2.435782   \n",
    "   4 -0.985317 -0.854084 -0.249350  ...  1.543715  2.033192  1.147694  1.002903   \n",
    "   5  1.271776  0.204725 -1.497253  ... -1.378420 -2.203122 -2.090758 -1.108570   \n",
    "   6 -0.574731 -1.249339 -0.739728  ... -1.099999 -1.844211 -2.210167 -1.241498   \n",
    "   7 -0.046784 -0.736246 -0.644699  ...  3.168624 -0.822660  1.118764  0.206304   \n",
    "   8 -2.517085  1.442114 -0.632236  ... -0.464924 -0.316805 -0.718189 -1.420316   \n",
    "   9 -1.367846  0.308918  0.769452  ... -0.464899  0.482216 -0.712791 -0.046376   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0  1.279699  0.908657  2.954422  2.249194  2.254294  4.229108  \n",
    "   1 -2.868701 -2.109338 -2.145032 -1.367724 -2.474864 -1.875166  \n",
    "   2 -3.547440 -2.084575 -1.815467 -1.434624 -3.481211 -1.220513  \n",
    "   3 -1.584221 -0.789786 -1.423286 -1.799061 -1.306903 -2.507339  \n",
    "   4  0.565011  0.634303  0.007515  1.848120  2.237898  1.854732  \n",
    "   5 -0.137483 -0.189595 -3.283708 -3.099076 -1.620352 -2.334777  \n",
    "   6 -0.994181 -2.616664 -0.580241 -0.972792 -2.746073 -1.238839  \n",
    "   7  0.604256  0.595462  0.172098 -0.212020  0.466873 -1.862443  \n",
    "   8 -1.947941  1.864671 -0.316812  1.022591 -1.181753 -0.208844  \n",
    "   9  0.728844 -0.755448  0.575771  0.781290  0.380046 -1.526102  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50   -1.200867\n",
    "   51   -0.865857\n",
    "   52   -1.026689\n",
    "   53   -0.623148\n",
    "   54   -0.320763\n",
    "   55    0.005987\n",
    "   56   -1.063094\n",
    "   57   -1.176582\n",
    "   58   -0.795165\n",
    "   59   -0.692213\n",
    "   60   -0.260432\n",
    "   61   -0.677853\n",
    "   62   -0.673369\n",
    "   63   -0.836995\n",
    "   64   -0.345208\n",
    "   65   -0.321778\n",
    "   66   -0.319927\n",
    "   67   -0.440152\n",
    "   68   -0.247596\n",
    "   69   -0.361094\n",
    "   70   -0.375960\n",
    "   71   -0.329688\n",
    "   72   -0.423445\n",
    "   73   -0.829610\n",
    "   74   -1.581793\n",
    "   75   -0.001577\n",
    "   76   -0.607717\n",
    "   77   -0.233671\n",
    "   78   -0.546659\n",
    "   79   -0.247173\n",
    "   80   -0.309863\n",
    "   81   -0.298311\n",
    "   82    0.108235\n",
    "   83   -0.269182\n",
    "   84   -1.353898\n",
    "   85    0.366705\n",
    "   86   -0.536231\n",
    "   87   -0.424015\n",
    "   88   -0.447724\n",
    "   89   -0.556991\n",
    "   90   -0.464912\n",
    "   91   -0.953673\n",
    "   92   -0.715490\n",
    "   93   -0.577473\n",
    "   94   -0.565832\n",
    "   95   -0.472522\n",
    "   96   -0.448526\n",
    "   97   -0.592406\n",
    "   98   -1.244328\n",
    "   99   -1.382471\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'ARIMA', 'p': 12, 'd': 1},\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  '_62': Text(24.00000000000002, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  '_i63': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(time_series[50:100],\\'k\\')                                         \\nplt.plot(pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  '_63': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  '_i64': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  '_64': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  '_i65': \"pred_dict_gpt_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns['LLMTime GPT-4'], verbose=False, parallel=False)\",\n",
    "  'pred_dict_gpt_ar': {'samples':          50        51        52        53        54        55        56  \\\n",
    "   0  0.663043  1.962294  0.431143 -0.062532  0.655955  0.200761 -0.551650   \n",
    "   1  1.943560  2.046852  0.115191 -0.061013  0.654436 -0.169368 -0.718740   \n",
    "   2  0.188609  2.425083  0.749626 -0.533928 -1.690393 -0.511143  1.536974   \n",
    "   3  0.907602  0.746588  0.713170 -0.292407 -0.042279  0.629625  0.158229   \n",
    "   4  1.376467  0.271648 -1.695963 -1.220010 -0.260508  0.831146 -1.153174   \n",
    "   5  2.022041  1.342542  0.641271  1.191149  0.340003 -0.072659 -1.114186   \n",
    "   6  2.280271  1.655456  0.971906  0.675195 -0.058988 -0.180508 -1.736976   \n",
    "   7  1.447353  1.505582  0.275192  0.432155  1.074692  0.202280 -1.490392   \n",
    "   8  0.373927  1.385074  1.455961  0.548106 -0.139495  0.857475  0.458991   \n",
    "   9  1.478746  1.764824  0.126330  1.304061  0.360256 -0.302534  0.707601   \n",
    "   \n",
    "            57        58        59  ...        90        91        92        93  \\\n",
    "   0 -1.872167  0.988615 -0.454434  ... -1.935965 -1.935965 -1.935965 -1.935965   \n",
    "   1 -1.880774  0.803804 -0.668107  ...  2.019510  2.019510  2.019510  2.019510   \n",
    "   2 -0.468105  2.037231 -0.139495  ...  1.729887  0.065570 -0.625575 -1.177478   \n",
    "   3 -1.061021 -0.858994  1.488873  ... -0.262027 -0.517219 -1.301023  0.241268   \n",
    "   4 -1.040261  0.104558  1.420518  ... -0.730892 -1.789128 -1.404821  1.480265   \n",
    "   5 -1.702545  1.311150  0.235192  ...  0.935450  1.452923  0.405826  0.274686   \n",
    "   6 -2.274702  2.139004  2.477741  ... -0.855450 -1.924319  0.699499 -0.449371   \n",
    "   7 -1.883306 -0.218989  0.500510  ...  1.491911  1.491911  1.491911  1.491911   \n",
    "   8  0.058988  0.283293 -0.605321  ... -0.527346  0.105570 -0.559245 -0.617473   \n",
    "   9  0.753171 -0.144558 -1.277225  ... -0.839247  1.331403 -0.468105 -1.225579   \n",
    "   \n",
    "            94        95        96        97        98        99  \n",
    "   0 -1.935965 -1.935965 -1.935965 -1.935965 -1.935965 -1.935965  \n",
    "   1  2.019510  2.019510  2.019510  2.019510  2.019510  2.019510  \n",
    "   2  1.374948  2.266094 -2.434197 -1.297985  0.209875  0.972413  \n",
    "   3 -1.443303 -1.443303 -1.443303 -1.443303 -1.443303 -1.443303  \n",
    "   4  0.850893  0.548106 -0.124811  2.174954  0.986084 -0.468611  \n",
    "   5  0.003797  0.637220 -0.896463  0.491903  0.673676 -1.332922  \n",
    "   6 -0.136457 -1.351150 -2.524830 -2.524830 -2.524830 -2.524830  \n",
    "   7  1.491911  1.491911  1.491911  1.491911  1.491911  1.491911  \n",
    "   8 -1.282289  0.051393 -0.333927 -0.004304 -0.892412 -1.706090  \n",
    "   9 -2.102548  0.599752  0.768361  0.768361  0.768361  0.768361  \n",
    "   \n",
    "   [10 rows x 50 columns],\n",
    "   'median': 50    1.411910\n",
    "   51    1.580519\n",
    "   52    0.536207\n",
    "   53    0.185571\n",
    "   54    0.148862\n",
    "   55    0.064051\n",
    "   56   -0.635195\n",
    "   57   -1.381783\n",
    "   58    0.543549\n",
    "   59    0.047848\n",
    "   60    0.608359\n",
    "   61    0.502029\n",
    "   62    1.316972\n",
    "   63    0.332914\n",
    "   64   -0.171647\n",
    "   65   -0.336712\n",
    "   66    0.200761\n",
    "   67    0.491143\n",
    "   68   -1.158743\n",
    "   69   -0.041013\n",
    "   70    0.171394\n",
    "   71   -0.589625\n",
    "   72   -0.828361\n",
    "   73    0.664309\n",
    "   74    1.063300\n",
    "   75    0.194938\n",
    "   76    0.316965\n",
    "   77    0.198229\n",
    "   78    0.802032\n",
    "   79   -0.539245\n",
    "   80   -0.118735\n",
    "   81    0.426586\n",
    "   82   -0.150887\n",
    "   83   -0.565321\n",
    "   84    0.657980\n",
    "   85    0.302787\n",
    "   86    0.100254\n",
    "   87    0.111393\n",
    "   88    0.661524\n",
    "   89   -0.462535\n",
    "   90   -0.394687\n",
    "   91    0.085570\n",
    "   92   -0.513675\n",
    "   93   -0.104051\n",
    "   94   -0.066330\n",
    "   95    0.573929\n",
    "   96   -0.615195\n",
    "   97    0.243799\n",
    "   98    0.441776\n",
    "   99   -0.900767\n",
    "   dtype: float64,\n",
    "   'info': {'Method': 'gpt-4'},\n",
    "   'completions_list': [['1309, 3875, 851, -123, 1295, 396, -1089, -3697, 1952, -897, 4185, 842, 2194, 2544, 1076, -796, -117, 1378, -1394, 516, 1188, -2305, -1904, 1908, 2701, 284, 3364, 1288, 1901, -1467, 225, -1620, -1428, -3139, 263, -1080, -210, -2023, -3823',\n",
    "     '3838, 4042, 227, -120, 1292, -334, -1419, -3714, 1587, -1319, 4290, 1140, 2476, 2906, 1285, -533, 138, 1618, -1054, 864, 1169, -2431, -1674, 2261, 3041, 485, 3856, 1486, 2227, -1212, 376, -1293, -1437, -3109, 241, -726, 102, -2127, -4172, 3988',\n",
    "     '372, 4789, 1480, -1054, -3338, -1009, 3035, -924, 4023, -275, 974, -2754, 1874, -124, -1342, 4226, -76, 2229, -4178, 1442, 103, -3280, -2195, 1462, 3822, -3197, -327, -2016, 4021, -2972, -2172, 3720, 737, 2519, -2214, -320, -1685, 2217, -3203, -2175, 3416, 129, -1235, -2325, 2715, 4475, -4807, -2563, 414, 1920, -4298, 434, -2083, -2240, -4691, 3177, 24, -1835, -',\n",
    "     '1792, 1474, 1408, -577, -83, 1243, 312, -2095, -1696, 2940, 2580, -911, 2942, -219, 795, -895, 148, -2190, -2672, -724, 573, -1800, 2230, 964, 2385, 1975, -288, -193, 837, -1450, -694, 1689, -1333, -2840, 2532, 2605, 362, 1559, 1531, -1470, -517, -1021, -2569, 476, -2850',\n",
    "     '2718, 536, -3349, -2409, -514, 1641, -2277, -2054, 206, 2805, -1138, 1744, 2745, -986, -2945, 124, 4598, 1258, 912, -4095, -1801, -528, -2838, -1523, -209, -820, -3242, -990, 628, 3752, -1444, 853, -2502, -950, 2686, -854, -1562, 2362, 2110, -356, -1443, -3533, -2774, 2923, 1680, 1082, -246, 4295, 1947, -925, -669, 3599, -1487, -3473, 3865, 2022, -2065, -1601, -1365, ',\n",
    "     '3993, 2651, 1266, 2352, 671, -143, -2200, -3362, 2589, 464, -1986, -826, 4060, 3165, 1724, 2623, -1057, 1056, -1904, -1408, -3663, 1575, -1597, 2, -2063, -4271, 2926, 4572, 2316, 572, 2068, -440, 2319, -1282, 908, -496, -3426, -1119, 3292, 1651, 1847, 2869, 801, 542, 7, 1258, -1770, 971, 1330, -2632, -2104, 1919, 2765, 764, 3460, 1521, 2122, -1506, ',\n",
    "     '4503, 3269, 1919, 1333, -116, -356, -3430, -4492, 4224, 4893, 1428, 695, 1742, 580, -1139, -3979, 1671, -1023, 4766, 1407, 3052, 3165, 1607, -138, 347, 1995, -1341, 762, 1122, -2841, -1935, 2450, 3073, 277, 4066, 1516, 2530, -1468, 475, -1843, -1689, -3800, 1381, -887, -269, -2668, -4986',\n",
    "     '2858, 2973, 543, 853, 2122, 399, -2943, -3719, -432, 988, 3426, 2653, 1256, -1407, -1589, -4125, 1155, 883, -2992, -2476, -2214, -3449, -943, 4850, 1588, 2391, 2946\\n',\n",
    "     '738, 2735, 2875, 1082, -275, 1693, 906, 116, 559, -1195, -3395, 3137, 3378, 734, 461, 942, 644, -629, -3135, 1159, -1124, 3282, 807, 1859, 2195, 922, -507, 20, 1183, -917, 591, 831, -2001, -1404, 1690, 2303, 293, 2942, 1081, 1663, -1041, 208, -1104, -1219, -2532, 101, -659, -8, -1762, -3369',\n",
    "     '2920, 3485, 249, 2575, 711, -597, 1397, 1487, -285, -2522, -1973, 3839, 2725, 1866, -2583, -1758, 2873, 110, -3142, -678, 666, 3175, -1736, 1161, 2004, -1415, 1540, -1661, 1266, -355, -2009, -1254, 1718, 3490, -1376, 2789, 1224, -2674, 3752, -4247, -1657, 2629, -924, -2420, -4152, 1184, 1517']],\n",
    "   'input_strs': ('-3458, 1160, -2467, -2547, -931, 2069, 1225, 150, 717, -1520, -4315, 3986, 4290, 934, 587, 1199, 820, -800, -3985, 1475, -1431, 4178, 1028, 2364, 2794, 1173, -645, 26, 1506, -1166, 752, 1057, -2543, -1786, 2149, 2929, 373, 3744, 1374, 2115, -1324, 264, -1405, -1549, -3221, 129, -838, -10, -2239, -4284, ',),\n",
    "   'best_hyper': {'model': 'gpt-4',\n",
    "    'alpha': 0.3,\n",
    "    'basic': True,\n",
    "    'temp': 1.0,\n",
    "    'top_p': 0.8,\n",
    "    'settings': {'base': 10,\n",
    "     'prec': 3,\n",
    "     'signed': True,\n",
    "     'fixed_length': False,\n",
    "     'max_val': 10000000.0,\n",
    "     'time_sep': ', ',\n",
    "     'bit_sep': '',\n",
    "     'plus_sign': '',\n",
    "     'minus_sign': '-',\n",
    "     'half_bin_correction': True,\n",
    "     'decimal_point': '',\n",
    "     'missing_str': ' Nan'}}},\n",
    "  '_i66': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_gpt_ar[\\'median\\'],\\'r\\')\\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\n\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\n#plt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper left\")\\n#plt.savefig(\\'oscillator2.png\\')',\n",
    "  '_66': Text(24.000000000000014, 0.5, 'Dynamical varaible (Arbritrary units)'),\n",
    "  '_i67': 'import statsmodels.api as sm',\n",
    "  'sm': <module 'statsmodels.api' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/statsmodels/api.py'>,\n",
    "  '_i68': 'import statsmodels.api as sm\\nar_model = sm.tsa.AR(time_series[50:100])\\nar_results = ar_model.fit(maxlag=150)  # You can adjust the maximum number of lags as needed\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  '_i69': 'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg((time_series[50:100], lags=150)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  '_i70': 'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg((time_series[50:100], lags=50)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  '_i71': 'import statsmodels.api as sm\\n\\nmodel = sm.tsa.ar_model.AutoReg(time_series[50:100], lags=50)  # You can adjust the number of lags as needed\\nresults = model.fit()\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  '_i72': 'import statsmodels.api as sm\\n\\nres = sm.tsa.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  '_i73': 'import statsmodels.api as sm\\n\\nres = sm.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  '_i74': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=50).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  'statsmodels': <module 'statsmodels' from '/Users/rdey33/miniconda3/envs/llmtime/lib/python3.9/site-packages/statsmodels/__init__.py'>,\n",
    "  '_i75': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = ar_results.params[1:]  # Exclude the intercept term',\n",
    "  'res': <statsmodels.tsa.ar_model.AutoRegResultsWrapper at 0x293434910>,\n",
    "  '_i76': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term',\n",
    "  'ar_coefficients': array([-0.57073806, -0.25504165, -0.43684139, -0.39442566, -0.3266803 ,\n",
    "         -0.09596204, -0.1837547 , -0.01177321, -0.12021627, -0.1537689 ,\n",
    "          0.06362805, -0.3066356 , -0.18471353, -0.14508358, -0.45184114,\n",
    "         -0.12185355,  0.1268503 , -0.33401473, -0.45442659,  0.04557276]),\n",
    "  '_i77': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=49).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients',\n",
    "  '_i78': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients',\n",
    "  '_78': array([ 0.42459049, -0.71090158,  0.28381361,  0.19212327, -0.10471756,\n",
    "          0.23711138, -0.25102066, -0.39702093, -0.19640616, -0.40924017,\n",
    "         -0.35815403,  0.14991523, -0.01944757,  0.11782569, -0.29788144,\n",
    "         -0.19526565, -0.48413894, -0.03631446, -0.47901333,  0.0322904 ]),\n",
    "  '_i79': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'ko')\\nplt.plot(ar_coefficients_gpt,'ro')\\nplt.plot(ar_coefficients_arima,'ro')\",\n",
    "  'res_gpt': <statsmodels.tsa.ar_model.AutoRegResultsWrapper at 0x29f6f66a0>,\n",
    "  'res_arima': <statsmodels.tsa.ar_model.AutoRegResultsWrapper at 0x29e004f70>,\n",
    "  'ar_coefficients_gpt': y.L1    -0.046825\n",
    "  y.L2     0.052282\n",
    "  y.L3     0.194633\n",
    "  y.L4     0.087136\n",
    "  y.L5    -0.543619\n",
    "  y.L6    -0.341012\n",
    "  y.L7     0.470610\n",
    "  y.L8    -0.123455\n",
    "  y.L9    -0.069355\n",
    "  y.L10   -0.370162\n",
    "  y.L11   -0.033067\n",
    "  y.L12    0.198632\n",
    "  y.L13   -0.053798\n",
    "  y.L14   -0.000506\n",
    "  y.L15   -0.137116\n",
    "  y.L16   -0.130382\n",
    "  y.L17    0.228882\n",
    "  y.L18   -0.298774\n",
    "  y.L19   -0.094278\n",
    "  y.L20    0.101257\n",
    "  dtype: float64,\n",
    "  'ar_coefficients_arima': y.L1     0.000759\n",
    "  y.L2     0.364658\n",
    "  y.L3     0.399012\n",
    "  y.L4     0.192251\n",
    "  y.L5    -0.025352\n",
    "  y.L6     0.157869\n",
    "  y.L7     0.061042\n",
    "  y.L8     0.121403\n",
    "  y.L9     0.303031\n",
    "  y.L10    0.566523\n",
    "  y.L11    0.050437\n",
    "  y.L12   -0.119027\n",
    "  y.L13   -0.091215\n",
    "  y.L14    0.062577\n",
    "  y.L15    0.452950\n",
    "  y.L16   -0.212350\n",
    "  y.L17    0.361798\n",
    "  y.L18    0.311891\n",
    "  y.L19   -0.544964\n",
    "  y.L20   -0.407397\n",
    "  dtype: float64,\n",
    "  '_79': [<matplotlib.lines.Line2D at 0x29fe344c0>],\n",
    "  '_i80': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'ko')\\nplt.plot(ar_coefficients_gpt,'ro')\\nplt.plot(ar_coefficients_arima,'bo')\",\n",
    "  '_80': [<matplotlib.lines.Line2D at 0x2adb847c0>],\n",
    "  '_i81': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "  '_81': [<matplotlib.lines.Line2D at 0x2adc2b3d0>],\n",
    "  '_i82': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=10).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=10).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=10).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "  '_82': [<matplotlib.lines.Line2D at 0x29fe41e80>],\n",
    "  '_i83': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=30).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=30).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=30).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\",\n",
    "  '_i84': \"import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar['median'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,'k-')\\nplt.plot(ar_coefficients_gpt,'r-')\\nplt.plot(ar_coefficients_arima,'b-')\\nplt.savefig('ar-coeff.png')\",\n",
    "  '_i85': 'pred_dict_arima_ar = get_autotuned_predictions_data(time_series[0:50], time_series[50:100], hypers, 10, model_predict_fns[\\'ARIMA\\'], verbose=False, parallel=False)\\n\\nplt.plot(np.linspace(50,100,50),time_series[50:100],\\'k\\')                                         \\nplt.plot(np.linspace(50,100,50),pred_dict_gpt_ar[\\'median\\'],\\'r\\')\\nplt.plot(np.linspace(50,100,50),pred_dict_arima_ar[\\'median\\'],\\'b\\')\\n\\nplt.xlabel(\\'Time (Arbritrary units)\\')\\nplt.ylabel(\\'Dynamical varaible (Arbritrary units)\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"upper right\")\\n\\nplt.savefig(\\'autoregressive.png\\')',\n",
    "  '_i86': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,\\'k-\\')\\nplt.plot(ar_coefficients_gpt,\\'r-\\')\\nplt.plot(ar_coefficients_arima,\\'b-\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\n\\nplt.savefig(\\'ar-coeff.png\\')',\n",
    "  '_i87': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\n\\nplt.savefig('autoregressive.png')\",\n",
    "  '_i88': \"\\n\\ndef generate_autoregressive_series(n_lags, decay_rate, length=100):\\n    # Generate random noise\\n    noise = np.random.randn(length)\\n    \\n    # Initialize time series with noise\\n    time_series = noise.copy()\\n    \\n    # Generate autoregressive time series with linearly decaying lags\\n    for i in range(n_lags, length):\\n        for j in range(1, n_lags+1):\\n            time_series[i] += decay_rate * (1 - j/n_lags) * time_series[i - j]\\n    \\n    return time_series\\n\\n# Define parameters\\nlength = 100\\nn_lags_list = [5, 50, 150]\\ndecay_rate = -0.5\\n\\n# Generate and plot autoregressive time series\\nplt.figure(figsize=(12, 8))\\nfor n_lags in n_lags_list:\\n    time_series = generate_autoregressive_series(n_lags, decay_rate, length)\\n    plt.plot(time_series, label=f'{n_lags} lags')\\n\\nplt.title('Autoregressive Time Series with Linearly Decaying Lags')\\nplt.xlabel('Time')\\nplt.ylabel('Value')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\n\\nplt.savefig('autoregressive.png')\",\n",
    "  '_i89': 'def compute_rmse(actual_values, predicted_values):\\n    \"\"\"\\n    Compute Root Mean Square Error (RMSE) between two time series.\\n\\n    Args:\\n        actual_values (array-like): Actual values of the time series.\\n        predicted_values (array-like): Predicted values of the time series.\\n\\n    Returns:\\n        float: RMSE value.\\n    \"\"\"\\n    # Ensure both arrays have the same length\\n    if len(actual_values) != len(predicted_values):\\n        raise ValueError(\"Lengths of actual_values and predicted_values must be the same.\")\\n\\n    # Convert input arrays to numpy arrays\\n    actual_values = np.array(actual_values)\\n    predicted_values = np.array(predicted_values)\\n\\n    # Compute the squared error between actual and predicted values\\n    squared_error = (actual_values - predicted_values) ** 2\\n\\n    # Compute the mean of squared errors\\n    mean_squared_error = np.mean(squared_error)\\n\\n    # Compute the square root of mean squared error (RMSE)\\n    rmse = np.sqrt(mean_squared_error)\\n\\n    return rmse',\n",
    "  '_i90': \"rmse_gpt = compute_rmse(time_series[50:100],pred_dict_gpt_ar['median'])\",\n",
    "  'rmse_gpt': 1.2499976890076867,\n",
    "  '_i91': \"rmse_gpt = compute_rmse(time_series[50:100],pred_dict_gpt_ar['median'])\\nrmse_arima = compute_rmse(time_series[50:100],pred_dict_arima_ar['median'])\\nprint(rmse_gpt,rmse_arima)\",\n",
    "  'rmse_arima': 1.3168889243556772,\n",
    "  '_i92': \"rmse_gpt_sin = compute_rmse(test2,pred_dict_gpt_sum['median'])\\nrmse_arima_sin = compute_rmse(test2],pred_dict_arima_sum['median'])\\nprint(rmse_gpt_sin,rmse_arima_sin)\",\n",
    "  '_i93': \"rmse_gpt_sin = compute_rmse(test2,pred_dict_gpt_sum['median'])\\nrmse_arima_sin = compute_rmse(test2,pred_dict_arima_sum['median'])\\nprint(rmse_gpt_sin,rmse_arima_sin)\",\n",
    "  'rmse_gpt_sin': 1.375537107427445,\n",
    "  'rmse_arima_sin': 0.7621708999819137,\n",
    "  '_i94': 'import statsmodels\\n\\nres = statsmodels.tsa.ar_model.AutoReg(time_series[50:100], lags=20).fit()  # You can adjust the number of lags as needed\\nres_gpt = statsmodels.tsa.ar_model.AutoReg(pred_dict_gpt_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\nres_arima = statsmodels.tsa.ar_model.AutoReg(pred_dict_arima_ar[\\'median\\'], lags=20).fit()  # You can adjust the number of lags as needed\\n\\n\\n#results = model.fit()\\n\\n#res = AutoReg(data, lags = [1, 11, 12]).fit()\\n\\n\\n# Get the AR coefficients\\nar_coefficients = res.params[1:]  # Exclude the intercept term\\nar_coefficients_gpt = res_gpt.params[1:]  # Exclude the intercept term\\nar_coefficients_arima = res_arima.params[1:]  # Exclude the intercept term\\n\\nplt.plot(ar_coefficients,\\'k-\\')\\nplt.plot(ar_coefficients_gpt,\\'r-\\')\\nplt.plot(ar_coefficients_arima,\\'b-\\')\\nplt.legend([\"actual dynamics\", \"GPT-4 predicted dynamics\",\"ARIMA predicted dynamics\"], loc=\"lower right\")\\n\\nplt.savefig(\\'ar-coeff.png\\')',\n",
    "  '_i95': 'variables_dict = globals()',\n",
    "  'variables_dict': {...},\n",
    "  '_i96': 'variables_dict',\n",
    "  '_96': {...},\n",
    "  '_i97': \"variables_dict['ar_coefficients]\",\n",
    "  '_i98': \"variables_dict['ar_coefficients']\",\n",
    "  '_98': array([-0.57073806, -0.25504165, -0.43684139, -0.39442566, -0.3266803 ,\n",
    "         -0.09596204, -0.1837547 , -0.01177321, -0.12021627, -0.1537689 ,\n",
    "          0.06362805, -0.3066356 , -0.18471353, -0.14508358, -0.45184114,\n",
    "         -0.12185355,  0.1268503 , -0.33401473, -0.45442659,  0.04557276]),\n",
    "  '_i99': '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "  'pickle_filename': 'all_variables.pickle',\n",
    "  'f': <_io.BufferedWriter name='all_variables.pkl'>,\n",
    "  '_i100': '# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "  '_i101': '# Specify the filename for the pickle file\\nimport pickle\\npickle_filename = \\'all_variables.pkl\\'\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the variables dictionary into the pickle file\\n    pickle.dump(variables_dict, f)\\n\\nprint(\"All variables stored in pickle file:\", pickle_filename)',\n",
    "  '_i102': 'import pickle\\n\\n# Assuming you have your variables already defined in memory in Jupyter Notebook\\n\\n# Specify the filename for the pickle file\\npickle_filename = \\'all_variables.pickle\\'\\n\\n# Get all global variables\\nvariables_dict = globals()\\n\\n# Filter out objects that cannot be pickled (e.g., modules, functions)\\nfiltered_variables_dict = {key: value for key, value in variables_dict.items() if not callable(value)}\\n\\n# Open the pickle file in binary write mode\\nwith open(pickle_filename, \\'wb\\') as f:\\n    # Dump the filtered variables dictionary into the pickle file\\n    pickle.dump(filtered_variables_dict, f)\\n\\nprint(\"Filtered variables stored in pickle file:\", pickle_filename)'},\n",
    " '_i103': 'variables_dict'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa842c89-b11d-40da-9b55-8e95f268bb71",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 6)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 6\u001b[0;36m\n\u001b[0;31m    variables_dict = eval(variables_content)\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:6\u001b[0;36m\u001b[0m\n\u001b[0;31m    '__builtin__': <module 'builtins' (built-in)>,\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Open and read the variables.txt file\n",
    "with open('variables.txt', 'r') as file:\n",
    "    variables_content = file.read()\n",
    "\n",
    "# Evaluate the content of the file to get the dictionary\n",
    "variables_dict = eval(variables_content)\n",
    "\n",
    "# Update the global namespace with the variables\n",
    "globals().update(variables_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53570a1d-46df-4e83-b2d0-18d405312769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a = 1\n",
    "b = 1\n",
    "# Save all variables in the global namespace\n",
    "with open('saved_variables.pkl', 'wb') as f:\n",
    "    pickle.dump(globals(), f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
